<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>AI Future | Prof Truyen Tran</title>

<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">
<style>
body {
font-family: 'Abel';
font-size: 100px;
}
</style>
<meta name="GENERATOR" content="LyX 2.3.1-1">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;</style>
<meta name="GENERATOR" content="LyX 2.3.1-1">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;
}
</style></head>
<body>
<table style="border-collapse: collapse; width: 1000px; height: 1000px;" id="1" border="0" bordercolor="#111111" cellpadding="3" cellspacing="0">
<tbody>
<tr>
<td style="border-width: 1px; border-right: 1px solid; vertical-align: top; background-color: rgb(241, 242, 241);" v="" rowspan="8">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="figs/deepLearningAI500.png" hspace="0"><br>
</p>
<p align="right">[Source:&nbsp;rdn-consulting]
&nbsp;</p>
<p align="right"> </p>
<p align="right"><big><a href="index.html">Home</a> <br><a href="#Grants">Grants</a> <br><a href="#TalksTutorials">Talks</a><br><a href="#Popular_writings">Popular writings</a><br><a href="#Publications">Publications</a></big> </p>
<br>
&nbsp; <br>
</td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(215, 228, 244);">
<p style="color: rgb(0, 51, 0);"><font style="color: rgb(0, 102, 0); font-weight: bold;" size="+3">&nbsp;AI
Future</font><a name="medical"></a></p>
<p style="margin-left: 40px; color: black;"><big>Our
goal is to
build a generalist AI of the future&nbsp;which can seamlessly work
on all
practical scenarios. This includes a unified
cognitive architecture that guides the learning and reasoning across
scales in space-time.</big></p>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top; width: 50%;">
<p class="MsoNormal" style="text-align: justify; font-weight: bold;"><big>Aims</big></p>
<ul>
<li><big>To <span style="font-style: italic;">understand
intelligence</span>.<o:p></o:p></big></li>
<li><big>To <span style="font-style: italic;">design intelligent machines</span>.<o:p></o:p></big></li>
<li><big>To <span style="font-style: italic;">solve important problems</span>.</big></li>
</ul>


</td>
<td style="vertical-align: top;">
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: black;"><big>Areas</big></p>
<ul>
<li><a href="#Scaling_out:_Agents_as_digital_spieces"><big><span style="text-decoration: underline;">Scaling out: Agents as
digital spieces</span></big></a></li>
<li><a href="#Reasoning:_System_2_capability"><big>Reasoning:
System 2 capability</big></a></li>
<li><a href="#Alignment:_Truth_values_and_safety"><big>Alignment:
Truth, values and safety</big></a></li>
</ul>

<big> </big> </td>
</tr>
</tbody>
</table>

</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(222, 236, 244);"><big><span style="font-weight: bold;">&nbsp;Projects</span><br>
</big>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top; width: 50%;"><big>»
<a href="#New_inductive_biases_in_deep_learning">New
inductive biases in deep learning</a></big><br>
<big>» <a href="#Memory_architectures_for_neural_networks">Memory
architectures for neural networks</a></big><br>
<big>» <a href="#Indirection_mechanisms_for_better">Indirection
mechanisms for&nbsp;generalization</a></big><br>
<big>» <a href="#Compositional_reasoning_in_">Compositional
reasoning in vision-language</a></big><br>
<big>» <a href="#Collaborative_priors_for_LLM-powered">Collaborative
priors for LLM multi-agents</a><br>
</big><big>» <a href="#Learning_for_structural_reasoning">Learning for
structural reasoning</a><br>
</big><big>» <a href="#Theory_of_mind_architectures">Theory of mind
architectures</a><br>
</big><big>» <a href="#Efficient_exploration_of_combinatorial">Efficient
exploration of combinatorial spaces</a></big></td>
<td style="vertical-align: top;"><big>» <a href="#Theory_of_mind_in_LLMs_">Theory of mind in LLMs</a></big><br>
<big>» <a href="#Scaling_with_sparse_mixture_of_experts_">Scaling with
sparse mixture of experts</a></big><br>
<big>» <a href="https://theoryinformed-ml.github.io/">Theory-informed
machine learning</a></big><br>
<big>» <a href="#Representing_and_reasoning_over_noisy_">Representing
and reasoning over noisy data</a><br>
</big><big>» <a href="#Structured_reasoning_in_video_">Structured reasoning
in video</a></big><br>
<big>» </big><a href="AI-fundamental.html#Human_behaviour_understanding_in_video"><big>Understanding
human behaviours in video</big></a><br>
<big>» </big><a href="AI-fundamental.html#Visual_question_answering_and_dialog"><big>Visual
question answering</big></a><br>
<big>» </big><a href="#Video_dialog"><big>Video
dialog</big></a></td>
</tr>
</tbody>
</table>
&nbsp;</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(233, 233, 233);"><big><span style="font-weight: bold;">Projects (Old)<br>
</span></big>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top; width: 50%;"><big>»
Recomender systems: Random fields</big><br>
<big>» Ordinal choice modelling</big><br>
<big>» Conditional random fields</big><br>
<big>» Advances in Restricted
Boltzmann Machines<br>
</big><big>» Software projects analytics and
automation&nbsp;<br>
</big><big>» Software language models</big></td>
<td style="vertical-align: top;"><big>»
High-dimensional model stability</big><br>
<big>» RNNs for structured data</big><br>
<big>» Advances in representation learning<br>
</big><big>» Understanding GANs<br>
</big><big>» Learning relational structures in
time</big><br>
<big>» Learning to represent episodic data</big></td>
</tr>
</tbody>
</table>
<br>
</td>
</tr>
<tr>
<td style="width: 24px;">&nbsp; &nbsp;
&nbsp;&nbsp;
<p>&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp; <br>
</p>
</td>
<td style="vertical-align: top; width: 90%; background-color: white;"><big><big><o:p></o:p></big></big>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 102, 0);"><big><big><a name="Scaling_out:_Agents_as_digital_spieces"></a>Scaling
out: Agents as digital spieces </big></big></p>
<p><big>Instead of scaling up a single agent, we
envision</big><big><span style="font-weight: bold;"></span>
a future of "society of agents", representing a new kind of digital
species. Each agent has lifewide experience to interact
and work with other agents and humans, evolving lifelong with the
dynamics of its environments. Equipped with perception, memory,
statistical relational learning, theory of mind, common sense,
knowledge and reasoning capabilities, we aim to bring this new digital
species to a new level.</big></p>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 102, 0);"><big><big><a name="Reasoning:_System_2_capability"></a>Reasoning:
System 2 capability</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big>We
are concerned about learning
the capability to deduce new knowledge from previously acquired
knowledge in
response to a query. Such behaviours can be demonstrated naturally
using a symbolic
system with a rich set inferential tools, given that the symbols can be
grounded to the sensory world. Deep learning contributes to the
bottom-up
learning of such a reasoning system by resolving the symbol grounding
problem.
Our research aims to build neural architectures that can learn to
exhibit
high-level reasoning functionalities, e.g., answering new questions
over
space-time in a compositional and progressive fashion.</big></p>
<p class="MsoNormal" style="text-align: justify;"><big><font style="color: rgb(0, 153, 0); font-weight: bold;" size="+2"><span style="color: rgb(0, 102, 0);"><a name="Alignment:_Truth_values_and_safety"></a>Alignment:
Truth, values and safety</span></font></big> </p>
<big>The
rapid advancement of AI raises new ethical challenges which pose great
risks to humanity if unsolved. We aim to invent new machine learning
algorithms that teach machine to be compatible with human preferences.
We derive&nbsp;
computational frameworks for instilling intrinsic human preferences
into AI through preference learning, alignment optimisation, and
preference-guided agent designs.<br>
</big><br>
<p class="MsoNormal" style="text-align: justify; font-weight: bold;"><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="New_inductive_biases_in_deep_learning"></a>New inductive biases in deep learning</span></big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big>We
derive modular networks for regular data such as matrix
and
tensor as well as new data such as graphs and relations. We draw our
architectural inspiration from neuroscience including the columnar
structure of
the neocortex for distributed processing, the thalamus structure for
information routing, working memory for problem solving, and episodic
memory
for integrating information over time.</big></p>
<div style="text-align: center;"><big><big><span><img style="width: 367px; height: 246px;" alt="Column networks" src="figs/column-net.png" v:shapes="_x0000_i1033"><br>
</span></big></big><big><span style="font-style: italic;">Column
Networks, as inspired
by the cortical columns, to solve multi-relational learning</span>.</big><big><br>
</big></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Memory_architectures_for_neural_networks"></a>Memory
architectures for neural networks<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>Deep
neural networks excel at
function approximation and pattern recognition but fall short on
manipulating
complex, highly dependent systems, rapid contextualisation in new
settings, retaining previously acquired skills, and holding long
conversations. These limitations are possibly due to the lack of an
explicit notion of memory. We design new kinds of memory with more
robust handling of variability,
less
memorization, and stored programs. The memory serves as a central
component in a grand unified cognitive architecture that naturally
supports learning, reasoning, rapid contextualisation and imagination.</big></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 519px; height: 345px;" alt="Variational memory encoder decoder" src="figs/VMED.png" v:shapes="Picture_x0020_2"><br>
</span></big></big><big style="font-style: italic;">Generative models with
variational memory</big></div>
<p class="MsoNormal" style="text-align: justify;"><big style="font-style: italic;"><big><o:p></o:p></big></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big>&nbsp;<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Compositional_reasoning_in_"></a>Compositional
reasoning in vision-language domains<br>
</span></big></big><big><br>
Compositionality is pervasive in nature, language and our thought
processes. However, the compositional structures need to be uncovered
from raw signals and texts. <br>
&nbsp;<br>
<br>
</big>
<div style="text-align: center;"><big><big><span style=""><img style="width: 602px; height: 280px;" alt="A system for Video QA" src="figs/VideoQA.png" v:shapes="Picture_x0020_1"><br>
</span></big></big><big><span style="font-style: italic;">A system for
Video Question
Answering that implements the dual-process theory of reasoning.</span></big><br>
</div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Learning_for_structural_reasoning"></a>Learning
for structural reasoning<br>
<br>
</span></big></big><big>Relational and
causal structures exist in nature, language and thought processes.
&nbsp; </big><br>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big>
<div style="text-align: center;"><big><big><span style=""><img style="width: 579px; height: 289px;" alt="Relational Dynamic Memory Network" src="figs/RDMN.png" v:shapes="Picture_x0020_2147"></span></big></big><big><span style="font-style: italic;"><br>
Relational Dynamic Memory
Network, a model for detecting relations between graphical structures.</span></big></div>

<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"></span><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Indirection_mechanisms_for_better"></a>Indirection
mechanisms for better generalization<br>
<br>
</span></big></big><big>The capacity of
extreme generalization into completely new
domains in human-level intelligence is strongly connected to the
ability to abstract out the complex world and draw analogies between
seemingly disconnected parts of the world. Here we search for new
computational foundations that support abstraction, including object
discovery, </big><big>relations discovery,&nbsp;
functional programming, indirection, symbolic manupilation
and&nbsp; formulation of analogies.<br>
<br>
</big>
<div style="text-align: center;"><big><big><span><img v:shapes="Picture_x0020_1" src="figs/InLay-IQ-prob.png" alt="A system for Video QA" style="width: 700px; height: 224px;"><br>
</span></big></big><big><span style="font-style: italic;">A system for abstracting out
visual details, focusing on relations
between images via an indirection mechanism. This is capable of solving
IQ problems.</span></big></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Theory_of_mind_architectures"></a>Theory of mind
architectures<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>Theory
of mind refers to the ability to attribute the mental states of others.
This is a hallmark of human intelligence. This project aims to design
architectures which enable this ability in artificial agents.&nbsp;</big></p>
<p class="MsoNormal" style="text-align: center;"><big><img style="width: 500px; height: 283px;" alt="ToMAGA system." src="figs/ToMAGA.png"></big><big><span style="font-style: italic;"><br>
</span></big></p>
<p class="MsoNormal" style="text-align: center;"><big><span style="font-style: italic;">A system of multi-agents
equipped with
social psychology.</span></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Efficient_exploration_of_combinatorial"></a>Efficient
exploration of combinatorial spaces<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>Theory
of mind refers to the ability to attribute the mental states of others.
This is a hallmark of human intelligence. This project aims to design
architectures which enable this ability in artificial agents.&nbsp;</big></p>
<p class="MsoNormal" style="text-align: center;"><big><img style="width: 500px; height: 283px;" alt="ToMAGA system." src="figs/ToMAGA.png"></big><big><span style="font-style: italic;"><br>
</span></big></p>
<p class="MsoNormal" style="text-align: center;"><big><span style="font-style: italic;">A system of multi-agents
equipped with
social psychology.</span></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><br>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Collaborative_priors_for_LLM-powered"></a>Collaborative
priors for LLM-powered multi-agents<br>
</span></big></big><big><br>
LLMs
are powerful agents, but they are not pre-designed to work with other
agents. This project aims at developing effective priors to enable
LLMs-powered agents to collaborate to achieve greater long-term team
goals.</big><br>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Theory_of_mind_in_LLMs_"></a>Theory of mind in
LLMs<br>
</span></big></big><big><br>
LLMs
learn to compress the text and then are tuned to follow instructions.
Their ability to understand others' mental states is not a built-in.
This project aims to analyse this ability, and finds new ways to build
theory of mind in to LLMs.<br>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big>&nbsp;</big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
<a name="Scaling_with_sparse_mixture_of_experts_"></a>Scaling
with sparse mixture of experts<br>
</span></big></big><big><br>
Sparse
mixture of experts is a scalable solution to train LLMs. However, much
of its behaviours is still poorly understood. This project aims to shed
light on the matter.<br>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Representing_and_reasoning_over_noisy_"></a>Representing
and reasoning over noisy data<br>
<br>
</span></big></big><big>The
world is noisy, and system with thousands of sensors are impossible for
human to understand. This project aims at inventing an unified
representation schemes across sensors of multiple types, and reasoning
mechanism over extended period of time.</big><br>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><br>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Structured_reasoning_in_video_"></a>Structured
reasoning in video<br>
</span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big><big>Video
is highly structured, but the structural information is hidden behind
flat pixels, making it challenging for direct reasoning over video's
events, objects, characters and stories. This project to uncover such
structures and demonstrate the effects on complex video reasoning tasks.<br>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big>

<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);"></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Human_behaviour_understanding_in_video"></a>Human
behaviour
understanding in video</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big>This
project
aims at a deep understanding of human behaviours seen through (fixed
and
moving) videos in various indoor and outdoor contexts. We build new
models of
trajectories and social interactions, inferring past trigger events,
and predict actions and
intention. <o:p></o:p></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><u>Partners</u>:
iCetana</big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 454px; height: 465px;" alt="Anomaly detection with skeleton trajectories" src="figs/skeleton-anomaly.png" v:shapes="Picture_x0020_2086"><br>
</span></big></big><big><span style="font-style: italic;">Detecting anomalies in video
using skeleton trajectories (last row)</span></big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big></div>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Visual_question_answering_and_dialog"></a>Visual
question
answering and dialog</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal"><big>We
study the new cognitive
capability of a system to answer new natural questions about an image
or a
video. This is a powerful way to demonstrate the reasoning capacity,
which
involves linguistic, visual processing and high-level symbols
manipulation
skills. In visual dialog, we build a system having a natural multi-turn
chat
with human about a visual object.</big></p>
<p class="MsoNormal" style="margin-left: 18pt;"></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 568px; height: 207px;" alt="Answering question about video" src="figs/VideoQA-exp.png" v:shapes="Picture_x0020_2085"><br>
</span></big></big><big><span style="font-style: italic;">Answering questions about a
video.</span></big></div>
<p class="MsoCaption" style="text-align: center;" align="center"></p>
<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
</span>
<p class="MsoCaption" style="text-align: center;" align="center"></p>
<div style="text-align: left;"><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Video_dialog"></a>Video dialog</span></big></big></div>
<p class="MsoCaption" style="text-align: center;" align="center"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);"></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big><span style="font-style: italic;"></span><big><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: left;"><big>This
project aims to build a dialog system that can talk about video of
arbitrary length.</big></p>
<p class="MsoCaption" style="text-align: left;"></p>
<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
</span><font style="font-weight: bold;" size="5"><a name="Grants"></a>Grants<br></font><ul><li><font size="+1">Learning and reasoning
on multisensor data</font><big> ($850K), </big><big><span style="font-style: italic;">Australian
DoD</span></big><big><span style="font-style: italic;"></span>, 2022-2024.</big></li><li><big>Framework
for verifying machine learning algorithms ($360K), <span style="font-style: italic;">ARC Discovery</span>,
2021-2023.</big></li><li><big>Defence
applied AI
experiential CoLab ($1M), <span style="font-style: italic;">Australian
DoD</span>, 2020-2021.</big></li><li><big>Telstra
centre of excellence in big data and machine learning ($1.6M), <span style="font-style: italic;">Telstra</span>, 2016–2020.</big></li><li><big>Predicting
hazardous
software using deep learning, ($100K), <span style="font-style: italic;">Samsung GRO</span>,
2016–2017.</big></li><li><big>Studying
and developing advanced machine learning based models for extracting
chemical/drug-disease relations from biomedical literature”, ($54K), <span style="font-style: italic;">Vietnam NAFOSTED</span>, 2017–2018.</big></li><li><big>Building a simulator of mail sorting machine, ($12K), <span style="font-style: italic;">PTIT VN</span>, 2003..</big></li></ul>
<big>
</big><font size="5"><span style="font-weight: bold;"></span></font><font style="font-weight: bold;" size="5"><a name="TalksTutorials"></a>Talks/Tutorials<br>
</font>
<ul><li><a href="https://www.dropbox.com/scl/fi/qxkfgpij1p76n2mlulmqi/DL-2023-TT-Truyen.pdf?rlkey=upma73p6iiriv2y6snps9aeyq&amp;dl=0"><font size="+1"><span style="text-decoration: underline;">Deep
learning and reasoning: Recent advances</span></font></a><big>,
Tutorial @<span style="font-style: italic;">VIASM Summer
School in DL</span>, July 2023.</big></li><li><font size="+1"><a href="https://www.dropbox.com/scl/fi/jqy6ed197l8rqoszscf72/deep-analytics-v2.pdf?rlkey=s5wwbyagrekum8sralxs5zpkx&amp;dl=0"><span style="text-decoration: underline;">Deep analytics via
learning to reason</span></a></font><big>
Keynote @<span style="font-style: italic;">ACOMPA</span>,
Nov 2022.</big></li><li><font size="+1"><a href="https://neuralreasoning.github.io/"><span style="text-decoration: underline;">Neural machine reasoning</span></a></font><big>
A tutorial @<span style="font-style: italic;">IJCAI</span>,
August 2021.</big></li><li><font size="+1"><a href="https://www.slideshare.net/truyen/deep-learning-20-250013746"><span style="text-decoration: underline;">Deep learning 2.0</span></a></font><big>
Keynote @<span style="font-style: italic;">FPT AI
Conference</span>, August 2021.</big></li><li><font size="+1"><a href="kdd2021-tute.html"><span style="text-decoration: underline;">From deep learning to
deep reasoning</span></a></font><big> A
tutorial @<span style="font-style: italic;">KDD</span>,
August 2021.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="ssci2020-tute.html">Deep learning 1.0 and beyond</a>,
<a href="http://www.ieeessci2020.org/program.html">A
tutorial</a> @<span style="font-style: italic;">IEEE
SSCI</span>,
Canberra, Dec 2020.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="https://www.slideshare.net/truyen/machine-reasoning">Machine
reasoning</a>, @<span style="font-style: italic;">Monash
University</span>,
August 2020.</big></li><li><big><a href="https://www.slideshare.net/truyen/machine-reasoning-at-a2i2-deakin-university">Machine
reasoning at A2I2</a>, @<span style="font-style: italic;">A2I2
reading
group</span>, April 2020.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="https://truyentran.github.io/talks/visual-reasoning.pdf">Machines
that learn to talk about what they see</a>, <span style="font-style: italic;">Keynote at NICS'19</span>,
Hanoi, Vietnam, Dec 2019.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="https://truyentran.github.io/talks/VinAI-NTM-June-2019.pdf"><span style="text-decoration: underline;">Memory advances in
Neural Turing
Machines</span></a>,<span style="font-style: italic;">
<a href="https://www.facebook.com/events/2494442860621824/permalink/2508856739180436/">AI
Day</a>,</span> Hanoi, Vietnam, June 2019.</big></li><li><big><a href="https://truyentran.github.io/talks/ML2019.pdf" target="_blank">Empirical AI Research</a> , @<span style="font-style: italic;">International University</span>,
HCM City,
Vietnam, May 2019.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="https://truyentran.github.io/talks/mapr-graph-keynote.pdf">Representation
learning on graphs</a>, <a style="font-style: italic;" href="https://mapr2019.uit.edu.vn/keynote-speakers">Keynote
at MAPR</a>,
HCM City, Vietnam, May 2019.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="http://truyentran.github.io/talks/NTM++.pdf"><span style="text-decoration: underline;">Advances in Neural
Turing Machines</span></a>, <span style="font-style: italic;">@CafeDSL</span>,&nbsp;<span style="font-style: italic;">University of Wollongong</span>,
Aug 2018.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><a href="talks/Deep-anomaly-Jan-2017.pdf">Deep
learning for detecting anomalies and software vulnerabilities</a>,
@<span style="font-style: italic;">ACT</span>,
Hanoi, Jan 2017.</big></li><li><big><a href="talks/Deep-arc-en-Jan-2017.pdf">Deep
architecture engineering</a>, <span style="font-style: italic;">@HUST &amp; </span><span style="font-style: italic;">VNU-UET</span>, Hanoi, Jan
2017.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><span style="text-decoration: underline;">Deep learning</span>,
@WEHI, Melbourne, Dec 2016.</big></li><li><font size="+1"><span style="font-weight: bold;"></span></font><big><span style="text-decoration: underline;">Deep learning tutorials
at</span> <a style="font-style: italic;" href="ausdm16-tute.html">AusDM'16</a>
in Canberra, <a style="font-style: italic;" href="ai16-tute.html">AI'16</a>
in Hobart.</big></li><li><big><a href="https://truyentran.github.io/talks/Talk-DSL-UoW-deep-learning-noncognitive.pdf"><span style="text-decoration: underline;">Deep learning for
non-cognitive
domains</span></a>,<span style="font-style: italic;">
@DSL, University
of Wollongong</span>, Aug 2016.</big></li></ul><font style="font-weight: bold;" size="5"><a name="Popular_writings"></a>Popular writings<br>
</font>
<ul><li><big><a href="https://medium.com/@tranthetruyen/the-dynamics-of-knowledge-99536b84092a">The
dynamics of knowledge</a>, <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">Medium</span>,
October 2024.<span style="text-decoration: underline;"><br>
</span></big></li><li><font size="+1"><a href="https://medium.com/@tranthetruyen/a-i-development-and-education-2348f219ef9b">AI development and education</a></font><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Medium</span>,&nbsp;</big><font size="+1">Sep </font><font size="+1">2024.</font></li><li><font size="+1"><a href="https://medium.com/@tranthetruyen/the-shifting-landscape-of-modern-ai-df1c114383cb"><span style="text-decoration: underline;">The shifting landscape
of modern AI</span></a></font><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Medium</span>,&nbsp;</big><font size="+1">Aug 2024.</font>&nbsp;</li><li><big><a href="https://medium.com/@tranthetruyen/ai-math-medicine-software-and-the-sciences-a-shifting-landscape-f32cea698e6f">AI,
math, medicine, software, and the sciences</a>,
</big><big><span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">Medium</span>,
August 2024.&nbsp;</big></li><li><font size="+1"><a href="https://medium.com/@tranthetruyen/ai-be-careful-what-you-wish-for-or-even-the-rich-cry-april-2023-2f04eec0d448">AI: Be careful what you wish for, or even the rich cry</a></font><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Medium</span>,&nbsp;</big><font size="+1">April 2023.</font></li><li><font size="+1"><a href="https://medium.com/@tranthetruyen/very-big-text-models-915435ad8f0d">Very big text models</a></font><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Medium</span>,&nbsp;</big><font size="+1">Feb 2023.</font></li><li><a href="https://medium.com/@tranthetruyen/on-expressiveness-learnability-and-generalizability-of-deep-learning-4cd2fe3d29b7"><font size="+1">On expressiveness, learnability and generalizability of deep learning</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1">Jan 2017.</font></li><li><a href="https://medium.com/@tranthetruyen/making-a-dent-in-ai-or-how-to-play-a-fast-ball-game-f56f55e4773c"><font size="+1">Making a dent in AI, or how to play a fast ball game</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1">Dec 2016.</font></li><li><a href="https://medium.com/@tranthetruyen/30-years-of-a-swiss-army-knife-restricted-boltzmann-machines-beaeb93d99ca"><font size="+1">RBMs: A brief 30 year history of a Swiss army knife</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1">Dec 2016.</font></li><li><a href="https://medium.com/@tranthetruyen/machine-learning-in-three-lines-3d405931588e"><font size="+1">Machine learning in three lines</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"> </font><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1"> Dec 2016.</font></li><li><a href="https://medium.com/@tranthetruyen/machine-learning-four-years-after-the-turning-point-5a3bcd86d7b7"><font size="+1">Machine learning: Four years after the turning point</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span>, </big><font size="+1"></font><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1"> Dec 2016.</font></li><li><a href="https://medium.com/@tranthetruyen/machine-learning-in-2012-at-its-turning-point-non-convexity-7929ec9f0ff2"><font size="+1">Machine learning at its turning point: Non-convexity</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span></big><big>, </big><font size="+1"></font><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1">May 2012.</font></li><li><a href="https://medium.com/@tranthetruyen/data-size-still-matters-dea7b4f16abf"><font size="+1">Data size matters</font></a><font size="+1">,&nbsp;</font><big><span style="font-weight: bold;">Truyen
Tran</span></big><big>, </big><big><span style="font-style: italic;">Blogger</span>, </big><font size="+1">Aug 2008.</font></li></ul><font style="font-weight: bold;" size="5"><a name="Preprints"></a>Preprints<br>
</font>
<ul>
<li><big><a href="https://arxiv.org/abs/1702.07021"><span style="text-decoration: underline;">On size fit many: Column
bundle
for multi-X learning</span></a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;">&nbsp;</span><span style="font-style: italic;">arXiv
preprint arXiv</span>: <span style="font-style: italic;">1702.07021</span>.</big></li>
<li><big><span style="font-style: italic;">
</span><a href="https://arxiv.org/abs/1703.01454">Learning
deep
matrix
representations</a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1703.01454.</span></big></li>
<li><big><span style="font-style: italic;">
</span><a href="https://arxiv.org/abs/1808.04247">Relational
dynamic
memory
networks</a>, Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;Svetha
Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1808.04247.</span></big></li>
<li><big><span style="font-style: italic;">
</span><a href="https://arxiv.org/abs/2011.10094">Logically
consistent loss for
visual question answering</a>, Anh-Cat Le-Ngo, <span style="font-weight: bold;">Truyen Tran</span>, Santu
Sana, Sunil
Gupta, Svetha Venkatesh,<span style="font-style: italic;">
arXiv
preprint arXiv:2011.10094.</span></big></li>
</ul>
<ol>
</ol>
<p align="justify"><font style="font-weight: bold;" size="5">Publications</font><font size="5"><a name="Publications"></a></font></p>
<ul>
<li><big><a href="https://arxiv.org/abs/2411.06781">MP-PINN: A
Multi-Phase Physics-Informed Neural Network for epidemic forecasting</a>,
</big><big>Thang Nguyen, Dung Nguyen, Kha Pham, <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">AusDM'24</span>.</big></li>
<li><big><span style="text-decoration: underline;">Promptable iterative
visual refinement for video instance segmentation</span>, </big><big>Tuyen
Tran, Thao Minh Le, <span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">ECCV WS on IRL</span>,
2024.</big></li>
<li><big><a href="https://arxiv.org/abs/2409.02385">Unified
compositional query machine with multimodal consistency for video-based
human activity recognition</a>, </big><big>Tuyen
Tran, Thao Minh Le, Duy Hung Tran, <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;<span style="font-style: italic;">BMVC'24</span>.</big></li>
<li><big><a href="https://arxiv.org/abs/2402.03577">Revisiting the
dataset bias problem from a statistical perspective</a>, </big><big>Do,
Kien, Dung Nguyen, Hung Le, Thao Le, Dang Nguyen, Haripriya Harikumar, <span style="font-weight: bold;">Truyen Tran</span>, Santu
Rana, and Svetha Venkatesh, <span style="font-style: italic;">ECAI'24</span>.</big></li>
<li><big><a href="https://www.ijcai.org/proceedings/2024/19">Diversifying
training pool predictability for zero-shot coordination: A theory of
mind approach</a>, </big><big>Dung Nguyen, Hung Le,
Kien Do, Svetha Venkatesh, <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;</big><big><span style="font-style: italic;">IJCAI</span>, 2024.</big></li>
<li><big><a href="https://arxiv.org/abs/2312.11818">Root cause
explanation of outliers under noisy mechanisms</a>, Phuoc Nguyen,
<span style="font-weight: bold;">Truyen Tran</span>,
Sunil Gupta, Thin Nguyen, SvethaVenkatesh, <span style="font-style: italic;">AAAI'2</span>4.&nbsp;</big></li>
<li><big><a href="https://openreview.net/forum?id=dJuDv4MKLE">Hierarchical
GFlowNet for crystal structure generation</a>, </big><big>Nguyen,
Tri, Sherif Tawfik, <span style="font-weight: bold;">Truyen
Tran</span>, Sunil Gupta, Santu Rana, and Svetha Venkatesh. In <span style="font-style: italic;">AI for Accelerated Materials
Design-NeurIPS 2023 Workshop</span>. 2023.</big></li>
<li><big><a href="https://ieeexplore.ieee.org/abstract/document/10272656">Dynamic
reasoning for Movie QA: A character-centric approach</a>, Long
Hoang Dang, Thao Minh Le, Vuong Le, Tu Minh Phuong, <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">IEEE Transactions on Multimedia</span>,
2023.</big></li>
<li><big><a href="https://www.sciencedirect.com/science/article/pii/S0004370223001674">Balanced
Q-learning: Combining the influence of optimistic and pessimistic
targets</a>, Thommen George Karimpanal, Hung Le, Majid Abdolshah,
Santu Rana, Sunil Gupta, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">Artificial Intelligence</span>,
2023.<br>
</big></li>
<li><big><a href="https://www.computer.org/csdl/proceedings-article/iccv/2023/071800j824/1TJkFJHq8Xm"><span style="text-decoration: underline;">Persistent-transient
duality: A multi-mechanism approach for modeling human-object
interaction</span></a>, </big><big>Hung Tran,
Vuong Le, Svetha Venkatesh, <span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">ICCV'23</span>.</big></li>
<li><big><span style="text-decoration: underline;">Compositional prompting
with successive decomposition for multimodal language models</span>,
</big><big>Long Hoang Dang, Thao Minh Le, Tu Minh
Phuong and <span style="font-weight: bold;">Truyen Tran</span>,
</big><big><span style="font-style: italic;">KDD'23
workshop on LLM4AI: Theories and Applications in Large-scale AI Models,
2023</span>.</big></li>
<li><big><a href="https://www.ijcai.org/proceedings/2023/454"><span style="text-decoration: underline;">Social motivation for
modelling other agents under partial observability in decentralised
training</span></a>, </big><big>Dung Nguyen,
Hung Le, Kien Do, Svetha Venkatesh, <span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">IJCAI</span>, 2023.<br>
</big></li>
<li><big><a href="https://openreview.net/forum?id=0f-0I6RFAch">Improving
out-of-distribution generalization with indirection representations</a>,
Pham, Kha, Hung Le, Man Ngo, and <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">ICLR'23</span>.</big></li>
<li><big><a href="https://arxiv.org/abs/2301.06926">Memory-augmented
theory of mind network</a>, Nguyen, Dung, Phuoc Nguyen, Hung Le,
Kien Do, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">AAAI'23</span>.</big></li>
<li><big><a href="https://openaccess.thecvf.com/content/WACV2023/html/Le_Guiding_Visual_Question_Answering_With_Attention_Priors_WACV_2023_paper.html">Guiding
visual question answering with attention priors</a>, Le, Thao
Minh, Vuong Le, Sunil Gupta, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">WACV'23</span>.</big></li>
<li><big><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/41128e5b3a7622da5b17588757599077-Abstract-Conference.html">Momentum
adversarial distillation: Handling large
distribution shifts in data-free knowledge distillation</a>, Do,
Kien, Thai
Hung Le, Dung Nguyen, Dang Nguyen, Haripriya Harikumar, <span style="font-weight: bold;">Truyen Tran</span>, Santu
Rana, and Svetha Venkatesh, <span style="font-style: italic;">NeurIPS'22</span>.</big></li>
<li><big><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/13b8d8fb8d05369480c2c344f2ce3f25-Abstract-Conference.html">Functional
indirection neural estimator for better out-of-distribution
generalization</a>, Pham, Kha, Thai Hung Le, Man Ngo, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">NeurIPS'22</span>.</big></li>
<li><big><a href="https://openreview.net/forum?id=NXnSr_uXgh">Time-evolving
conditional character-centric graphs for movie understanding</a>,
</big><big>Long Hoang Dang, Thao Minh Le, Vuong
Le, Tu-Minh Phuong, and <span style="font-weight: bold;">Truyen
Tran</span>, </big><big><span style="font-style: italic;">NeurIPS 2022 Temporal Graph
Learning Workshop</span>.<br>
</big></li>
<li><big><a href="https://link.springer.com/chapter/10.1007/978-3-031-19842-7_41">Video
dialog as conversation about objects living in space-time</a>,
Pham, Hoang-Anh, Thao Minh Le, Vuong Le, Tu Minh Phuong, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">ECCV'22</span>.</big></li>
<li><big><a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_17">Towards
effective and robust neural Trojan defenses via input filtering</a>,
Do, Kien, Haripriya Harikumar, Hung Le, Dung Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Santu
Rana, Dang Nguyen, Willy Susilo, and Svetha Venkatesh. <span style="font-style: italic;">ECCV'22</span>.</big></li>
<li><big><a href="https://arxiv.org/abs/2204.12937">Learning to
transfer role assignment across team sizes</a>,&nbsp;</big>
<big>Dung
Nguyen, Phuoc Nguyen, Svetha Venkatesh, <b>Truyen Tran</b>,
<em>AAMAS</em>,
2022.</big></li>
<li><big><a href="https://arxiv.org/abs/2204.09047">Learning
theory of mind via dynamic traits attribution</a>, </big><big>Dung
Nguyen, Phuoc Nguyen, Hung Le, Kien Do, Svetha Venkatesh, <b>Truyen
Tran</b>, <em>AAMAS</em>, 2022.&nbsp;</big></li>
<li><big><a href="https://arxiv.org/abs/2111.02104"><span style="text-decoration: underline;">Model-based episodic
memory
induces dynamic hybrid controls</span></a>, </big><big>Hung
Le,
Thommen K George, Majid Abdolshah, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">NeurIPS'21</span>.</big></li>
<li><big><a href="https://link.springer.com/chapter/10.1007/978-3-030-91431-8_2"><span style="text-decoration: underline;">DeepProcess: Supporting
business
process execution using a MANN-based recommender system</span></a>,
</big><big>Asjad
Khan, Aditya Ghose, Hoa Dam, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Kien Do, <span style="font-style: italic;">ICSOC'21</span>.</big></li>
<li><big><a href="https://dl.acm.org/doi/abs/10.1145/3447548.3470803">From
deep
learning to deep reasoning</a>, Truyen Tran, Vuong Le, Hung Le,
Thao
Le, <span style="font-style: italic;">KDD</span>,
2021.</big><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_366.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_366.pdf"><span style="text-decoration: underline;">Knowledge distillation
with
distribution mismatch</span></a>, D Nguyen, S Gupta, T
Nguyen, S Sana,
P Nguyen, <span style="font-weight: bold;">T Tran</span>,
KL Le, S
Ryan, ... <span style="font-style: italic;">ECML-PKDD'21</span>,
2021<a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_529.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_529.pdf"><span style="text-decoration: underline;">Fast conditional network
compression using Bayesian HyperNetworks</span></a>, P
Nguyen, <span style="font-weight: bold;">T Tran</span>,
KL Le, S Gupta, S Sana, D
Nguyen, T Nguyen, S Ryan, ... <span style="font-style: italic;">ECML-PKDD'21</span>,
2021<a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_659.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_659.pdf"><span style="text-decoration: underline;">Variational
hyper-encoding networks</span></a>,
P Nguyen, <span style="font-weight: bold;">T Tran</span>,
S Gupta, S
Rana, HC Dam, S Venkatesh, <span style="font-style: italic;">ECML-PKDD'21</span>,
2021</big></li>
<li><big><a href="https://arxiv.org/abs/2010.10019">Hierarchical
conditional relation networks for multimodal video question answering</a>,
TM Le, V Le, S Venkatesh, <span style="font-weight: bold;">T
Tran</span>, <span style="font-style: italic;">International
Journal of
Computer Vision</span>, 2021<a href="https://arxiv.org/abs/2106.13432"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/2106.13432"><span style="text-decoration: underline;">Hierarchical
object-oriented
spatio-temporal reasoning for video question answering</span></a>,
LH
Dang, TM Le, V Le, <span style="font-weight: bold;">T Tran</span>,
<span style="font-style: italic;">IJCAI'21</span></big></li>
<li><big><a href="https://arxiv.org/abs/2104.05166">Object-centric
representation learning for video question answering</a> Long
Hoang
Dang, Thao Minh Le, Vuong Le, <span style="font-weight: bold;">Truyen
Tran</span><span style="font-style: italic;">,
IJCNN'21.&nbsp;</span></big></li>
<li><big><a href="https://arxiv.org/abs/2103.02758">Learning
asynchronous and sparse human-object interaction in videos</a>
Romero
Morais, Vuong Le, Svetha Vekatesh, <span style="font-weight: bold;">Truyen
Tran</span><span style="font-style: italic;">,
CVPR'21.&nbsp;</span></big></li>
<li><big><a href="https://arxiv.org/abs/2011.02751">Goal-driven
long-term trajectory prediction</a>, Hung Tran, Vuong Le, <span style="font-weight: bold;">Truyen Tran</span><span style="font-style: italic;">, WACV'21.&nbsp;</span></big></li>
<li><big><a href="https://link.springer.com/article/10.1007/s10664-020-09898-5">Automatically
recommending components for issue reports using deep learning</a>,
Morakot Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Trang Pham, Chaiyong Ragkhitwetsagul &amp;
Aditya Ghose <span style="font-style: italic;">,
Empirical Software Engineering</span>
volume 26, Article number: 14 (2021).</big><big><span style="font-style: italic;"></span></big></li>
<li><big><a href="http://arxiv.org/abs/2012.01793">Semi-supervised
learning with variational Bayesian inference and maximum uncertainty
regularization</a>, </big><big>Kien Do, <span style="font-weight: bold;">Truyen Tran</span> and
Svetha Venkatesh,</big><big>&nbsp;<span style="font-style: italic;"> AAAI'21.</span></big>
<br>
<big><span style="font-style: italic;"> </span></big></li>
<li><big><a href="https://arxiv.org/abs/2011.00754">Toward a
generalization metric for deep generative models</a>, Thanh-Tung,
Hoang, and <span style="font-weight: bold;">Truyen Tran</span>.<span style="font-style: italic;"> NeurNIPS 2020 1st Workshop on I
Can’t
Believe It’s Not Better.</span></big></li>
<li><big><a href="https://arxiv.org/abs/2009.12146">GEFA: Early
Fusion Approach in Drug-Target Affinity Prediction</a>, Tri Minh
Nguyen, Thin Nguyen, Thao Minh Le, <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">Machine
Learning for
Structural Biology (MLSB) Workshop at NeurIPS 2020.</span></big></li>
<li><big><a href="https://arxiv.org/abs/2005.08482">HyperVAE: A
minimum description length variational hyper-encoding network</a>,
Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Sunil Gupta, Santu Rana, Hieu-Chi Dam, Svetha Venkatesh<span style="font-style: italic;">, NeurIPS 2020 Workshop on
Meta-Learning</span></big></li>
<li><big><a href="https://arxiv.org/abs/2009.09443">Unsupervised
anomaly detection on temporal multiway data</a>, Duc Nguyen,
Phuoc
Nguyen, Kien Do, Santu Rana, Sunil Gupta, <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">2020 IEEE Symposium Series on
Computational Intelligence (SSCI) (SSCI 2020).</span></big></li>
<li><big><a href="https://arxiv.org/abs/2009.07445">Theory of
mind with guilt aversion facilitates cooperative reinforcement learning</a>,
<span style="font-style: italic;"></span>Dung
Nguyen, Svetha
Venkatesh, Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">ACML'20</span>.</big></li>
<li><big><a href="https://arxiv.org/abs/2008.09234">Learning to
abstract and predict human actions</a>, <span style="font-style: italic;"></span>Romero Morais,
Vuong Le, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">BMVC'20</span>.</big><big><span style="text-decoration: underline;"></span></big></li>
<li><big><span style="text-decoration: underline;">Object-centric
relational reasoning for video question answering</span>, <span style="font-style: italic;"></span>Long Hoang Dang,
Thao Minh Le,
Vuong Le, <span style="font-weight: bold;">Truyen Tran</span>,
<span style="font-style: italic;">The ECCV 2nd
Workshop on Video Turing
Test: Toward Human-Level Video Story Understanding, August 2020</span>.</big></li>
<li><big><a href="https://www.biorxiv.org/content/10.1101/686394v1.abstract">Deep
in the bowel: Highly interpretable neural encoder-decoder networks
predict gut metabolites from gut microbiome</a>, <span style="font-style: italic;"></span>V Le, TP Quinn, <span style="font-weight: bold;">T Tran</span>, S Venkatesh,
<span style="font-style: italic;">BMC Genomics
(21)</span>, 07/2020.</big></li>
<li><big><a href="https://arxiv.org/abs/2002.03519">Self-attentive
associative memory</a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh<span style="font-style: italic;">,
ICML'20</span><span style="font-style: italic;">.</span></big><big><a href="https://arxiv.org/abs/2004.14603"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/2004.14603"><span style="text-decoration: underline;">Dynamic language binding
in
relational visual reasoning</span></a>, Thao Minh Le, Vuong
Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen
Tran</span>,<span style="font-style: italic;"> </span><span style="font-style: italic;">
IJCAI'20</span>, July 11-17, Yokohama, Japan.<br>
<a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;">Neural reasoning, fast
and slow,
for video question answering</span></a>, Thao Minh Le,
Vuong Le, Svetha
Venkatesh, and <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">IJCNN'20</span><br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1909.04307">Learning
transferable
domain priors for safe exploration in reinforcement learning</a><span style="font-style: italic;"></span>, Thommen G
Karimpanal, Santu Rana,
Sunil Gupta, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">,
IJCNN'20</span><br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1807.04015">On
catastrophic
forgetting and mode collapse in Generative Adversarial Networks</a>,
Thanh-Tung, Hoang, and <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">IJCNN'20</span><br>
<a href="https://arxiv.org/abs/2002.10698"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/2002.10698"><span style="text-decoration: underline;">Hierarchical conditional
relation
networks for video question answering</span></a>, Thao Minh
Le, Vuong
Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;<span style="font-style: italic;">CVPR'20.</span><br>
<a href="https://baicsworkshop.github.io/pdf/BAICS_28.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://baicsworkshop.github.io/pdf/BAICS_28.pdf"><span style="text-decoration: underline;">Theory of mind with
guilt aversion
facilitates cooperative reinforcement learning</span></a>,
Dung Nguyen,
Truyen Tran, Svetha Venkatesh,<span style="font-style: italic;">
</span><span style="font-style: italic;">ICLR
2020 workshop on Bridging AI and
Cognitive Science</span>, April 26-30, Addis Ababa, Ethiopia. <span style="font-style: italic;"></span><br>
<span style="font-style: italic;"> </span></big></li>
<li><big><a href="https://arxiv.org/abs/1906.08862">Neural
stored-program memory</a>,
Hung Le, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha
Venkatesh<span style="font-style: italic;">, ICLR'20.</span><br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1908.09961">Theory and
evaluation
metrics for learning disentangled representations</a>, K Do, <span style="font-weight: bold;">T Tran</span><span style="font-style: italic;">, ICLR'20.</span><br>
</big></li>
<li><big><a href="https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-020-0658-5">DeepTRIAGE:
Interpretable and individualised biomarker scores using attention
mechanism for the classification of breast cancer sub-types</a>,
Adham
Beykikhoshk, Thom P Quinn, Sam C Lee, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,<span style="font-style: italic;">
B</span><span style="font-style: italic;">MC Medical
Genomics, 2020</span><span style="font-style: italic;">MC
Medical Genomics, 2020</span> <br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1812.09441">Graph
transformation
policy
network for chemical reaction prediction</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;">KDD'19</span>.<br>
<a href="https://arxiv.org/abs/1903.03295"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/1903.03295"><span style="text-decoration: underline;">Learning regularity in
skeleton
trajectories for anomaly detection in videos</span></a>,
Romero Morais,
Vuong Le, Budhaditya Saha, <span style="font-weight: bold;">Truyen
Tran</span>,
Moussa Reda Mansour, Svetha Venkatesh, <span style="font-style: italic;">CVPR'19</span>.<br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1802.00921">Lessons
learned from using a deep tree-based model for software defect
prediction in practice</a>, Hoa Khanh Dam, Trang Pham, Shien Wee
Ng, <span style="font-weight: bold;">Truyen Tran</span>,
John Grundy, Aditya
Ghose, Taeksu Kim, Chul-Joo Kim, <span style="font-style: italic;">MSR'19.</span><br>
<a href="https://openreview.net/forum?id=r1xlvi0qYm"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://openreview.net/forum?id=r1xlvi0qYm"><span style="text-decoration: underline;">Learning to remember
more with
less memorization</span></a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.<br>
<a href="https://openreview.net/forum?id=ByxPYjC5KQ"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://openreview.net/forum?id=ByxPYjC5KQ"><span style="text-decoration: underline;">Improving generalization
and
stability of Generative Adversarial Networks</span></a>,
Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.<br>
<a href="https://arxiv.org/abs/1811.06060"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/1811.06060"><span style="text-decoration: underline;">Incomplete conditional
density
estimation for fast materials discovery</span></a>, Phuoc
Nguyen,
Truyen Tran,&nbsp;Sunil
Gupta, Svetha Venkatesh. <span style="font-style: italic;"></span><span style="font-style: italic;">SDM'19</span>. <br>
</big></li>
<li><big><a href="https://truyentran.github.io/papers/main-CCI.pdf">Neural
reasoning for chemical-chemical interaction</a>.&nbsp;Trang
Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">NIPS
2018 Workshop
on Machine
Learning for
Molecules and Materials</span>. <br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1804.00293">Attentional
multilabel
learning over graphs: A message passing approach</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Thin
Nguyen,
SvethaVenkatesh,&nbsp;<span style="font-style: italic;">Machine
Learning, 2019.</span><br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1708.02368">Automatic
feature
learning for
predicting vulnerable software components</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang
Pham, &nbsp;Shien
Wee Ng, John Grundy, Aditya Ghose,<span style="font-style: italic;">
IEEE Transactions on Software Engineering, </span>2019.<br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1807.09950">Variational
memory
encoder-decoder,</a> Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Thin Nguyen, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">NIPS'18.</span><br>
</big></li>
<li><big><a href="https://arxiv.org/abs/1802.00662">Dual Memory
Neural
Computer
for Asynchronous Two-view Sequential Learning</a>, Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, S vetha
Venkatesh, <span style="font-style: italic;">KDD'18.</span><br>
<a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;">On catastrophic
forgetting and
mode collapse in Generative Adversarial Networks</span></a>,
Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">; ICML
Workshop on Theoretical Foundations
and Applications of Deep Generative Models</span>, 2018<span style="font-style: italic;">.</span><br>
<span style="font-style: italic;"> </span></big></li>
<li><big><a href="https://arxiv.org/abs/1801.02622">Graph
Memory Networks for Molecular Activity Prediction</a>,&nbsp;Trang
Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICPR'18</span>.&nbsp;<br>
</big> </li>
<li><big><a href="https://arxiv.org/abs/1801.08641">Knowledge
Graph
Embedding with
Multiple Relation Projections</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh,&nbsp;<span style="font-style: italic;">ICPR'18.</span></big></li>
<li><big> <a href="https://arxiv.org/abs/1802.00948">Resset:
A Recurrent Model for Sequence of Sets with Applications to Electronic
Medical Records</a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">,
IJCNN'18.</span></big></li>
<li><big> <a href="https://arxiv.org/abs/1802.03689">Dual
control memory
augmented neural networks for treatment
recommendations</a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">PAKDD'18</span>.<span style="font-style: italic;"> </span></big></li>
<li><big> <a href="https://dl.acm.org/citation.cfm?id=3194952"><span style="text-decoration: underline;">Predicting
components for issue reports using deep learning with information
retrieval</span></a>, Morakot Choetkiertikul, Hoa Khanh
Dam, <span style="font-weight: bold;">Truyen Tran</span>,
Trang Pham, Aditya
Ghose, <span style="font-style: italic;">International
Conference on Software
Engineering (ICSE'18) - Poster Track</span><span style="font-style: italic;"></span></big></li>
<li><big> <a href="https://truyentran.github.io/papers/outlier_kais17.pdf"><span style="text-decoration: underline;">Energy-Based Anomaly
Detection for
Mixed Data</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">Knowledge
and Information Systems</span>, 2018.&nbsp;Earlier
works are: </big></li>
<li><big> <a href="https://arxiv.org/abs/1610.06249">Multilevel
Anomaly Detection for Mixed Data</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;"></span><span style="font-style: italic;">arXiv
preprint arXiv</span>: <span style="font-style: italic;">1610.06249</span>.</big></li>
<li><big> <a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien
Do, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
<li><big> <a href="http://arxiv.org/abs/1609.00489">A
deep learning model for estimating story points</a>, Morakot
Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Trang Pham, Aditya Ghose, Tim Menzies, <span style="font-style: italic;">IEEE Transactions on Software
Engineering,
2018.</span></big></li>
<li><big> <a href="https://truyentran.github.io/papers/nips17-ml4h.pdf"><span style="text-decoration: underline;">Finding Algebraic
Structure of
Care in Time: A Deep Learning Approach</span></a>, Phuoc
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">NIPS
Workshop on Machine Learning for
Health (ML4H)</span>.</big></li>
<li><big> <a href="https://arxiv.org/abs/1708.04357"><span style="text-decoration: underline;">Graph Classification via
Deep
Learning with Virtual Nodes</span></a> Trang Pham, <span style="text-decoration: underline;"></span><span style="font-weight: bold;">Truyen Tran</span>, Hoa
Dam, Svetha
Venkatesh, <span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiG 2017)</span>.</big></li>
<li><big> <a href="https://arxiv.org/abs/1707.05010"><span style="text-decoration: underline;">Deep Learning to Attend
to Risk in
ICU</span></a>,&nbsp;Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">IJCAI'17
Workshop on Knowledge Discovery in Healthcare II: Towards Learning
Healthcare Systems</span> <span style="font-style: italic;">(KDH
2017</span>).<span style="text-decoration: underline;"></span><span style="text-decoration: underline;"></span></big></li>
<li><big> <a href="https://arxiv.org/abs/1703.01454"><span style="text-decoration: underline;">Learning Recurrent
Matrix
Representation</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;"> </span><span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiF 2017)</span></big></li>
<li><big> <a href="https://www.researchgate.net/profile/Truyen_Tran/publication/314024495_Hierarchical_semi-Markov_conditional_random_fields_for_deep_recursive_sequential_data/links/5a585845a6fdccf0ad1a4ce9/Hierarchical-semi-Markov-conditional-random-fields-for-deep-recursive-sequential-data.pdf"><span style="text-decoration: underline;">Hierarchical semi-Markov
conditional random fields for deep recursive sequential data</span></a>,
<span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Hung Bui, Svetha Venkatesh, &nbsp;<span style="font-style: italic;">Artificial Intelligence</span>,
Volume 246, May 2017, Pages 53–85.&nbsp;(Extension of the <a href="https://truyentran.github.io/papers/truyen_nips08.pdf">NIPS'08
paper</a>).</big></li>
<li><big> <a href="http://www.sciencedirect.com/science/article/pii/S1532046417300710">Predicting
healthcare trajectories from medical records: A deep learning approach</a>,Trang
Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">Journal
of
Biomedical Informatics</span>, April 2017, DOI:
10.1016/j.jbi.2017.04.001. [<a href="http://arxiv.org/abs/1602.00357">Tech
report PDF</a>].</big></li>
<li><big> <a href="http://arxiv.org/abs/1607.07519"><span style="text-decoration: underline;">Deepr: A Convolutional
Net for Medical Records</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Nilmini
Wickramasinghe, Svetha Venkatesh,&nbsp;&nbsp;<span style="font-style: italic;">IEEE Journal of Biomedical
and
Health Informatics</span>,&nbsp;vol.
21, no. 1, pp. 22–30, Jan. 2017, Doi: 10.1109/JBHI.2016.2633963.</big></li>
<li><big> <a href="https://arxiv.org/abs/1609.04508">Column
Networks for Collective Classification</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha
Venkatesh, <span style="font-style: italic;"></span><span style="font-style: italic;">AAAI'17</span></big></li>
<li><big> <a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien
Do, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
<li><big> <a href="https://arxiv.org/abs/1609.08752"><span style="text-decoration: underline;">Stabilizing Linear
Prediction Models using Autoencoder</span></a>, Shivapratap
Gopakumara, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh, <span style="font-style: italic;">International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
<li><big> <a href="http://arxiv.org/abs/1608.02715">A
deep language model for software code</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span> and
Trang Pham, <span style="font-style: italic;">FSE NL+SE
2016</span>.</big></li>
<li><big> <a href="http://arxiv.org/abs/1608.00092">DeepSoft:
A vision for a deep model of software</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, John
Grundy and Aditya Ghose, <span style="font-style: italic;">FSE
VaR</span> 2016.<a href="https://truyentran.github.io/papers/deepr.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big> <a href="https://truyentran.github.io/papers/flexible_gating.pdf">Faster
Training of Very Deep Networks Via p-Norm Gates</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">ICPR'16</span>.</big></li>
<li><big> <a href="http://arxiv.org/abs/1602.00357">DeepCare:
A Deep Dynamic Memory Model for Predictive Medicine</a>, Trang
Pham,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh,<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD'16</span>, Auckland,
NZ, April 2016.&nbsp;</big></li>
<li><big> <a href="https://truyentran.github.io/papers/bdm16.pdf">Neural
Choice by Elimination via Highway Networks</a>,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung and Svetha Venkatesh,&nbsp;<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD workshop on Biologically
Inspired Techniques for Data Mining (BDM'16)</span><span class="Apple-converted-space"></span>, April 19-22
2016, Auckland, NZ.</big></li>
<li><big> <a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X"><span style="text-decoration: underline;">Graph-induced restricted
Boltzmann machines for document modeling</span></a>, Tu
Dinh
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Information
Sciences</span><span style="font-style: italic;">.
doi:10.1016/j.ins.2015.08.023.</span> </big></li>
<li><big> <a href="http://www.uow.edu.au/%7Ehoa/papers/ASE2015-preprint-choetkiertikul-dam-tran-ghose.pdf"><span style="text-decoration: underline;">Predicting delays in
software projects using networked classification</span></a>,
Morakot Choetikertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Aditya
Ghose,<span style="font-style: italic;"> 30th IEEE/ACM
International Conference on Automated Software Engineering</span>,
November 9–13, 2015 Lincoln, Nebraska, USA.</big></li>
<li><big> <a href="http://www.sciencedirect.com/science/article/pii/S1532046415000143">Learning
vector
representation of medical objects via EMR-driven nonnegative restricted
Boltzmann machines (e-NRBM)</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Tu
Dinh Nguyen, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Biomedical Informatics</span>, 2015, pii:
S1532-0464(15)00014-3. doi: 10.1016/j.jbi.2015.01.012.&nbsp;</big></li>
<li><big> <a href="https://truyentran.github.io/papers/aaai15_main.pdf">Tensor-variate
Restricted Boltzmann Machines</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">AAAI</span>
2015.&nbsp;</big></li>
<li><big> <a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">Thurstonian
Boltzmann machines: Learning from multiple inequalities</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of
30th
International Conference in Machine Learning (ICML’13)</span>,
Atlanta, USA, June, 2013.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Learning
parts-based representations with Nonnegative Restricted Boltzmann
Machine</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Machine Learning Research (JMLR) Workshop and Conference
Proceedings, Vol. 29, Proc. of 5th Asian Conference on Machine
Learning,</span> Nov 2013.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Latent
patient profile modelling and
applications with Mixed-Variate Restricted Boltzmann Machine</a>,
Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh,&nbsp; In<span style="font-style: italic;">
Proc. of 17th
Pacific-Asia Conference on Knowledge Discovery and Data Mining
(PAKDD’13)</span>, Gold Coast, Australia, April 2013.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/icme13_142.pdf">Learning
sparse latent representation and
distance metric for image retrieval</a>, Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of IEEE
International Conference on Multimedia and Expo (ICME)</span>,
San Jose, California, USA, July 2013. </big></li>
<li><big> <a href="https://truyentran.github.io/papers/acml12_OSM_revised.pdf">Learning
from Ordered Sets and
Applications in Collaborative Ranking</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">Cumulative
Restricted
Boltzmann Machines for Ordinal&nbsp;Data Analysis</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/truyen_etal_fusion12.pdf">Embedded
Restricted Boltzmann
Machines for Fusion of Mixed Data Types and Applications in Social
Measurements Analysis</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 15-th
International Conference on&nbsp;Information
Fusion&nbsp;(FUSION-12)</span>,
Singapore, July 2012.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">A
Sequential Decision Approach
to Ordinal Preferences in Recommender Systems</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 25-th Conference on Artificial Intelligence (AAAI-12)</span>,
Toronto,
Canada, July 2012.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/truyen_etal_icme12.pdf">Learning
Boltzmann Distance Metric for Face Recognition</a>,&nbsp;<span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of&nbsp;IEEE
International Conference on Multimedia &amp; Expo
(ICME-12)</span>, Melbourne, Australia, July 2012.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/tran_phung_venkatesh_acml11.pdf">Mixed-Variate
Restricted
Boltzmann Machines</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung and Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 3rd Asian Conference on Machine Learning (ACML2011)</span>,
Taoyuan, Taiwan, Nov 2011.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/gupta_kdd10.pdf">Nonnegative
Shared Subspace
Learning and Its Application to Social Media Retrieval</a>, Sunil
Gupta, Dinh Phung, Brett. Adams, <span style="font-weight: bold;">Tran
The Truyen</span><span style="font-style: italic;">
Proc. of 16th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining</span>, 25-28 Jul,
Washington DC, 2010.
and Svetha Venkatesh, In</big></li>
<li><big> <a href="http://truyen.vietlabs.com/papers/uai09_final.pdf">Ordinal
Boltzmann Machines for
Collaborative Filtering</a>. <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung and Svetha Venkatesh. In <span style="font-style: italic;">Proc. of 25th
Conference on Uncertainty in Artificial Intelligence</span>,
June, 2009, Montreal, Canada. <span style="font-weight: bold; color: rgb(204, 0, 0);">Runner-up
for the best paper award</span>.</big></li>
<li><big> <a href="https://truyentran.github.io/papers/hcrf_fast.pdf">MCMC
for Hierarchical
Semi-Markov Conditional Random Fields</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Q. Phung, Svetha Venkatesh and Hung H. Bui. In <span style="font-style: italic;">NIPS'09
Workshop on Deep Learning for Speech
Recognition and Related Applications</span>. December, 2009,
Whistler, BC, Canada</big></li>
<li><big> <a href="https://truyentran.github.io/papers/truyen_nips08.pdf">Hierarchical
Semi-Markov
Conditional Random Fields for Recursive Sequential Data</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung, Hung H. Bui, and Svetha Venkatesh.
In <span style="font-style: italic;">Proc.
of&nbsp;21st
Annual Conference on Neural Information Processing Systems</span>,
Dec 2008, Vancouver, Canada. [See <a href="https://truyentran.github.io/papers/truyen_hcrf_tr08.pdf">technical
report</a>
and <a href="https://truyentran.github.io/papers/thesis.pdf">thesis</a>
for more
details and
extensions.]</big></li>
<li><big> <a href="https://truyentran.github.io/papers/truyen_cvpr06.pdf">AdaBoost.MRF:
Boosted Markov
random forests and application to multilevel activity recognition</a>,
<span style="font-weight: bold;">Truyen
Tran</span>, Dinh&nbsp;Quoc Phung, Hung&nbsp;Hai Bui,
and Svetha Venkatesh. In <span style="font-style: italic;">Proc.
of&nbsp; IEEE Conference
on Computer Vision and Pattern Recognition</span>,
volume Volume 2, pages 1686-1693, New York, USA, June 2006.</big></li>
</ul>
<ol>
</ol>
<ul>
</ul>
<ol>
</ol>
</td>
</tr>
</tbody>
</table>
</body></html>