<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Truyen Tran</title>



























<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">

<style>
body {
font-family: 'Abel', serif;
font-size: 12px;
}
</style></head>
<body>
<table style="border-collapse: collapse; width: 1038px; height: 530px;" id="1" border="0" bordercolor="#111111" cellpadding="0" cellspacing="0">
<tbody>
<tr>
<td style="border-right: 1px solid; background-color: rgb(0, 0, 0); height: 10px;" v="">&nbsp;</td>


</tr>
<tr>
<td rowspan="2" v="" style="border-width: 1px; border-right: 1px solid; vertical-align: top;">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 178px;" alt="transparent ML" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Hydrogen_Density_Plots.png/1200px-Hydrogen_Density_Plots.png" hspace="0"><br>
(Source: <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Hydrogen_Density_Plots.png/1200px-Hydrogen_Density_Plots.png">wikipedia.com</a>)</p>
<p align="right">
</p>
<p align="right">
</p>
<p align="right">
</p>
<p align="right"><font size="5"><a href="index.html">Home</a></font> &nbsp; </p>
<br>
<br>
<p align="justify">&nbsp;</p>
</td>
</tr>
<tr>
<td width="24">
<p></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</td>
<td style="width: 837px; vertical-align: top;">
<p><font style="font-weight: bold; color: rgb(0, 102, 0);" size="5"><font size="+3">Theory-informed Machine Learning</font> </font><a name="medical"></a></p>
<p style="color: black;"><font size="5">Data-efficient machine learning that respects theory and does not hallucinate.<br>
</font></p>
<p style="color: black;"><font size="5"><span style="font-weight: bold;">Overview</span>:</font></p><p style="color: black;"><big>Current
leading data-driven learning systems such as ChatGPT, Gemini, and Sora
often hallucinate non-existent, sometimes dangerous artifacts and
generate scientifically implausible outcomes when applied to realistic
science and engineering settings. Lacking built-in mechanisms to
understand real-world phenomena, they fail to generalize beyond their
trained ranges. In contrast, theory-driven models respect the
underlying laws and extrapolate well but may suffer from being
simplistic, incomplete, and prohibitively expensive to solve, thus
unable to accurately represent the dynamics and complexity of the real
world. For example, a detailed theory-driven model of weather would
fail to compute forecasts in real-time due to the sheer complexity of
modeling the atmosphere, ocean, land, and the interactions among them.
Theory-informed Machine Learning (TiML) integrates the strengths of
both approaches, showing great promise for providing trustworthy
insights to help solve pressing global and local problems like
infectious diseases, energy security, and climate change.</big></p><p style="color: black;"><big>We
have pioneered the development of TiML to solve diverse real-world
problems. For example, our ontology-induced model of medical risk
discovered risk factors that were more certain and consistent with
established medicine than those found by purely data-driven methods.
Our epidemiology-guided neural network model of COVID-19 dynamics had
both its design and parameters informed by theory and past outbreaks.
This approach greatly outperformed standard data-driven machine
learning and mechanistic models, helping Ho Chi Minh City, home to over
10 million people, make critical decisions to mitigate a devastating
late 2021 COVID crisis that took over 20,000 lives. Likewise, our
physics-informed graph neural network integrates the external potential
term found in density functional theory calculations to predict the
potential energy surface in materials science applications. Our model
is more accurate in predicting the total energy per atom of a defective
system, as well as the structural changes that result from the presence
of a defect in a material. Another TiML work of ours develops a crystal
generative model that exploits the symmetry of crystal groups and
incorporates an expert-guided reward function. This results in much
faster and more stable crystal generation compared to competing
data-driven methods that do not respect these theoretical priors.</big></p><p style="color: black;"><big>However,
TiML tends to be instance-specific and demands extensive domain and ML
expertise to implement in practice. Despite ultimate success, our
experience with COVID-19 modeling shows that TiML models are very hard
to train, have an extremely complex loss landscape, suffer from
instability, and require major efforts in data conditioning and
hyperparameter tuning. To realize the global potential for TiML to
problem-solve across diverse real-world instances and domains, key
obstacles around model expressiveness and adaptability must be overcome.</big></p><p style="color: black;"><big><span style="font-weight: bold;">Aims</span>:
Our goal is to develop more generally applicable and trustworthy TiML
models. This project addresses critical gaps in current TiML, which
struggles to adapt, capture complexity, and generalize across diverse
problem instances, spatiotemporal domains, and datasets. We will create
new TiML algorithms and neural architectures that are:<br></big></p><ul><li><big><span style="font-style: italic;">Well-validated</span>:
comprehensive benchmarking across diverse domains including, but not
limited to, infectious diseases, road traffic, reaction-diffusion,
materials science, and energy storage;</big></li><li><big><span style="font-style: italic;">Expressive</span>: able to represent a wide range of problems and theoretical priors, including those hidden in scientific literature;</big></li><li><big><span style="font-style: italic;">Adaptive</span>: enabling rapid adaptation to new problems with minimal expertise, data, compute, and effort; and</big></li><li><big><span style="font-style: italic;">Realistic</span>: effectively capturing interacting, multi-scale, multi-physics processes.</big></li></ul>
<big><span style="font-weight: bold;"></span></big><p style="color: black;"><font size="5"><span style="font-weight: bold;">Areas</span>:</font></p>
<ul>
        <li><big><span style="font-weight: bold;">Scientific Large Language Models</span></big></li><li><big><span style="font-weight: bold;">Benchmarking</span></big></li><li><big><span style="font-weight: bold;">Representing theoretical prior</span></big></li><li><big><span style="font-weight: bold;">Multi-process learning</span></big></li><li><big><span style="font-weight: bold;">Rapid adaptation</span></big></li><li><big><span style="font-weight: bold;">Promptable structure generation</span></big></li><li><big><span style="font-weight: bold;">Knowledge graphs<br></span></big></li></ul><p align="justify"><font size="5"><span style="font-weight: bold;">Talks/Tutorials<br>
      </span></font>
      </p>

      
      <ul>
        
        <li>
      <a href="https://www.dropbox.com/scl/fi/zot2yv92ry6eh768zlqor/Tran-GenAI-talk-PRCIM11.pdf?rlkey=78vbqfto9lvki1orgaowryuuo&amp;dl=0"><font size="+1"><span style="text-decoration: underline;">Generative AI to accelerate discovery of materials</span></font></a><big>, Keynote @<span style="font-style: italic;">PRICM11</span>, Nov 2023.</big></li>
        <li><a href="https://www.dropbox.com/scl/fi/9amrwhuvinib00dwemfox/AI4matters.pdf?rlkey=4gxykqnm7bci7xkns3zsvo3y6&amp;dl=0"><font size="+1"><span style="text-decoration: underline;">AI for automated materials discovery via learning to represent, predict, generate and explain</span></font></a><big>, @<span style="font-style: italic;">Thuyloi University</span>, May 2023.</big><br>
        </li>
        <li><font size="+1"><a href="http://truyentran.github.io/ecmlpkdd2021-tute.html"><span style="text-decoration: underline;">Machine learning and reasoning for drug discovery</span></a></font><big> Tutorial @<span style="font-style: italic;">ECML-PKDD</span>, Sept 2021.</big></li>
        <li><big><a href="https://truyentran.github.io/talks/AIML-climate-short.pdf">Climate
change: Challenges and AI-driven solutions</a>, <span style="font-style: italic;">@Swinburne Vietnam</span>, Hanoi,&nbsp;
Vietnam, Dec 2019. <br>

          <a href="https://truyentran.github.io/talks/AI4matters-2019.pdf"><span style="text-decoration: underline;"></span></a></big></li>
<li><big><a href="https://truyentran.github.io/talks/AI-drug-VietAI-Summit-2019.pdf">Modern
AI for drug discovery</a>, <span style="font-style: italic;">VietAI
Summit</span>, Nov 2019.</big></li>
        <li><big>Lecture on <a href="https://truyentran.github.io/talks/seaml19.pdf">Deep
learning for biomedicine</a>, <span style="font-style: italic;">Southeast
Asia Machine Learning</span> (SEA ML) School, Depok, Greater Jakarta,
Indonesia, July 2019.</big></li>
        <li><big><a href="https://truyentran.github.io/talks/GM2019-DL4genomics.pdf">Deep
learning for genomics: Present and future</a>, <span style="font-style: italic;">Genomic Medicine 2019</span>, Hanoi,
Vietnam, June 2019.</big></li>
        
        <li><big><a href="https://truyentran.github.io/talks/AI4matters-2019.pdf"><span style="text-decoration: underline;">AI for matters</span></a>, <span style="font-style: italic;">Phenikaa University,</span> Hanoi, Vietnam, Jan 2019.</big></li>
        <li><big><a href="https://truyentran.github.io/talks/BigData-VIN-2019.pdf">Deep
learning for biomedicine: Genomics and Drug design</a>, <span style="font-style: italic;">Institute of Big Data,</span> Hanoi,
Vietnam, Jan 2019. </big></li></ul><p style="font-weight: bold;" align="justify"><big><font size="+2">Preprints</font><span style="text-decoration: underline;"></span></big></p>



      
      
      
      <ul>
<big> </big>
      </ul>


      
      
      <ul><li><big><a href="https://arxiv.org/abs/2402.10931">Enabling discovery of
materials through enhanced generalisability of deep learning models</a>, </big><big>Tawfik, Sherif Abdulkader, Tri Minh Nguyen, Salvy P. Russo, Truyen
Tran, Sunil Gupta, and Svetha Venkatesh.&nbsp;<span style="font-style: italic;">
arXiv preprint</span> <span style="font-style: italic;">arXiv:2402.10931</span>.</big></li></ul><p align="justify"><font style="font-weight: bold;" size="5">Benchmarking</font><font size="5"><a name="Publications"></a></font></p><p align="justify"><font style="font-weight: bold;" size="5">Policy reports</font><font size="5"><a name="Publications"></a></font></p><ul><li><big><a href="https://truyentran.github.io/talks/T4C.HCM-COVID-19.Report.Aug15-EN.pdf">Analysis and forecasting of COVID-19 in Ho Chi Minh city</a>. </big><big>Tran, T., Tran, Q., &amp; Tech4Covid Group. </big><big><span style="font-style: italic;">Report to HCM City Council &amp; COVID Response Task Force</span>, 13/08/2021. <br></big></li></ul>



      <p align="justify"><font style="font-weight: bold;" size="5">Publications</font><font size="5"><a name="Publications"></a></font></p>


<ul>
</ul>
      <ul>
        
        <li><big><a href="https://www.nature.com/articles/s41524-023-01163-9">Towards understanding structure–property relations in materials with interpretable deep learning</a>,&nbsp; Tien-Sinh Vu, Minh-Quyet Ha, Duong Nguyen Nguyen, Viet-Cuong Nguyen, Yukihiro Abe, <span style="font-weight: bold;">Truyen Tran</span>, Huan Tran, Hiori Kino, Takashi Miyake, Koji Tsuda, </big><big>Hieu-Chi Dam, </big><big> <span style="font-style: italic;">npj Computational Materials, 9(215), (2023)</span>.</big></li>
        <li><big><a href="https://openreview.net/forum?id=dJuDv4MKLE">Hierarchical GFlowNet for crystal structure generation</a>, </big><big>Nguyen, Tri, Sherif Tawfik, <span style="font-weight: bold;">Truyen Tran</span>, Sunil Gupta, Santu Rana, and Svetha Venkatesh. In <span style="font-style: italic;">AI for Accelerated Materials Design-NeurIPS 2023 Workshop</span>. 2023.</big></li>
        <li><big><a href="https://pubs.acs.org/doi/abs/10.1021/acs.jpcc.2c03926">Machine learning-aided exploration of ultrahard materials,</a> Tawfik, Sherif Abdulkader, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Tiffany R. Walsh, and Svetha Venkatesh. <span style="font-style: italic;">The Journal of Physical Chemistry</span> C 126, no. 37 (2022): 15952-15961.</big></li><li><big><a href="https://link.springer.com/article/10.1007/s41060-022-00371-8">Learning to discover medicines</a>, Nguyen, Minh-Tri, Thin Nguyen, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">International Journal of Data Science and Analytics</span> (2022): 1-16.</big></li><li><big><a href="https://academic.oup.com/bib/article-abstract/23/4/bbac269/6628784">Mitigating cold-start problems in drug-target affinity prediction with interaction knowledge transferring</a>, Nguyen, Tri Minh, Thin Nguyen, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">Briefings in Bioinformatics</span> 23, no. 4 (2022): bbac269.</big></li><li><big><a href="https://ieeexplore.ieee.org/abstract/document/9827583/">Explaining black box drug target prediction through model agnostic counterfactual samples</a>, Nguyen, Tri Minh, Thomas P. Quinn, Thin Nguyen, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">IEEE/ACM Transactions on Computational Biology and Bioinformatics</span> (2022).</big></li><li><big><a href="https://arxiv.org/abs/2009.12146">GEFA: Early fusion approach in drug-target affinity prediction</a>, Tri Minh Nguyen, Thin Nguyen, Thao Minh Le, <span style="font-weight: bold;">Truyen Tran</span>,&nbsp;<span style="font-style: italic;"></span></big><big><span style="font-style: italic;">IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2021</span></big><big><span style="font-style: italic;">.</span></big></li><li><big><a href="https://www.biorxiv.org/content/10.1101/534628v2.abstract">Personalized
Annotation-based Networks (PAN) for the prediction of breast cancer
relapse</a>, T Nguyen, SC Lee, TP Quinn, B Truong, X Li, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, TD Le, <span style="font-style: italic;">IEEE/ACM Transactions on Computational Biology and Bioinformatics,</span> 2021.</big></li><li><big><a href="https://www.biorxiv.org/content/10.1101/686394v1.abstract">Deep
in the bowel: Highly interpretable neural encoder-decoder networks
predict gut metabolites from gut microbiome</a>, <span style="font-style: italic;"></span>V Le, TP Quinn, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, <span style="font-style: italic;">BMC Genomics (21)</span>, 07/2020.</big></li><li><big><a href="https://www.biorxiv.org/content/10.1101/533406v2.abstract">DeepTRIAGE:
Interpretable and individualised biomarker scores using attention
mechanism for the classification of breast cancer sub-types</a>. A
Beykikhoshk, TP Quinn, SC Lee, <span style="font-weight: bold;">T Tran</span>,
S Venkatesh, <span style="font-style: italic;">BMC Medical Genomics</span><span style="font-style: italic;"></span>, 2020.</big></li>


        
<big>
        </big><big>
        </big>
        <li><big><a href="https://truyentran.github.io/papers/incomplete-alloy.pdf"><span style="text-decoration: underline;">Incomplete conditional density estimation for fast materials discovery</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,&nbsp;Sunil Gupta,  Svetha Venkatesh. <span style="font-style: italic;"></span><span style="font-style: italic;">SDM'19</span>.</big></li><li><big><a href="https://arxiv.org/abs/1807.10751"><span style="text-decoration: underline;">Committee machine that votes for similarity between material</span>s</a>; Duong-Nguyen Nguyen, Tien-Lam Pham, Viet-Cuong Nguyen, Tuan-Dung Ho, <span style="font-weight: bold;">Truyen Tran</span>, Keisuke Takahashi and Hieu-Chi Dam.&nbsp;<span style="font-style: italic;"></span><span style="font-style: italic;">IUCrJ</span>, 2018 Nov 1; 5(Pt 6): 830–840.</big></li><big></big><big></big><li><big><a href="https://arxiv.org/abs/1812.09441">Graph transformation policy network for chemical reaction prediction</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">KDD'19</span>.</big></li><li><big><a href="https://arxiv.org/abs/1804.00293">Attentional multilabel
learning over graphs: A message passing approach</a>, K Do, <span style="font-weight: bold;">T Tran</span>, T Nguyen, S Venkatesh, <span style="font-style: italic;">Machine Learning, 2019.</span></big></li><li><big><a href="https://arxiv.org/abs/1801.08641">Knowledge
Graph
Embedding with
Multiple Relation Projections</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh,&nbsp;<span style="font-style: italic;">ICPR'18.</span></big></li><li><big><a href="https://arxiv.org/abs/1801.02622">Graph memory networks for molecular activity prediction</a>,&nbsp;Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICPR'18</span>.</big></li><li><big> <a href="https://arxiv.org/abs/1609.04508">Column
Networks for Collective Classification</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh Phung, Svetha
Venkatesh, <span style="font-style: italic;"></span><span style="font-style: italic;">AAAI'17</span></big></li><li><big><a href="https://arxiv.org/abs/1708.04357"><span style="text-decoration: underline;">Graph classification via deep learning with virtual nodes</span></a> Trang Pham, <span style="text-decoration: underline;"></span><span style="font-weight: bold;">Truyen Tran</span>, Hoa Dam, Svetha
Venkatesh, <span style="font-style: italic;">Third Representation
Learning for Graphs Workshop (ReLiG 2017)</span>.</big></li><li><big><a href="https://arxiv.org/abs/1609.08752"><span style="text-decoration: underline;">Stabilizing Linear
Prediction Models using Autoencoder</span></a>, Shivapratap
Gopakumara, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh, <span style="font-style: italic;">International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li><li><big><a href="https://truyentran.github.io/papers/bdm16.pdf">Neural
Choice by Elimination via Highway Networks</a>,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung and Svetha Venkatesh,&nbsp;<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD workshop on Biologically
Inspired Techniques for Data Mining (BDM'16)</span><span class="Apple-converted-space"></span>, April 19-22
2016, Auckland, NZ.</big></li><li><big> <a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X"><span style="text-decoration: underline;">Graph-induced restricted
Boltzmann machines for document modeling</span></a>, Tu Dinh
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Information
Sciences</span>, 2016<span style="font-style: italic;">.</span></big></li><li><big><a href="../../Dropbox%20%28Toby%20Playpad%29/public_html/papers/pakdd_main.pdf">Stabilizing Sparse Cox Model
using Statistic and Semantic Structures in Electronic Medical Records</a>.
Shivapratap Gopakumar, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">PAKDD'15</span>,
HCM City, Vietnam, May 2015.</big></li><li><big> <a href="https://truyentran.github.io/papers/aaai15_main.pdf">Tensor-variate
Restricted Boltzmann Machines</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">AAAI</span>
2015.&nbsp;</big></li><li><big><a href="../../Dropbox%20%28Toby%20Playpad%29/public_html/papers/shivan_jbhi14.pdf">Stabilizing
high-dimensional
prediction models using feature graphs</a>, Shivapratap
Gopakumar, <span style="font-weight: bold;">Truyen Tran</span>,
Tu Dinh Nguyen, Dinh Phung, and Svetha Venkatesh, <span style="font-style: italic;">IEEE Journal of Biomedical and
Health Informatics</span>, 2014
DOI:10.1109/JBHI.2014.2353031S&nbsp;</big></li><li><big><a href="http://link.springer.com/article/10.1007%2Fs10115-014-0740-4">Stabilized
sparse ordinal regression for medical risk stratification</a>, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Wei Luo, and Svetha Venkatesh, <span style="font-style: italic;">Knowledge
and Information Systems</span>,
2014, DOI: 10.1007/s10115-014-0740-4.</big></li><li><big> <a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">Thurstonian
Boltzmann machines: Learning from multiple inequalities</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of
30th
International Conference in Machine Learning (ICML’13)</span>,
Atlanta, USA, June, 2013.</big></li><li><big> <a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">A
Sequential Decision Approach
to Ordinal Preferences in Recommender Systems</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 25-th Conference on Artificial Intelligence (AAAI-12)</span>,
Toronto,
Canada, July 2012.</big></li>

        
</ul><span style="font-weight: bold;"><font size="5"><span style="color: rgb(0, 153, 0);"></span></font></span><span style="font-weight: bold;"><font size="5"><span style="color: rgb(0, 153, 0);"></span></font></span>
      
      <ul></ul></td></tr></tbody></table><br style="">
<p style="" align="justify"><br>
&nbsp;</p>
</body></html>