<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Truyen Tran</title>








<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">
<style>
body {
font-family: 'Abel';
font-size: 10px;
}
</style></head><body>
<table style="border-collapse: collapse; width: 1031px; height: 1113px;" id="1" border="0" bordercolor="#111111" cellpadding="0" cellspacing="0">
<tbody>
<tr>
<td style="border-right: 1px solid;" v="" bgcolor="#000000">&nbsp;</td>
<td style="width: 200px;">&nbsp;</td>
<td style="vertical-align: top;" v="">&nbsp;</td>
</tr>
<tr>
<td rowspan="2" v="" style="border-width: 1px; border-right: 1px solid; vertical-align: top;">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="http://rdn-consulting.com/blog/wp-content/uploads/2015/12/deepLearningAI500.png" hspace="0"><br>
</p>
<p style="text-align: center;">[Source:&nbsp;rdn-consulting] <br>
</p>
<p align="right"></p>
<p align="right">
</p>
<p align="right"><font size="5"><a href="index.html">Home</a></font>&nbsp;
&nbsp; </p>
<br>
<p align="justify"></p>
<p align="justify">&nbsp;</p>
<p align="justify"></p>

<p align="justify">&nbsp;</p>
</td>
</tr>
<tr>
<td width="24">
<p></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</td>
<td style="vertical-align: top; width: 80%;">&nbsp; <font style="font-weight: bold; color: rgb(0, 102, 0);" size="+2">Resources for Deep Learning</font><br>
&nbsp;<br>&nbsp;

      <big><a href="repLearn.html">Our own research</a></big><br>
      <big>&nbsp;Textbooks: <a href="http://www.deeplearningbook.org/">Deep Learning</a> (2016) | <a href="http://d2l.ai/index.html">Dive into Deep Learning</a> (2019)</big><br>
      <big>&nbsp;<span style="font-weight: bold;">Tutorials</span><br>
      </big>
      <ul>
        <big>
          </big><li><big><a href="https://truyentran.github.io/ai16-tute.html">DL in non-cognitive domains</a> by us (Dec, 2016)</big></li><big>
          </big><li><big><a href="https://truyentran.github.io/pakdd18-tute.html">DL for biomedicine</a> by us (June, 2018)<br>

            </big></li><big>
        </big>
      </ul>
      <big>&nbsp;<span style="font-weight: bold;">Courses</span></big><span style="font-weight: bold;">
      </span><br>
<ul>
        <li><big>DL series <a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF">2020</a> by DeepMind &amp; UCL</big></li>
        <li><big>DL course, <a href="https://cds.nyu.edu/deep-learning/">Spring 2020</a>, at NYU by Yann LeCun<br>
</big></li>
<li><big>General: <a href="http://www.cs.cmu.edu/%7Ersalakhu/10707/">CMU</a> | <a href="https://ift6266h16.wordpress.com/category/lectures/">Montreal (Yoshua Bengio)</a> | <a href="https://cs230.stanford.edu/syllabus/">Stanford (Andrew Ng)</a> | <a href="https://m2dsupsdlclass.github.io/lectures-labs/">Paris Saclay</a> | <a href="https://github.com/glouppe/info8010-deep-learning/tree/v2-info8010-2019">ULiège</a> |</big></li><li><big>NLP:&nbsp;<a href="http://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/">Oxford + DeepMind</a> | <a href="http://onlinehub.stanford.edu/cs224">Standford</a> |&nbsp;</big></li><li><big>Computer Vision:&nbsp;<a href="http://cs231n.stanford.edu/">Standford</a> |</big></li><li><big>Reinforcement learning: <a href="https://katefvision.github.io/">CMU</a>&nbsp;|  <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">David Silver</a> | <a href="http://rll.berkeley.edu/deeprlcourse/">Berkeley</a> | <a href="https://sites.google.com/view/deep-rl-bootcamp/lectures">Deep RL Bootcamp</a> |</big></li><big>
          </big><li><big>Deep unsupervised learning: <a href="https://sites.google.com/view/berkeley-cs294-158-sp20/home">CMU</a> |</big></li><big>
        </big>
        <li><big>Probabilistic graphical models: <a href="https://ermongroup.github.io/cs228-notes/">Standford</a> (Stefano Ermon) |</big></li>
<li><big>Artificial General Intelligence: <a href="https://agi.mit.edu/">Lex Fridman</a> |</big></li><li><big>Theory: <a href="https://stats385.github.io/">Stanford (David Donoho)</a> | <a href="http://mitliagkas.github.io/ift6085-dl-theory-class-2019/">Montreal (Ioannis Mitliagkas)</a> |</big></li>
      </ul>
      <big>&nbsp;<span style="font-weight: bold;">Programming frameworks:&nbsp;</span></big>
      <ul>
<li><big>Google's <a href="https://www.tensorflow.org/">TensorFlow</a> (Python)</big></li><li><big>Facebook's <a href="http://pytorch.org/">PyTorch</a> (Python)<br>
          </big></li><li><big>Amazon's <a href="https://aws.amazon.com/mxnet/">Mxnet</a> (Multiple languages)<a href="https://gist.github.com/graphific/f211174ebffb1f874f6d"><br></a></big></li>
      </ul>
      <big>&nbsp;<span style="font-weight: bold;">Research areas</span></big>
      <ul>
<li style="font-weight: bold;"><big>Top:&nbsp;RL/planning, DGM,&nbsp;graphs, reasoning</big></li><li><big>A list of <a href="https://medium.com/ai-roadmap-institute/unsolved-problems-in-ai-38f4ce18921d">open problems</a>.&nbsp;</big></li><li><big><a href="http://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/">Structures</a> (sets &amp; graphs)</big></li><li><big><a href="https://www.oreilly.com/ideas/a-look-at-deep-learning-for-science?utm_campaign=Revue%20newsletter&amp;utm_medium=Newsletter&amp;utm_source=revue">DL for sciences</a><br>
          </big></li><li><big><a href="http://rinuboney.github.io/2015/10/18/theoretical-motivations-deep-learning.html">Theoretical motivations</a></big></li><li><big><a href="http://deepmind.com/publications.html">Google DeepMind publications</a></big></li><li><big>Dialog systems. <a href="https://www.technologyreview.com/s/604117/facebooks-perfect-impossible-chatbot/?utm_campaign=add_this&amp;utm_medium=post&amp;utm_source=twitter">Facebook's chatbot</a>.</big></li><li><big><a href="https://www.wired.com/2016/05/the-end-of-code/">Automated programming</a> (aka description2code).<br>
          </big></li><li><big>Explainable AI: <a href="http://www.darpa.mil/program/explainable-artificial-intelligence">DARPA</a></big></li><li><big><a href="https://venturebeat.com/2017/04/15/the-art-of-algorithms-how-automation-is-affecting-creativity/?utm_campaign=Revue%20newsletter&amp;utm_medium=Newsletter&amp;utm_source=revue">Creative arts</a></big></li><li><big><a href="http://waitbutwhy.com/2017/04/neuralink.html?utm_campaign=Revue%20newsletter&amp;utm_medium=Newsletter&amp;utm_source=revue">Human-machine interacing</a><br>
          </big></li>
      </ul>
      <big>&nbsp;<span style="font-weight: bold;">Views by leaders &amp; leading groups</span></big>
      <ul>
        <li><big>Yann LeCun, Eric Horvitz &amp;&nbsp; Peter Norvig: on Reddit AMA (<a href="https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/">2018</a>),</big></li>
        <li><big>Google Brain: on Reddit AMA (<a href="https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/">Sept, 2017</a>),</big></li>
        <li><big>Yann LeCun:&nbsp;<a href="https://www.quora.com/session/Yann-LeCun/1?srid=uDFQ&amp;share=97ce126b">on Quora (July 2016)</a>,</big></li>
        <li><big>Pedro Domingos: <a href="https://www.quora.com/profile/Pedro-Domingos-2/session/67/">on Quora (Feb 2016)</a>,</big></li>
        <li><big>Yoshua Bengio:&nbsp;<a href="https://www.quora.com/profile/Yoshua-Bengio/session/37/">on Quora (Jan 2016)</a>,</big></li>
        <li><big>Nando de Freitas: <a href="https://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/">on Reddit AMA (Dec, 2015)</a>,</big></li>
        <li><big><a href="http://people.idsia.ch/%7Ejuergen/">Jürgen Schmidhuber</a>: <a href="https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama">on Reddit AMA (Feb, 2015)</a></big><big> </big></li>
      </ul>
      <big>&nbsp;Different views of deep learning:</big>
      <ul>
<li><big><a href="http://blog.shakirm.com/2015/01/a-statistical-view-of-deep-learning-i-recursive-glms/">Statistical view</a></big></li><li><big><a href="http://cbmm.mit.edu/publications/deep-convolutional-networks-are-hierarchical-kernel-machines">Kernel view</a>, from Poggio's group</big></li><li><big><a href="https://charlesmartin14.wordpress.com/2015/04/01/why-deep-learning-works-ii-the-renormalization-group/">Physics view, renormalization group theory</a>.</big></li>
      </ul>
      <big>&nbsp;Blogs</big>
      <ul>
<li><big><a href="http://ruder.io/#open">Sebastian Ruder</a>: Multitask, NLP<br>
          </big></li><li><big><a href="http://www.inference.vc/">inFERENCe</a>: GAN</big></li>
      </ul>
      <big>&nbsp;Practical issues:</big>
      <ul>
<li><big>Trouble shooting neural nets: <a href="https://docs.google.com/presentation/d/183aCHcSq-YsaokZrqI3khuy_zPbehG-XgkyA6L5W4t4/edit#slide=id.g38a7d6b174_18_44">here</a>, <a href="https://towardsdatascience.com/a-bunch-of-tips-and-tricks-for-training-deep-neural-networks-3ca24c31ddc8">here</a> and <a href="https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607">here</a>. <br>
          </big></li>
      </ul>


</td>
</tr>
</tbody>
</table>
<font style=""></font></body></html>