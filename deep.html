<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Truyen Tran</title>

<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">
<style>
body {
font-family: 'Abel';
font-size: 10px;
}
</style></head>
<body>
<table style="border-collapse: collapse; width: 70%; height: 1416px;" id="1" border="0" bordercolor="#111111" cellpadding="0" cellspacing="0">
<tbody>
<tr>
<td style="border-right: 1px solid;" v="" bgcolor="#000000">&nbsp;</td>
<td style="width: 200px;">&nbsp;</td>
<td style="vertical-align: top;" v="">&nbsp;</td>
</tr>
<tr>
<td rowspan="2" v="" style="border-width: 1px; border-right: 1px solid; vertical-align: top;">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="http://rdn-consulting.com/blog/wp-content/uploads/2015/12/deepLearningAI500.png" hspace="0"><br>
</p>
<p align="right">[Source:&nbsp;rdn-consulting]</p>
<p align="right"></p>
<p align="right">
</p>
<p align="right"><font size="5"><a href="index.html">Home</a></font>&nbsp;
&nbsp; </p>
<br>
<p align="justify"></p>
<p align="justify">&nbsp;</p>
<p align="justify"></p>
<p align="justify">&nbsp;</p>
<p align="justify">&nbsp;</p>
</td>
</tr>
<tr>
<td width="24">
<p></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</td>
<td style="vertical-align: top; width: 80%;">

<font size="24"> Resources for Deep Learning </font>

<br>

<ul><li><font size="5"><a href="repLearn.html">Our own research</a></font></li><li><font size="5"><a href="http://news.startup.ml/">News</a>.</font></li><li><font size="5">The <a href="http://www.deeplearningbook.org/">textbook</a>.</font></li><li><font size="5"><a href="http://eclass.cc/courselists/117_deep_learning">Collection of courses</a></font></li><ul><li><font size="5">Up-to-date courses:</font></li><ul><li><font size="5"><a href="https://ift6266h16.wordpress.com/category/lectures/">Montreal course on Representation learning</a></font></li></ul><ul><li><font size="5">Stanford course on <a href="http://cs224d.stanford.edu/">Deep learning for NLP</a></font></li><li><font size="5">Stanford course on<a href="http://cs231n.stanford.edu/"> CNN for Vision</a></font></li></ul></ul><ul><li><font size="5">Coursera's <a href="https://www.coursera.org/course/neuralnets">Neural networks</a> by Geoff Hinton</font></li></ul><ul><li><font size="5"><a href="http://www.computervisiontalks.com/tag/deep-learning-course">Deep learning course</a> by&nbsp;<a href="http://www.cs.ox.ac.uk/people/nando.defreitas/">Nando de Freitas</a></font></li></ul><ul><li><font size="5"><a href="http://www.machinelearningtalks.com/tag/rl-course/">Reinforcement learning course</a> by David Silver. RL is a new playground for deep learning.</font></li></ul><ul><li><font size="5">Japan's NAIST course on <a href="http://cl.naist.jp/%7Ekevinduh/a/deep2014/">Neural networks and Deep learning</a> by Kevin Duh</font></li></ul><ul><li><font size="5"><a href="https://www.udacity.com/course/deep-learning--ud730">Google/Udacity course (2016)</a></font></li></ul><ul><li><font size="5"><a href="http://llcao.net/cu-deeplearning15/reading.html">Reading list for Columbia Uni's deep learning course</a>, and <a href="http://llcao.net/cu-deeplearning15/resource.html">their resources collection</a>.</font></li></ul><li><font size="5">Installation</font></li><ul><li><font size="5"><a href="https://gist.github.com/graphific/f211174ebffb1f874f6d">A worked-out installation script here for Linux</a></font></li></ul><li><font size="5"><a href="https://www.quora.com/Whats-the-most-effective-way-to-get-started-with-Deep-Learning">Getting started</a>. Discussion on <a href="https://news.ycombinator.com/from?site=arxiv.org">Hacker News</a>.</font></li><li><font size="5">Tutorials/Talks/Introduction</font></li><ul><li><font size="5">By the trio (Hinton, LeCun &amp; Bengio): NIPS 2015</font></li><li><font size="5">By <a href="http://colah.github.io/">Christopher Olah</a>: <a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/">Embedding</a>, <a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/">CNN</a>1, <a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">CNN2</a>, <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM</a>.</font></li></ul><ul><li><font size="5">By <a href="http://deeplearning.net/tutorial/">Theano's creators</a>.</font></li><li><font size="5">By Quoc Le: (2015) <a href="http://www-cs.stanford.edu/%7Equocle/tutorial1.pdf">part 1</a>, <a href="http://www-cs.stanford.edu/%7Equocle/tutorial2.pdf">part 2</a>.</font></li><li><font size="5">By Ruslan Salakhutdinov: (Deep Learning Summer School 2015) <a href="http://www.cs.toronto.edu/%7Ersalakhu/talk_Montreal_part1_pdf.pdf">part 1</a>, <a href="http://www.cs.toronto.edu/%7Ersalakhu/talk_Montreal_part2_pdf.pdf">part 2</a>.</font></li><li><font size="5">By Yann LeCun: <a href="https://drive.google.com/file/d/0BxKBnD5y2M8NbWN6XzM5UXkwNDA/view">unsupervised learning</a> (2015).</font></li><li><font size="5"><a href="http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/">Convnet in Python</a></font></li><li><font size="5"><a href="https://gavagai.se/blog/2015/09/30/a-brief-history-of-word-embeddings/">Word embedding</a></font></li><li><font size="5"><a href="http://sebastianruder.com/optimizing-gradient-descent/">Stochastic gradient descent</a></font></li><li><font size="5">By Cho: <a href="http://arxiv.org/abs/1511.07916">deep NLP (Nov, 2015)</a></font></li><li><font size="5"><a href="http://karpathy.github.io/neuralnets/">Hacker's guide to Neural Networks</a></font></li><li><font size="5"><a href="http://yyue.blogspot.com.au/2015/01/a-brief-overview-of-deep-learning.html">Practical advice to run deep nets</a></font></li><li><font size="5"><a href="https://datascienceday.files.wordpress.com/2014/11/talk.pdf">Deep learning state of the arts</a>, as of 30/10/2014.</font></li><li><font size="5"><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Power of RNNs</a> | <a href="http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">Deep RNNs for translation</a> | <a href="http://www.bloomberg.com/news/articles/2015-06-25/google-s-new-ai-can-answer-dumb-it-questions-or-tell-you-the-meaning-of-life">RNN for conversation</a>.</font></li><li><font size="5">For fun: <a href="https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0">generating Obama style speech using RNN</a>.</font></li><li><font size="5"><a href="http://petewarden.com/2014/06/10/why-is-everyone-so-excited-about-deep-learning/">Why is everyone so excited about deep learning?</a></font></li></ul><li><font size="5">Frameworks/libraries:&nbsp;</font></li><ul><li><font size="5"><a href="https://github.com/zer0n/deepframeworks/blob/master/README.md">Comparision 1</a>,</font></li><li><font size="5"><a href="http://deeplearning.net/software/theano/">Theano</a> (run in Python) by Bengio's group.&nbsp;<a href="http://www.johnwittenauer.net/configuring-theano-for-high-performance-deep-learning/">Theano for faster</a>.</font></li><li><font size="5">Torch (run in Lua) used in Google DeepMind, Facebook, Twitter Cortex.&nbsp; <a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">Torch for NLP</a>.</font></li><li><font size="5">Google's TensorFlow</font></li><li><font size="5"><a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> (run in Matlab).&nbsp;</font></li><li><font size="5"><a href="https://github.com/IDSIA/brainstorm">Brainstorm</a> (Python) by Jürgen Schmidhuber's group.</font></li><li><font size="5">Caffe (for vision &amp; mutlimedia).</font></li><li><font size="5">CNTK (Microsoft)</font></li></ul><li><font size="5">Views by leaders &amp; leading groups</font></li><ul><li><font size="5">Nando de Freitas: <a href="https://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/">on Reddit AMA (Dec, 2015)</a>.</font></li></ul><ul><li><font size="5">Yoshua Bengio: <a href="https://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio">on Reddit AMA (Feb, 2014)</a>,&nbsp;<a href="https://www.quora.com/profile/Yoshua-Bengio/session/37/">on Quora (Jan 2016)</a>,</font></li><li><font size="5">Michael Jordan: <a href="https://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan">on Reddit AMA (Sep, 2014)</a>,</font></li><li><font size="5">Yann LeCun: <a href="https://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun">on Reddit AMA (May, 2014)</a>, <a href="https://www.quora.com/session/Yann-LeCun/1?srid=uDFQ&amp;share=97ce126b">on Quora (July 2016)</a>,</font></li><li><font size="5">Geoff Hinton: <a href="https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton">on Reddit AMA (Nov, 2014)</a>,</font></li><li><font size="5">Andrew Ng: <a href="https://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/">on Reddit AMA (April, 2015)</a>,</font></li><li> <font size="5"><a href="http://people.idsia.ch/%7Ejuergen/">Jürgen Schmidhuber</a>: <a href="https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama">on Reddit AMA (Feb, 2015)</a>, homepage of <a href="http://people.idsia.ch/%7Ejuergen/">Jürgen Schmidhuber</a>, his <a href="http://www.wired.com/2015/07/guy-taught-ai-remember-launching-startup">startup</a><a href="http://people.idsia.ch/%7Ejuergen/deep-learning-conspiracy.html">credit assignment</a>. </font> (Nnaisense),&nbsp;view on </li><li><font size="5"><a href="https://sites.google.com/site/deepernn/home/blog/briefsummaryofthepaneldiscussionatdlworkshopicml2015">Summary of discussion, ICML workshop on DL, 2015</a></font></li><li><font size="5"><a href="http://deepmind.com/publications.html">Google DeepMind publications</a></font></li><li><font size="5">Pedro Domingos: <a href="https://www.quora.com/profile/Pedro-Domingos-2/session/67/">on Quora (Feb 2016)</a>,</font></li></ul><li><font size="5">Architectures</font></li><ul><li><font size="5">FFN: Highway Net, Residual &amp; p-Norm</font></li><li><font size="5">RNN. <a href="https://github.com/kjw0612/awesome-rnn">A list</a>.</font></li><li><font size="5">CNN</font></li><li><font size="5">Memory &amp; attention</font></li></ul><li><font size="5">Areas</font></li><ul><li><font size="5"><a href="https://openai.com/blog/special-projects/">Projects by OpenAI (automated programming, security, AI life simulation)</a></font></li><li><font size="5">Unsupervised learning, representation learning</font></li><ul><li><font size="5"><a href="http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/">Objective function for finite data</a></font></li></ul><li><font size="5">Reinforcement learning, games and robotics</font></li><li><font size="5">Memory,&nbsp;attention and excecution</font></li><li><font size="5">Structured prediction &amp; logic</font></li><li><font size="5">Optimization</font></li><li><font size="5">NLP</font></li><li><font size="5">Graphs</font></li><li><font size="5"><a href="http://rinuboney.github.io/2015/10/18/theoretical-motivations-deep-learning.html">Theoretical motivations</a></font></li></ul><li><font size="5">Meetings</font></li><ul><li><font size="5">Summer school <a href="http://videolectures.net/deeplearning2015_montreal/">2015</a></font></li><li><font size="5">London summit <a href="https://medium.com/@alevitale/notes-from-deep-learning-summit-2015-london-day-1-1599f603a40b">2015</a></font> </li></ul><li><font size="5"><a href="http://cis.ieee.org/award-recipients.html#NeuralNetworksPioneerAward">Neural network pioneer awards</a>.</font></li><li><font size="5">Different views of deep learning:</font></li><ul><li><font size="5"><a href="http://numenta.com/learn/">Hierarchical Temporal Memory</a>,&nbsp;<a href="http://www.amazon.com/On-Intelligence-Jeff-Hawkins/dp/0805078533"><span style="font-style: italic;">On intelligence</span></a>&nbsp; by Jeff Hawkins.</font></li></ul><ul><li><font size="5"><a href="http://blog.shakirm.com/2015/01/a-statistical-view-of-deep-learning-i-recursive-glms/">Statistical view</a></font></li></ul><ul><li><font size="5"><a href="http://arxiv.org/abs/1506.02142">Bayesian view of deep learning + dropouts</a>.</font></li></ul><ul><li><font size="5"><a href="http://cbmm.mit.edu/publications/deep-convolutional-networks-are-hierarchical-kernel-machines">Kernel view</a>, from Poggio's group</font></li></ul><ul><li><font size="5"><a href="https://charlesmartin14.wordpress.com/2015/04/01/why-deep-learning-works-ii-the-renormalization-group/">Physics view, renormalization group theory</a>.</font></li></ul><ul><li><font size="5">Algebraic view</font></li></ul></ul>

</td>
</tr>
</tbody>
</table>
<font style=""><br>
</font>
<p style="" align="justify"><br>
&nbsp;</p>


</body></html>