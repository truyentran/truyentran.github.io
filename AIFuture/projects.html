<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>AI Future | Prof Truyen Tran</title>

<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">
<style>
body {
font-family: 'Abel';
font-size: 100px;
}
</style>
<meta name="GENERATOR" content="LyX 2.3.1-1">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;</style>
<meta name="GENERATOR" content="LyX 2.3.1-1">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;
}
</style></head>
<body>
<table style="border-collapse: collapse; width: 1000px; height: 1000px;" id="1" border="0" bordercolor="#111111" cellpadding="3" cellspacing="0">
<tbody>
<tr>
<td style="border-width: 1px; border-right: 1px solid; vertical-align: top; background-color: rgb(241, 242, 241);" v="" rowspan="8">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="figs/deepLearningAI500.png" hspace="0"><br>
</p>
<p align="right">[Source:&nbsp;rdn-consulting]
&nbsp;</p>
<p align="right"> </p>
<p align="right"><big><a href="../index.html">Home</a> <br><a href="index.html">AI Future page</a> <br><a href="#TalksTutorials"></a><a href="#Publications"><br></a></big> </p>
<br>
&nbsp; <br>
</td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(215, 228, 244);">
<p style="color: rgb(0, 51, 0);"><font style="color: rgb(0, 102, 0); font-weight: bold;" size="+3">&nbsp;AI
Future Projects</font></p>
</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(222, 236, 244);"><big><span style="font-weight: bold;">&nbsp;Projects</span><br>
</big>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top; width: 50%;"><big>»
<a href="#New_inductive_biases_in_deep_learning">New
inductive biases in deep learning</a></big><br>
<big>» <a href="#Memory_architectures_for_neural_networks">Memory
architectures for neural networks</a></big><br>
<big>» <a href="#Indirection_mechanisms_for_better">Indirection
mechanisms for&nbsp;generalization</a></big><br>
<big>» <a href="#Compositional_reasoning_in_">Compositional
reasoning in vision-language</a></big><br>
<big>» <a href="#Collaborative_priors_for_LLM-powered">Collaborative
priors for LLM multi-agents</a><br>
</big><big>» <a href="#Learning_for_structural_reasoning">Learning for
structural reasoning</a><br>
</big><big>» <a href="#Theory_of_mind_architectures">Theory of mind
architectures</a><br>
</big><big>» <a href="#Efficient_exploration_of_combinatorial">Efficient
exploration of combinatorial spaces</a></big></td>
<td style="vertical-align: top;"><big>» <a href="#Theory_of_mind_in_LLMs_">Theory of mind in LLMs</a></big><br>
<big>» <a href="#Scaling_with_sparse_mixture_of_experts_">Scaling with
sparse mixture of experts</a></big><br>
<big>» <a href="https://theoryinformed-ml.github.io/">Theory-informed
machine learning</a></big><br>
<big>» <a href="#Representing_and_reasoning_over_noisy_">Representing
and reasoning over noisy data</a><br>
</big><big>» <a href="#Structured_reasoning_in_video_">Structured reasoning
in video</a></big><br>
<big>» </big><a href="AI-fundamental.html#Human_behaviour_understanding_in_video"><big>Understanding
human behaviours in video</big></a><br>
<big>» </big><a href="AI-fundamental.html#Visual_question_answering_and_dialog"><big>Visual
question answering</big></a><br>
<big>» </big><a href="#Video_dialog"><big>Video
dialog</big></a></td>
</tr>
</tbody>
</table>
&nbsp;</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td></td>
<td style="background-color: rgb(233, 233, 233);"><big><span style="font-weight: bold;">Projects (Old)<br>
</span></big>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top; width: 50%;"><big>»
Recomender systems: Random fields</big><br>
<big>» Ordinal choice modelling</big><br>
<big>» Conditional random fields</big><br>
<big>» Advances in Restricted
Boltzmann Machines<br>
</big><big>» Software projects analytics and
automation&nbsp;<br>
</big><big>» Software language models</big></td>
<td style="vertical-align: top;"><big>»
High-dimensional model stability</big><br>
<big>» RNNs for structured data</big><br>
<big>» Advances in representation learning<br>
</big><big>» Understanding GANs<br>
</big><big>» Learning relational structures in
time</big><br>
<big>» Learning to represent episodic data</big></td>
</tr>
</tbody>
</table>
<br>
</td>
</tr>
<tr>
<td style="width: 24px;">&nbsp; &nbsp;
&nbsp;&nbsp;
<p>&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp; <br>
</p>
</td>
<td style="vertical-align: top; width: 90%; background-color: white;"><big><big><o:p></o:p></big></big>
<hr style="width: 100%; height: 2px;"><big>
</big><br>
<p class="MsoNormal" style="text-align: justify; font-weight: bold;"><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="New_inductive_biases_in_deep_learning"></a>New inductive biases in deep learning</span></big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big>This research
project explores novel architectural designs for neural networks,
drawing direct inspiration from biological neural systems. By studying
the structural organization of the brain, particularly the columnar
architecture of the neocortex and the routing mechanisms of the
thalamus, we develop modular networks optimized for diverse data types
including matrices, tensors, graphs, and relational data. Our approach
integrates key cognitive mechanisms such as working memory for enhanced
problem-solving capabilities and episodic memory for temporal
information integration. This biomimetic framework aims to improve
neural network performance by incorporating proven solutions from
neuroscience, potentially leading to more robust and adaptable AI
systems.</big></p>
<div style="text-align: center;"><big><big><span><img style="width: 367px; height: 246px;" alt="Column networks" src="figs/column-net.png" v:shapes="_x0000_i1033"><br>
</span></big></big><big><span style="font-style: italic;">Column
Networks, as inspired
by the cortical columns, to solve multi-relational learning</span>.</big><big><br>
</big></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Memory_architectures_for_neural_networks"></a>Memory
architectures for neural networks<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>While current
deep learning systems demonstrate remarkable capabilities in pattern
recognition, they struggle with higher-order cognitive tasks like
complex system manipulation, rapid adaptation, and maintaining coherent
long-term interactions. This research addresses these limitations by
developing novel memory architectures that move beyond simple pattern
matching. Our approach implements explicit memory systems capable of
robust generalization, reduced reliance on rote memorization, and
program-like information storage. This framework forms the foundation
of a comprehensive cognitive architecture that seamlessly integrates
learning, reasoning, and creative processes. By incorporating these
advanced memory mechanisms, we aim to bridge the gap between current AI
capabilities and human-like cognitive flexibility and contextual
understanding.</big></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 519px; height: 345px;" alt="Variational memory encoder decoder" src="figs/VMED.png" v:shapes="Picture_x0020_2"><br>
</span></big></big><big style="font-style: italic;">Generative models with
variational memory</big></div>
<p class="MsoNormal" style="text-align: justify;"><big style="font-style: italic;"><big><o:p></o:p></big></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big>&nbsp;<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Compositional_reasoning_in_"></a>Compositional
reasoning in vision-language domains<br>
</span></big></big><big><br></big><div style="text-align: justify;"><big>Compositionality
is pervasive in nature, language, and our thought processes, enabling
us to understand complex concepts by combining simpler elements.
However, these compositional structures must be uncovered from raw
signals and texts through sophisticated AI methods. Our research
develops neural architectures that learn to identify and manipulate
compositional patterns across visual and linguistic domains. By
integrating computer vision and natural language processing, we model
how basic visual elements combine into objects, scenes, and actions,
while simultaneously capturing how words form phrases, sentences, and
narratives. This compositional understanding enables more robust and
interpretable AI systems capable of human-like reasoning across
modalities. </big><br></div><big>
&nbsp;<br>
<br>
</big>
<div style="text-align: center;"><big><big><span style=""><img style="width: 700px; height: 224px;" alt="A system for Video QA" src="../AI4Science/figs/ProVil.png" v:shapes="Picture_x0020_1"><br>
</span></big></big><big><span style="font-style: italic;">Compositional reasoning over complex queries.</span></big><br>
</div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Learning_for_structural_reasoning"></a>Learning
for relational and causal reasoning<br>
<br>
</span></big></big><div style="text-align: justify;"><big>This research
investigates the fundamental role of relational and causal structures
across natural phenomena, linguistic systems, and cognitive processes.
By recognizing that causality and relationships are core organizing
principles in both physical and abstract domains, we develop novel
computational approaches to capture and reason about these structures.
Our work spans multiple levels, from identifying basic causal
mechanisms in natural systems to understanding how relational thinking
shapes language acquisition and human reasoning. Through advanced
machine learning techniques, we aim to create AI systems that can learn
and leverage these inherent structural patterns, leading to more
sophisticated understanding and decision-making capabilities comparable
to human cognitition.&nbsp; </big><br></div>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big>
<div style="text-align: center;"><big><big><span style=""><img style="width: 579px; height: 289px;" alt="Relational Dynamic Memory Network" src="figs/RDMN.png" v:shapes="Picture_x0020_2147"></span></big></big><big><span style="font-style: italic;"><br>
Relational Dynamic Memory
Network, a model for detecting relations between graphical structures.</span></big></div>

<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"></span><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Indirection_mechanisms_for_better"></a>Indirection
mechanisms for better generalization<br>
<br>
</span></big></big><div style="text-align: justify;"><big>This research
explores fundamental mechanisms enabling human-like generalization and
abstraction in artificial intelligence systems. By investigating how
humans effortlessly transfer knowledge across disparate domains through
analogical reasoning, we develop new computational frameworks that
support sophisticated abstraction capabilities. Our approach
encompasses multiple dimensions: automated discovery of objects and
their relationships, implementation of functional programming
principles, development of indirect reference mechanisms, and
formulation of complex analogies. These components work together to
create AI systems capable of symbolic manipulation and abstract
reasoning, ultimately enabling the kind of extreme generalization
characteristic of human intelligence. This work aims to bridge the gap
between current AI's domain-specific competence and human-level general
intelligence.</big><big></big><br></div><big>
<br>
</big>
<div style="text-align: center;"><big><big><span><img v:shapes="Picture_x0020_1" src="figs/InLay-IQ-prob.png" alt="A system for Video QA" style="width: 700px; height: 224px;"><br>
</span></big></big><big><span style="font-style: italic;">A system for abstracting out
visual details, focusing on relations
between images via an indirection mechanism. This is capable of solving
IQ problems.</span></big></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Theory_of_mind_architectures"></a>Theory of mind
architectures<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>This research
develops artificial intelligence systems capable of understanding and
attributing mental states to others—a fundamental aspect of human
social cognition. Drawing from developmental psychology, cognitive
science, and anthropology, we design architectures that enable AI
agents to engage in sophisticated social interactions. Our approach
encompasses multiple innovations: role-learning frameworks for
cooperative agents, guilt-aversion mechanisms to enhance cooperation,
and memory-augmented neural networks for processing long-term social
experiences. Particular emphasis is placed on developing false-belief
understanding, allowing agents to recognize that others may hold
beliefs incongruent with reality. The project aims to create more
socially intelligent AI systems that can effectively collaborate in
team environments.&nbsp;</big></p>
<p class="MsoNormal" style="text-align: center;"><big><img style="width: 500px; height: 283px;" alt="ToMAGA system." src="figs/ToMAGA.png"></big><big><span style="font-style: italic;"><br>
</span></big></p>
<p class="MsoNormal" style="text-align: center;"><big><span style="font-style: italic;">A system of multi-agents
equipped with
social psychology.</span></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Efficient_exploration_of_combinatorial"></a>Efficient
exploration of combinatorial spaces<br>
</span></big></big>
<p class="MsoNormal" style="text-align: justify;"><big>This research
addresses the fundamental challenge of navigating vast combinatorial
search spaces in critical domains including structural design,
materials science, drug discovery, and network optimization. Given the
exponential growth of possible solutions with problem size, traditional
exhaustive search methods become intractable. We develop novel
generative AI approaches that intelligently balance exploration of new
possibilities, exploitation of promising solutions, and maintenance of
solution diversity. Our methods employ advanced sampling strategies and
learning algorithms to efficiently traverse these complex spaces,
enabling practical solutions to previously intractable problems. This
work aims to accelerate discovery and optimization processes across
multiple scientific and engineering domains.</big></p><p class="MsoNormal" style="text-align: justify;"><big></big></p>
<p class="MsoNormal" style="text-align: center;"><big><img style="width: 700px; height: 286px;" alt="Crystal structures generated using Generative AI" src="figs/generated-crystals.png"></big><big><span style="font-style: italic;"><br>
</span></big></p>
<p class="MsoNormal" style="text-align: center;"><big><span style="font-style: italic;">Crystal structures generated and optimized by several generative AI techniques.</span></big></p>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><br>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Collaborative_priors_for_LLM-powered"></a>Collaborative
priors for LLM-powered multi-agents<br>
</span></big></big><big><br></big><div style="text-align: justify;"><big>
LLMs
are powerful agents, but they are not pre-designed to work with other
agents. This project aims at developing effective priors to enable
LLMs-powered agents to collaborate to achieve greater long-term team
goals.</big><br></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Theory_of_mind_in_LLMs_"></a>Theory of mind in
LLMs<br>
</span></big></big><big><br></big><div style="text-align: justify;"><big>
LLMs
learn to compress the text and then are tuned to follow instructions.
Their ability to understand others' mental states is not a built-in.
This project aims to analyse this ability, and finds new ways to build
theory of mind in to LLMs.</big><br></div><big>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big>&nbsp;</big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
<a name="Scaling_with_sparse_mixture_of_experts_"></a>Scaling
with sparse mixture of experts<br>
</span></big></big><big><br></big><div style="text-align: justify;"><big>
Sparse
mixture of experts is a scalable solution to train LLMs. However, much
of its behaviours is still poorly understood. This project aims to shed
light on the matter.</big><br></div><big>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Representing_and_reasoning_over_noisy_"></a>Representing
and reasoning over noisy data<br>
<br>
</span></big></big><div style="text-align: justify;"><big>The
world is noisy, and system with thousands of sensors are impossible for
human to understand. This project aims at inventing an unified
representation schemes across sensors of multiple types, and reasoning
mechanism over extended period of time.</big><br></div>
<br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big><br>
<big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Structured_reasoning_in_video_"></a>Structured
reasoning in video<br>
</span></big></big><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><br>
</span></big></big><div style="text-align: justify;"><big>Video
is highly structured, but the structural information is hidden behind
flat pixels, making it challenging for direct reasoning over video's
events, objects, characters and stories. This project to uncover such
structures and demonstrate the effects on complex video reasoning tasks.</big><br></div><big>
</big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big>

<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);"></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Human_behaviour_understanding_in_video"></a>Human
behaviour
understanding in video</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big>This
project
aims at a deep understanding of human behaviours seen through (fixed
and
moving) videos in various indoor and outdoor contexts. We build new
models of
trajectories and social interactions, inferring past trigger events,
and predict actions and
intention. <o:p></o:p></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><u>Partners</u>:
iCetana</big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 454px; height: 465px;" alt="Anomaly detection with skeleton trajectories" src="figs/skeleton-anomaly.png" v:shapes="Picture_x0020_2086"><br>
</span></big></big><big><span style="font-style: italic;">Detecting anomalies in video
using skeleton trajectories (last row)</span></big><br>
<hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big></big></div>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Visual_question_answering_and_dialog"></a>Visual
question
answering&nbsp;</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p style="text-align: justify;" class="MsoNormal"><big>We
study the new cognitive
capability of a system to answer new natural questions about an image
or a
video. This is a powerful way to demonstrate the reasoning capacity,
which
involves linguistic, visual processing and high-level symbols
manipulation
skills. In visual dialog, we build a system having a natural multi-turn
chat
with human about a visual object.</big></p>
<p class="MsoNormal" style="margin-left: 18pt;"></p>
<div style="text-align: center;"><big><big><span style=""><img style="width: 568px; height: 207px;" alt="Answering question about video" src="figs/VideoQA-exp.png" v:shapes="Picture_x0020_2085"><br>
</span></big></big><big><span style="font-style: italic;">Answering questions about a
video.</span></big></div>
<p class="MsoCaption" style="text-align: center;" align="center"></p>
<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
</span>
<p class="MsoCaption" style="text-align: center;" align="center"></p>
<div style="text-align: left;"><big><big><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Video_dialog"></a>Video dialog</span></big></big></div>
<p class="MsoCaption" style="text-align: center;" align="center"><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);"></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"></span></big><span style="font-style: italic;"></span><big><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: left;"><big>This
project aims to build a dialog system that can talk about video of
arbitrary length.</big></p>
<p class="MsoCaption" style="text-align: left;"></p><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"></span><font style="font-weight: bold;" size="5"></font><ol>
</ol>
<ul>
</ul>
<ol>
</ol>
</td>
</tr>
</tbody>
</table>
</body></html>