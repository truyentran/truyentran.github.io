<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Truyen Tran</title>













<meta content="en-us" http-equiv="Content-Language">
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">
<style>
body {
font-family: 'Abel';
font-size: 100px;
}
</style></head><body>
<table id="1" style="border-collapse: collapse; width: 976px; height: 12409px;" border="0" bordercolor="#111111" cellpadding="0" cellspacing="5">
<tbody>
<tr>
<td style="border-right: 1px solid; background-color: rgb(0, 0, 0);" v="">&nbsp;</td>
</tr>
<tr>
<td style="border-width: 1px; border-right: 1px solid; vertical-align: top;" v="" rowspan="2">
<p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="http://rdn-consulting.com/blog/wp-content/uploads/2015/12/deepLearningAI500.png" hspace="0"><br>
</p>
<p align="right">[Source:&nbsp;rdn-consulting]</p>
<p align="right"> </p>
<p align="right"><font size="5"><a href="index.html">Home</a></font>&nbsp;
&nbsp; </p>
<br>
&nbsp; <br>
</td>
</tr>
<tr>
<td style="width: 24px;">&nbsp; &nbsp;
&nbsp;&nbsp;
<p>&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp; <br>
</p>
</td>
<td style="vertical-align: top; width: 90%;">
<p style="color: rgb(0, 51, 0);"><font style="color: rgb(0, 102, 0); font-weight: bold;" size="+3">Deep
learning 2.0</font><a name="medical"></a></p>
<table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="vertical-align: top;">
<p class="MsoNormal" style="text-align: justify; color: rgb(0, 102, 0);"><big>Sub-areas</big></p>
            <a href="#New_inductive_biases_"><big>New
inductive
biases</big></a><br>
            <a href="#Memory-Augmented_Neural_Networks"><big>Memory-augmented
neural networks</big></a><br>
            <a href="#Learning_to_reason"><big>Learning
to reason</big></a><br>
            <a href="#Learning_with_less_labels_"><big>Learning
with less labels</big></a><br>
            <a href="#Deep_reinforcement_learning"><big>Deep
reinforcement learning</big></a><ul>





</ul>
<p class="MsoNormal" style="text-align: justify;"><a href="#Preprints"><big><br>
</big></a></p>
            <p class="MsoNormal" style="text-align: justify;"><a href="#Preprints"><big><span style="font-weight: bold;">Publications</span><br>
            </big></a> </p>

</td>
<td style="vertical-align: top;">
<p class="MsoNormal" style="text-align: justify; color: rgb(0, 102, 0);"><big>On
going
projects</big></p>
            <a href="#Human_behaviour_understanding_in_video"><big>Understanding
human behaviours in video</big></a><br>
            <a href="#Visual_question_answering_and_dialog"><big>Visual
question answering and dialog</big></a><br>
            <a href="#AI_for_automated_software_engineering"><big>AI
for automated software engineering</big></a><br>
            <a href="#Deep_learning_for_healthcare_and"><big>Deep
learning for healthcare and genomics</big></a><br>
            <a href="#Exploring_the_molecular_and_materials"><big>Exploring
molecular and materials spaces</big></a><br>
            <a href="#Building_a_smarter_home"><big>Building
a smarter home</big></a><br>
            <big><a href="#Value-aligned_machine_learning">Value-aligned
machine learning</a><br>
            </big><ul>







</ul>
</td>
</tr>
</tbody>
</table>
<p class="MsoNormal" style="text-align: justify;"><big><big>As
an
approach to general
intelligence, we study new ways for differentiable learning with minimal
human
supervision, towards System 2 capability. Deep Learning achieves the goals through compositional
neural
networks, iterative estimation, and differentiable programming. Our
research
program draws certain inspiration from cognitive neuroscience, fused
with
rigorous probabilistic inference. The ultimate long-term goal is devise
a unified
cognitive architecture that guides the learning and reasoning across
scales in space-time.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>The
research program has three broad
aims:<o:p></o:p></big></big></p>
      <big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;"></span></span></span></big></big>
      <div style="margin-left: 40px;"><big><big>» To
<span style="font-style: italic;">understand
intelligence</span> from computational and
cognitive perspectives.<o:p></o:p></big></big><br>
      <big><big>» </big></big><big><big>To <span style="font-style: italic;">design intelligent machines</span>
that are
competent, scalable and robust.<o:p></o:p></big></big><br>
      <big><big>» </big></big><big><big>To <span style="font-style: italic;">solve important data-rich
problems</span> across
living, physical and digital
domains.<o:p></o:p></big></big></div>

<p class="MsoNormal" style="text-align: justify;"><big><big>The
Key Focus is on:<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 102, 0);"><big><big>Sub-area:
<a name="New_inductive_biases_"></a>New
inductive biases</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>Successes
in machine learning
depend critically on having good priors on inductive biases. In deep
learning,
the strongest prior thus far has been neural architectures built on a
small set
of operators (signal filtering, convolution, recurrence, gating, memory
and
attention). We derive modular networks for regular data such as matrix
and
tensor as well as new data such as graphs and relations. We draw our
architectural inspiration from neuroscience including the columnar
structure of
the neocortex for distributed processing, the thalamus structure for
information routing, working memory for problem solving, and episodic
memory
for integrating information over time.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span><!--[if gte vml 1]><v:shapetype
id="_x0000_t75" coordsize="21600,21600" o:spt="75" o:preferrelative="t"
path="m@4@5l@4@11@9@11@9@5xe" filled="f" stroked="f">
<v:stroke joinstyle="miter"/>
<v:formulas>
<v:f eqn="if lineDrawn pixelLineWidth 0"/>
<v:f eqn="sum @0 1 0"/>
<v:f eqn="sum 0 0 @1"/>
<v:f eqn="prod @2 1 2"/>
<v:f eqn="prod @3 21600 pixelWidth"/>
<v:f eqn="prod @3 21600 pixelHeight"/>
<v:f eqn="sum @0 0 1"/>
<v:f eqn="prod @6 1 2"/>
<v:f eqn="prod @7 21600 pixelWidth"/>
<v:f eqn="sum @8 21600 0"/>
<v:f eqn="prod @7 21600 pixelHeight"/>
<v:f eqn="sum @10 21600 0"/>
</v:formulas>
<v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>
<o:lock v:ext="edit" aspectratio="t"/>
</v:shapetype><v:shape id="_x0000_i1033" type="#_x0000_t75" style='width:274.9pt;
height:184.5pt;visibility:visible;mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png"
o:title="Picture2"/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 367px; height: 246px;" alt="Column networks" src="figs/column-net.png" v:shapes="_x0000_i1033"><!--[endif]--></span><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: center; font-style: italic;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big>Column
Networks, as inspired
by the cortical columns, to solve multi-relational learning.<o:p></o:p></big></p>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
<a name="Memory-Augmented_Neural_Networks"></a>Memory-Augmented
Neural Networks</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>Deep
neural networks excel at
function approximation and pattern recognition but fall short on
manipulating
complex, highly dependent systems, possibly due to the lack of an
external
memory. Memory-Augmented Neural Networks (MANNs), which consist of
neural
networks that interact with an external memory matrix, are promising
solutions.
We design new kinds of MANNs with more robust handling of variability,
less
memorization, and stored programs.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape
id="Picture_x0020_2" o:spid="_x0000_i1032" type="#_x0000_t75" style='width:389.25pt;
height:258.4pt;visibility:visible;mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image003.emz"
o:title="" gain="84021f" blacklevel="-655f"/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 519px; height: 345px;" alt="Variational memory encoder decoder" src="figs/VMED.png" v:shapes="Picture_x0020_2"><!--[endif]--></span><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><big><span style=""></span></big><span style="font-style: italic;">Variational
Memory
Encoder-Decoder, as applied for generating a diverse and coherent
dialog.</span></big><big><big><o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify; color: rgb(0, 153, 0); font-weight: bold;"><big><big>Sub-area:
<a name="Learning_to_reason"></a>Learning to
reason</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>We
are concerned about learning
the capability to deduce new knowledge from previously acquired
knowledge in
response to a query. Such behaviours can be demonstrated naturally
using a symbolic
system with a rich set inferential tools, given that the symbols can be
grounded to the sensory world. Deep learning contributes to the
bottom-up
learning of such a reasoning system by resolving the symbol grounding
problem.
Our research aims to build neural architectures that can learn to
exhibit
high-level reasoning functionalities, e.g., answering new questions
over
space-time in a compositional and progressive fashion.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape
id="Picture_x0020_1" o:spid="_x0000_i1031" type="#_x0000_t75" style='width:451.5pt;
height:209.65pt;visibility:visible;mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image005.png"
o:title="overview"/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 602px; height: 280px;" alt="A system for Video QA" src="figs/VideoQA.png" v:shapes="Picture_x0020_1"><!--[endif]--></span><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><big><span style=""></span></big><span style="font-style: italic;">A system for
Video Question
Answering that implements the dual-process theory of reasoning.</span></big><big><big><o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
<a name="Learning_with_less_labels_"></a>Learning
with less labels</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>Learning
with a few explicit
labels is the hallmark of human intelligence. Leveraging unlabelled
data,
either through existing datasets, or through self-exploration, will be
critical
to the next AI generation. We investigate the following sub-areas. <i style="">Representation learning</i>: Learning starts
with representation of latent factors in the data which are invariant
to small
changes and insensitive of noise. <i style="">Generative
models</i>: The ability to model high-dimensional world and to
imagine
the
future is fundamental to AI. We investigate fundamental issues of deep
generative models including stability, generalisation and catastrophic
forgetting in Generative Adversarial Networks, as well as
disentanglement in
Variational Auto-Encoders. <i style="">Continual
learning</i>: We design new learning algorithms that adapt
continually
as new
tasks are introduced, even if the task change is not explicitly marked.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><b style=""><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2084" o:spid="_x0000_i1030"
type="#_x0000_t75" style='width:260.25pt;height:249pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image007.png"
o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 347px; height: 332px;" alt="2D Boltzmann machine" src="figs/OrdRBM.png" v:shapes="Picture_x0020_2084"></span></b></big></big><!--[endif]--></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">A Boltzmann machine for
recommender system.</span><big><b style=""><o:p></o:p></b></big></big></p>
<p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
<a name="Deep_reinforcement_learning"></a>Deep
reinforcement
learning</big></big></p>
<p class="MsoNormal" style="text-align: justify;"><big><big>We
leverage deep neural networks
to enable an agent to perceive the world, act on it, interact with
others,
build theory of mind, imagine the future and receive feedbacks.
Equipped with deep
nets for perception, memory, statistical relational learning, and
reasoning
capabilities, we aim to bring reinforcement learning to a new level.</big></big></p><hr style="width: 100%; height: 2px;">
<p class="MsoNormal" style="text-align: justify; font-weight: bold;"><big><big><big>Ongoing
Projects:</big></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Human_behaviour_understanding_in_video"></a>Human
behaviour
understanding in video</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big>This
project
aims at a deep understanding of human behaviours seen through (fixed
and
moving) videos in various indoor and outdoor contexts. We build new
models of
trajectories and social interactions, and predict actions and
intention. <o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><u>Partners</u>:
iCetana<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2086" o:spid="_x0000_i1029"
type="#_x0000_t75" style='width:340.15pt;height:348.4pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image009.png"
o:title="comparison_between_methods"/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 454px; height: 465px;" alt="Anomaly detection with skeleton trajectories" src="figs/skeleton-anomaly.png" v:shapes="Picture_x0020_2086"></span></big></big><!--[endif]--></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Detecting anomalies in video
using skeleton trajectories (last row).</span><big><o:p></o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Visual_question_answering_and_dialog"></a>Visual
question
answering and dialog</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt;"><big><big>We
study the new cognitive
capability of a system to answer new natural questions about an image
or a
video. This is a powerful way to demonstrate the reasoning capacity,
which
involves linguistic, visual processing and high-level symbols
manipulation
skills. In visual dialog, we build a system having a natural multi-turn
chat
with human about a visual object.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2085" o:spid="_x0000_i1028"
type="#_x0000_t75" style='width:425.65pt;height:155.25pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image011.png"
o:title="qualcomp"/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 568px; height: 207px;" alt="Answering question about video" src="figs/VideoQA-exp.png" v:shapes="Picture_x0020_2085"></span></big></big><!--[endif]--></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Answering questions about a
video.</span><big><o:p></o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="AI_for_automated_software_engineering"></a>AI
for automated
software engineering</span><o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big>We
design
new
deep neural architectures to read the code, fix the bugs, synthesize
programs,
translate between languages, automate the programming process,
understand
developer and support team management. <o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><u>Partners</u>:
University of Wollongong, Samsung.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2145" o:spid="_x0000_i1027"
type="#_x0000_t75" style='width:430.9pt;height:126pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image013.png"
o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 575px; height: 168px;" alt="AI system for code vulerability detection and fixing" src="figs/code-vulnerability.png" v:shapes="Picture_x0020_2145"></span></big></big><!--[endif]--></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big style="font-style: italic;">A system for instant
vulnerability warning
and suggesting fix
patches in code.</big><big><big><o:p></o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Deep_learning_for_healthcare_and"></a>Deep
learning for
healthcare and genomics</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big>This
research
aims at designing neural architectures for representation, clustering
and
prediction both at the patient and the cohort levels, based on the
electronic
medical records and genomics data. For genomics, we map
genotype-phenotype,
answer any genomic queries for a given sequence, predict protein-target
interactions, and learn to generate DNA. The long-term goals include
acquiring
and reasoning about established medical knowledge; having a meaningful
dialog
with patients; recommending the personalized course of medical actions;
and
supporting doctors and hospital managers to improve their precision and
efficiency.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><u>Partners</u>:
Barwon Health, University of Sydney, Northshore Hospital, Institute for
Health
Transformation at Deakin University.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2146" o:spid="_x0000_i1026"
type="#_x0000_t75" style='width:429pt;height:186.4pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image015.png"
o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 572px; height: 249px;" alt="Deepr: A system for health risk prediction" src="figs/deeper.png" v:shapes="Picture_x0020_2146"><!--[endif]--></span><o:p></o:p></big></big></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><big><span style=""></span></big><span style="font-style: italic;">Deepr - a deep
neural net
for scanning medical records, detecting risk motifs and predicting
future
risks.</span></big><big><big><o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><o:p>&nbsp;</o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a name="Exploring_the_molecular_and_materials"></a></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);">Exploring
the
molecular and materials space</span> <o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big>We
use deep
learning to characterise the chemical space, replace expensive physical
computation and experiments, predict molecular properties,
molecular-molecular interactions
and chemical reactions, and generate drug molecules given a set of
desirable
bioactivity properties. In materials design, we design new tools for
understanding the structure and characteristics of materials, searching
for new
alloys, and generating molecules &amp; crystals.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><u>Partners</u>:
Institute of Frontier Materials at Deakin, Japan Institute of Advanced
Science
and Technology.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2147" o:spid="_x0000_i1025"
type="#_x0000_t75" style='width:433.9pt;height:216.4pt;visibility:visible;
mso-wrap-style:square'>
<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image017.png"
o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img style="width: 579px; height: 289px;" alt="Relational Dynamic Memory Network" src="figs/RDMN.png" v:shapes="Picture_x0020_2147"></span></big></big><!--[endif]--></p>
<p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span
style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:
field-separator'></span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Relational Dynamic Memory
Network, a model for detecting interactions among molecules.</span><big><o:p></o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a name="Building_a_smarter_home"></a></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);">Building a
smarter
home</span> <o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big>We
model
human
activities and sensing systems/IoT within a home to assist/empower the
tenants
in their everyday life. An important AI goal is to build a situated
conversational agent that can hold meaningful conversations with
tenants. The
long-term goal is to build a digital companion that lives with us.<o:p></o:p></big></big></p>
<p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><big><u>Partners</u>:
Unisono.<o:p></o:p></big></big></p>
<p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Value-aligned_machine_learning"></a>Value-aligned
machine
learning</span> <o:p></o:p></big></big></p>
<div style="margin-left: 40px; text-align: justify; width: 722px;"><big><big>The
rapid advancement of AI raises new ethical
challenges which pose great risks to humanity if unsolved. We aim to
invent new
machine learning algorithms that teach machine to align values with
humans. We
provide a computational definition of value and derive a generic value
regularisation and optimisation framework. Our framework is
demonstrated via
(a) a conversational system that enables natural human–computer
interaction
through which human values can be regularised in batch or in an online
fashion;
and (b) a value-centric multi-agent learning system that enables agents
to
learn values of others through exchanging of value-laden expressions.
This
project aims to transform machine learning from being
performance-driven to
aligning with human values.</big></big><br>
</div>
<big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
</span>
<hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
</span><br>
<font style="font-weight: bold;" size="5"><a name="Preprints"></a>Preprints</font><font size="5"><span style="text-decoration: underline;"></span></font><br>
<ol>
</ol>
      <div style="margin-left: 40px;"><font size="5"><a href="https://arxiv.org/abs/1702.07021"><span style="text-decoration: underline;">On size fit many: Column
bundle
for multi-X learning</span></a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;">&nbsp;</span></font><font size="5"><span style="font-style: italic;">arXiv
preprint arXiv</span>: </font><font size="5"><span style="font-style: italic;">1702.07021</span>.<br>
      </font><font size="5"><a href="https://arxiv.org/abs/1802.00938">Memory–augmented
neural
retworks for predictive process analytics</a>, Asjad Khan, Hung Le, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Aditya Ghose, Hoa Dam, Renuka Sindhgatta, <span style="font-style: italic;">arXiv
preprint
arXiv:1802.00938.<br>
</span></font><font size="5"><a href="https://arxiv.org/abs/1703.01454">Learning deep matrix
representations</a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1703.01454.<br>
</span></font><font size="5"><a href="https://arxiv.org/abs/1808.04247">Relational dynamic
memory
networks</a>, Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;Svetha
Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1808.04247.<br>
</span></font><font size="5"><a href="https://arxiv.org/abs/2002.03519">Self-attentive associative memory</a>, Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh<span style="font-style: italic;">,&nbsp;</span></font><font size="5"><span style="font-style: italic;">arXiv preprint arXiv:</span></font><font size="5"><span style="font-style: italic;">2002.03519.</span></font></div>
<p align="justify"><font style="font-weight: bold;" size="5">Publications</font><font size="5"><a name="Publications"></a></font></p>
<ol>
</ol>
      <div style="margin-left: 40px;"><font size="5"><a href="https://arxiv.org/abs/2004.14603"><span style="text-decoration: underline;">Dynamic language binding in
relational visual reasoning</span></a>, </font><font size="5">Thao Minh Le, Vuong
Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>,<span style="font-style: italic;"> </span></font><font size="5"><span style="font-style: italic;"> IJCAI'20</span>, July 11-17, Yokohama, Japan.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;"></span></a></font><font size="5"><a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;">Neural reasoning, fast and slow, for video question answering</span></a>, Thao Minh Le, Vuong Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">IJCNN'20</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1909.04307">Learning transferable domain priors for safe exploration in reinforcement learning</a><span style="font-style: italic;"></span>, Thommen G Karimpanal, Santu Rana, Sunil Gupta, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh<span style="font-style: italic;">, IJCNN'20</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1807.04015">On catastrophic forgetting and mode collapse in Generative Adversarial Networks</a>, Thanh-Tung, Hoang, and <span style="font-weight: bold;">Truyen Tran</span>, </font><font size="5"><span style="font-style: italic;">IJCNN'20</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/2002.10698"><span style="text-decoration: underline;">Hierarchical conditional relation networks for video question answering</span></a>, Thao Minh Le, Vuong Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>,&nbsp;</font><font size="5"><span style="font-style: italic;">CVPR'20.</span></font><br>
      <font size="5"><a href="https://baicsworkshop.github.io/pdf/BAICS_28.pdf"><span style="text-decoration: underline;">Theory of mind with guilt aversion facilitates cooperative reinforcement learning</span></a>, </font><font size="5">Dung Nguyen, Truyen Tran, Svetha Venkatesh,<span style="font-style: italic;"> </span></font><font size="5"><span style="font-style: italic;">ICLR 2020 workshop on Bridging AI and Cognitive Science</span>, April 26-30, Addis Ababa, Ethiopia. <span style="font-style: italic;"></span></font><br>
      <font size="5"><span style="font-style: italic;">
          </span></font><font size="5"><a href="https://arxiv.org/abs/1906.08862">Neural stored-program memory</a>, Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh<span style="font-style: italic;">, ICLR'20.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1908.09961">Theory and evaluation metrics for learning disentangled representations</a>, K Do, <span style="font-weight: bold;">T Tran</span><span style="font-style: italic;">, ICLR'20.</span></font><br>
      <font size="5"><a href="https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-020-0658-5">DeepTRIAGE:
Interpretable and individualised biomarker scores using attention
mechanism for the classification of breast cancer sub-types</a>, Adham Beykikhoshk, Thom P Quinn, Sam C Lee, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh,<span style="font-style: italic;"> B</span></font><font size="5"><span style="font-style: italic;">MC Medical Genomics, 2020</span></font><font size="5"><span style="font-style: italic;">MC Medical Genomics, 2020</span></font>
      <br>
      <font size="5"><a href="https://arxiv.org/abs/1812.09441">Graph transformation
policy
network for chemical reaction prediction</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;">KDD'19</span>.</font><br>
      <font size="5">
          </font><font size="5"><a href="https://arxiv.org/abs/1903.03295"><span style="text-decoration: underline;">Learning regularity in
skeleton
trajectories for anomaly detection in videos</span></a>,
Romero Morais,
Vuong Le, Budhaditya Saha, <span style="font-weight: bold;">Truyen
Tran</span>,
Moussa Reda Mansour, Svetha Venkatesh, <span style="font-style: italic;">CVPR'19</span>.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1802.00921">Lessons
learned from using a deep tree-based model for software defect
prediction in practice</a>, Hoa Khanh Dam, Trang Pham, Shien Wee Ng, <span style="font-weight: bold;">Truyen Tran</span>, John Grundy, Aditya Ghose, Taeksu Kim, Chul-Joo Kim, <span style="font-style: italic;">MSR'19.</span></font><br>
      <font size="5"><a href="https://openreview.net/forum?id=r1xlvi0qYm"><span style="text-decoration: underline;">Learning to remember
more with
less memorization</span></a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.</font><br>
      <font size="5"><a href="https://openreview.net/forum?id=ByxPYjC5KQ"><span style="text-decoration: underline;">Improving generalization
and
stability of Generative Adversarial Networks</span></a>, Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.</font><br>
      <font size="5">
      </font><font size="5"><a href="https://arxiv.org/abs/1811.06060"><span style="text-decoration: underline;">Incomplete conditional
density
estimation for fast materials discovery</span></a>, Phuoc
Nguyen,
Truyen Tran,&nbsp;</font><font size="5">Sunil
Gupta, </font><font size="5"> Svetha Venkatesh. <span style="font-style: italic;"></span></font><font size="5"><span style="font-style: italic;">SDM'19</span></font><font size="5">.</font>
      <br>
      <font size="5"><a href="https://truyentran.github.io/papers/main-CCI.pdf">Neural
reasoning for chemical-chemical interaction</a>.&nbsp;</font><font size="5">Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh,</font><font size="5"> <span style="font-style: italic;">NIPS 2018 Workshop on Machine
Learning for
Molecules and Materials</span>.</font>
      <br>
      <font size="5"><a href="https://arxiv.org/abs/1804.00293">Attentional
multilabel
learning over graphs: A message passing approach</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Thin Nguyen, SvethaVenkatesh,&nbsp;<span style="font-style: italic;">Machine
Learning, 2019.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1708.02368">Automatic feature
learning for
predicting vulnerable software components</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang
Pham, &nbsp;Shien
Wee Ng, John Grundy, Aditya Ghose,<span style="font-style: italic;">
IEEE Transactions on Software Engineering, </span>2019.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1807.09950">Variational memory
encoder-decoder,</a> Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Thin Nguyen, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">NIPS'18.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1802.00662">Dual Memory Neural
Computer
for Asynchronous Two-view Sequential Learning</a>, Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, S vetha Venkatesh,
<span style="font-style: italic;">KDD'18.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;">On catastrophic
forgetting and
mode collapse in Generative Adversarial Networks</span></a>,
Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">; ICML
Workshop on Theoretical Foundations
and Applications of Deep Generative Models</span>, 2018<span style="font-style: italic;">.</span></font><br>
      <font size="5"><span style="font-style: italic;">
      </span></font><font size="5"><a href="https://arxiv.org/abs/1801.02622">Graph
Memory Networks for Molecular Activity Prediction</a>,&nbsp;</font><font size="5">Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh,</font><font size="5"> <span style="font-style: italic;">ICPR'18</span>.&nbsp;</font><br>
      <div style="margin-left: 40px;"><font size="5">Prelim version appears
at </font><font size="5"><span style="font-style: italic;">NIPS Workshop on Deep
learning for
physical sciences</span>, 2017.<span style="text-decoration: underline;"></span></font><br>
      </div>
      <font size="5"><a href="https://arxiv.org/abs/1801.08641">Knowledge Graph
Embedding with
Multiple Relation Projections</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh,&nbsp;<span style="font-style: italic;">ICPR'18.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1802.00948">Resset:
A Recurrent Model for Sequence of Sets with Applications to Electronic
Medical Records</a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">, IJCNN'18.</span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1802.03689">Dual control memory
augmented neural networks for treatment
recommendations</a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">PAKDD'18</span>.<span style="font-style: italic;"> </span></font><br>
      <font size="5"><a href="https://dl.acm.org/citation.cfm?id=3194952"><span style="text-decoration: underline;">Predicting
components for issue reports using deep learning with information
retrieval</span></a>, Morakot Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang Pham, Aditya
Ghose, <span style="font-style: italic;">International
Conference on Software
Engineering (ICSE'18) - Poster Track</span></font><font size="5"><span style="font-style: italic;"></span></font><br>
      <font size="5"><a href="papers/outlier_kais17.pdf"><span style="text-decoration: underline;">Energy-Based Anomaly
Detection for
Mixed Data</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">Knowledge
and Information Systems</span>, 2018.&nbsp;</font><font size="5">Earlier
works are: </font><br>
      <font size="5"><a href="https://arxiv.org/abs/1610.06249">Multilevel
Anomaly Detection for Mixed Data</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;"></span></font><font size="5"><span style="font-style: italic;">arXiv
preprint arXiv</span>: </font><font size="5"><span style="font-style: italic;">1610.06249</span>.</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien Do,
<span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1609.00489">A
deep learning model for estimating story points</a>, Morakot
Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Trang Pham, Aditya Ghose, Tim Menzies, <span style="font-style: italic;">IEEE Transactions on Software
Engineering,
2018.</span></font><br>
      <font size="5"><a href="papers/nips17-ml4h.pdf"><span style="text-decoration: underline;">Finding Algebraic
Structure of
Care in Time: A Deep Learning Approach</span></a>, Phuoc
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">NIPS
Workshop on Machine Learning for
Health (ML4H)</span>.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1708.04357"><span style="text-decoration: underline;">Graph Classification via
Deep
Learning with Virtual Nodes</span></a> Trang Pham, </font><font size="5"><span style="text-decoration: underline;"></span><span style="font-weight: bold;">Truyen Tran</span>, Hoa
Dam, Svetha
Venkatesh, <span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiG 2017)</span>.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1707.05010"><span style="text-decoration: underline;">Deep Learning to Attend
to Risk in
ICU</span></a>,&nbsp;Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">IJCAI'17
Workshop on Knowledge Discovery in Healthcare II: Towards Learning
Healthcare Systems</span> <span style="font-style: italic;">(KDH
2017</span>)</font><font size="5">.<span style="text-decoration: underline;"></span></font><font size="5"><span style="text-decoration: underline;"></span></font><br>
      <font size="5"><a href="https://arxiv.org/abs/1703.01454"><span style="text-decoration: underline;">Learning Recurrent
Matrix
Representation</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;"> </span></font><font size="5"><span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiF 2017)</span></font><br>
      <font size="5"><a href="https://www.researchgate.net/profile/Truyen_Tran/publication/314024495_Hierarchical_semi-Markov_conditional_random_fields_for_deep_recursive_sequential_data/links/5a585845a6fdccf0ad1a4ce9/Hierarchical-semi-Markov-conditional-random-fields-for-deep-recursive-sequential-data.pdf"><span style="text-decoration: underline;">Hierarchical semi-Markov
conditional random fields for deep recursive sequential data</span></a>,
<span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Hung Bui, Svetha Venkatesh, &nbsp;<span style="font-style: italic;">Artificial Intelligence</span>,
Volume 246, May 2017, Pages 53–85.&nbsp;(Extension of the <a href="papers/truyen_nips08.pdf">NIPS'08 paper</a>).</font><br>
      <font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S1532046417300710">Predicting
healthcare trajectories from medical records: A deep learning approach</a>,</font><font size="5">Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">Journal
of
Biomedical Informatics</span>, April 2017, DOI:
10.1016/j.jbi.2017.04.001. [<a href="http://arxiv.org/abs/1602.00357">Tech
report PDF</a>].</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1607.07519"><span style="text-decoration: underline;">Deepr: A Convolutional
Net for Medical Records</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Nilmini
Wickramasinghe, Svetha Venkatesh,&nbsp;</font><font size="5">&nbsp;</font><font size="5"><span style="font-style: italic;">IEEE Journal of Biomedical
and
Health Informatics</span>,&nbsp;</font><font size="5">vol.
21, no. 1, pp. 22–30, Jan. 2017, Doi: 10.1109/JBHI.2016.2633963</font><font size="5">.</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1609.04508">Column
Networks for Collective Classification</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh Phung, Svetha
Venkatesh, <span style="font-style: italic;"></span></font><font size="5"><span style="font-style: italic;">AAAI'17</span></font><br>
      <font size="5"><a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien Do,
<span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font><br>
      <font size="5"><a href="https://arxiv.org/abs/1609.08752"><span style="text-decoration: underline;">Stabilizing Linear
Prediction Models using Autoencoder</span></a>, Shivapratap
Gopakumara, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh, <span style="font-style: italic;">International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1608.02715">A
deep language model for software code</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span> and
Trang Pham, <span style="font-style: italic;">FSE NL+SE
2016</span>.</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1608.00092">DeepSoft:
A vision for a deep model of software</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, John
Grundy and Aditya Ghose, <span style="font-style: italic;">FSE
VaR</span> 2016.<a href="https://truyentran.github.io/papers/deepr.pdf"><span style="text-decoration: underline;"></span></a></font><br>
      <font size="5"><a href="papers/flexible_gating.pdf">Faster
Training of Very Deep Networks Via p-Norm Gates</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">ICPR'16</span>.</font><br>
      <font size="5"><a href="http://arxiv.org/abs/1602.00357">DeepCare:
A Deep Dynamic Memory Model for Predictive Medicine</a>, Trang
Pham,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh,<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD'16</span>, Auckland,
NZ, April 2016.&nbsp;</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/bdm16.pdf">Neural
Choice by Elimination via Highway Networks</a>,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung and Svetha Venkatesh,&nbsp;<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD workshop on Biologically
Inspired Techniques for Data Mining (BDM'16)</span><span class="Apple-converted-space"></span>, April 19-22
2016, Auckland, NZ.</font><br>
      <font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X"><span style="text-decoration: underline;">Graph-induced restricted
Boltzmann machines for document modeling</span></a>, Tu Dinh
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Information
Sciences</span><span style="font-style: italic;">.
doi:10.1016/j.ins.2015.08.023.</span></font>
      <br>
      <font size="5"><a href="http://www.uow.edu.au/%7Ehoa/papers/ASE2015-preprint-choetkiertikul-dam-tran-ghose.pdf"><span style="text-decoration: underline;">Predicting delays in
software projects using networked classification</span></a>,
Morakot Choetikertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Aditya
Ghose,<span style="font-style: italic;"> 30th IEEE/ACM
International Conference on Automated Software Engineering</span>,
November 9–13, 2015 Lincoln, Nebraska, USA.</font><br>
      <font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S1532046415000143">Learning
vector
representation of medical objects via EMR-driven nonnegative restricted
Boltzmann machines (e-NRBM)</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Tu
Dinh Nguyen, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Biomedical Informatics</span>, 2015, pii:
S1532-0464(15)00014-3. doi: 10.1016/j.jbi.2015.01.012.&nbsp;</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/aaai15_main.pdf">Tensor-variate
Restricted Boltzmann Machines</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">AAAI</span>
2015.&nbsp;</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">Thurstonian
Boltzmann machines: Learning from multiple inequalities</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of
30th
International Conference in Machine Learning (ICML’13)</span>,
Atlanta, USA, June, 2013.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Learning
parts-based representations with Nonnegative Restricted Boltzmann
Machine</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Machine Learning Research (JMLR) Workshop and Conference
Proceedings, Vol. 29, Proc. of 5th Asian Conference on Machine
Learning,</span> Nov 2013.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Latent
patient profile modelling and
applications with Mixed-Variate Restricted Boltzmann Machine</a>,
Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh,&nbsp; In<span style="font-style: italic;">
Proc. of 17th
Pacific-Asia Conference on Knowledge Discovery and Data Mining
(PAKDD’13)</span>, Gold Coast, Australia, April 2013.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/icme13_142.pdf">Learning
sparse latent representation and
distance metric for image retrieval</a>, Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of IEEE
International Conference on Multimedia and Expo (ICME)</span>,
San Jose, California, USA, July 2013. </font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/acml12_OSM_revised.pdf">Learning
from Ordered Sets and
Applications in Collaborative Ranking</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">Cumulative
Restricted
Boltzmann Machines for Ordinal&nbsp;Data Analysis</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_fusion12.pdf">Embedded
Restricted Boltzmann
Machines for Fusion of Mixed Data Types and Applications in Social
Measurements Analysis</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 15-th
International Conference on&nbsp;Information
Fusion&nbsp;(FUSION-12)</span>,
Singapore, July 2012.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">A
Sequential Decision Approach
to Ordinal Preferences in Recommender Systems</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 25-th Conference on Artificial Intelligence (AAAI-12)</span>,
Toronto,
Canada, July 2012.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_icme12.pdf">Learning
Boltzmann Distance Metric for Face Recognition</a>,&nbsp;<span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of&nbsp;IEEE
International Conference on Multimedia &amp; Expo
(ICME-12)</span>, Melbourne, Australia, July 2012.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/tran_phung_venkatesh_acml11.pdf">Mixed-Variate
Restricted
Boltzmann Machines</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung and Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 3rd Asian Conference on Machine Learning (ACML2011)</span>,
Taoyuan, Taiwan, Nov 2011.</font><br>
      <font size="5"><a href="https://truyentran.github.io/papers/gupta_kdd10.pdf">Nonnegative
Shared Subspace
Learning and Its Application to Social Media Retrieval</a>, Sunil
Gupta, Dinh Phung, Brett. Adams, <span style="font-weight: bold;">Tran
The Truyen</span><span style="font-style: italic;">
Proc. of 16th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining</span>, 25-28 Jul,
Washington DC, 2010.
and Svetha Venkatesh, In</font><br>
      <font size="5"><a href="http://truyen.vietlabs.com/papers/uai09_final.pdf">Ordinal
Boltzmann Machines for
Collaborative Filtering</a>. <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung and Svetha Venkatesh. In <span style="font-style: italic;">Proc. of 25th
Conference on Uncertainty in Artificial Intelligence</span>,
June, 2009, Montreal, Canada. <span style="font-weight: bold; color: rgb(204, 0, 0);">Runner-up
for the best paper award</span>.</font><br>
      <font size="5"><a href="papers/hcrf_fast.pdf">MCMC
for Hierarchical
Semi-Markov Conditional Random Fields</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Q. Phung, Svetha Venkatesh and Hung H. Bui. In <span style="font-style: italic;">NIPS'09
Workshop on Deep Learning for Speech
Recognition and Related Applications</span>. December, 2009,
Whistler, BC, Canada</font><br>
      <font size="5"><a href="papers/truyen_nips08.pdf">Hierarchical
Semi-Markov
Conditional Random Fields for Recursive Sequential Data</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung, Hung H. Bui, and Svetha Venkatesh.
In <span style="font-style: italic;">Proc.
of&nbsp;21st
Annual Conference on Neural Information Processing Systems</span>,
Dec 2008, Vancouver, Canada. [See <a href="papers/truyen_hcrf_tr08.pdf">technical
report</a>
and <a href="papers/thesis.pdf">thesis</a>
for more
details and
extensions.]</font><br>
      <font size="5"><a href="papers/truyen_cvpr06.pdf">AdaBoost.MRF:
Boosted Markov
random forests and application to multilevel activity recognition</a>,
<span style="font-weight: bold;">Truyen
Tran</span>, Dinh&nbsp;Quoc Phung, Hung&nbsp;Hai Bui,
and Svetha Venkatesh. In <span style="font-style: italic;">Proc.
of&nbsp; IEEE Conference
on Computer Vision and Pattern Recognition</span>,
volume Volume 2, pages 1686-1693, New York, USA, June 2006.</font></div>

          




 
<ul>


















</ul>
<ol>
</ol>
</td>
</tr>
</tbody>
</table>
</body></html>