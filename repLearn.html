<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Truyen Tran</title>




  

  
  
  <meta content="en-us" http-equiv="Content-Language">

  
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

  
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8">

  
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">

  
  <style>
body {
font-family: 'Abel';
font-size: 100px;
}
  </style></head><body>
<table id="1" style="border-collapse: collapse; width: 1029px; height: 6059px;" border="0" bordercolor="#111111" cellpadding="0" cellspacing="5">

  <tbody>
    <tr>
      <td style="border-right: 1px solid; background-color: rgb(0, 0, 0);" v="">&nbsp;</td>
      
      
    </tr>
    <tr>
      <td style="border-width: 1px; border-right: 1px solid; vertical-align: top;" v="" rowspan="2">
      <p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="http://rdn-consulting.com/blog/wp-content/uploads/2015/12/deepLearningAI500.png" hspace="0"><br>
      </p>
      <p align="right">[Source:&nbsp;rdn-consulting]</p>
      
      <p align="right">
      </p>
      <p align="right"><font size="5"><a href="index.html">Home</a></font>&nbsp;
&nbsp; </p>
      <br>&nbsp;
      <br>
      
      </td>
    </tr>
    <tr>
      <td style="width: 24px;">&nbsp; &nbsp; &nbsp;&nbsp;
      
      <p>&nbsp;</p>
      <p>&nbsp;&nbsp;&nbsp; <br>
</p>
      </td>
      <td style="vertical-align: top; width: 90%;">
      <p style="color: rgb(0, 51, 0);"><font style="color: rgb(0, 102, 0); font-weight: bold;" size="+3">Deep
learning and beyond</font><a name="medical"></a></p>
      <p><font size="5"><b>Deep learning</b>
is learning
through multiple steps of data transformation
in a compositional fashion. It enables <b>end-to-end learning</b>
from raw data
to tasks of interests. We target the following sub-problems:</font></p>
      <p><font size="5"><span style="font-weight: bold;">»
<span style="color: rgb(153, 0, 0);">Representation learning</span></span><o:p></o:p></font></p>
      <p><font size="5">The learning starts
with representation. This is
because raw data may lie on
hidden manifolds and contain noise and thus it may not be appropriate
for tasks
at hand. The goal of <b>representation learning</b> is to
discover latent
factors in the data which are invariant to small changes and
insensitive of
noise. Learning curve for the later stages will be much easier (e.g.,
better
linearity and pre-conditioning)&nbsp;and the final performance will
be improved
(e.g., due to noise reduction and invariance promotion).</font></p>
      <ul>
        <li><font size="5">Mixed-type data
with Mixed-variate RBM and
Thurstonian Boltzmann Machine [Published in&nbsp; <a href="https://truyentran.github.io/papers/tran_phung_venkatesh_acml11.pdf">ACML'11</a>,
          <a href="https://truyentran.github.io/papers/truyen_etal_fusion12.pdf">FUSION'12</a>,
          <a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">ICML'13</a>, ADMA'16, KAIS'18]</font></li>
        <li><font size="5">Non-negative data
with Nonnegative RBM
[Published in: <a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">ACML'13</a>].</font></li>
        <li><font size="5">Ordered partitions
&nbsp;[Published in <a href="https://truyentran.github.io/papers/Truyen_etal_sdm11.pdf">SDM'11</a>,
          <a href="https://truyentran.github.io/papers/acml12_OSM_revised.pdf">ACML'12</a>]</font></li>
        <li><font size="5">Matrices and
tensors&nbsp; [Published in: <a href="https://truyentran.github.io/papers/uai09_final.pdf">UAI'09</a>,
          <a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">AAAI'12</a>,
          <a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">ACML'12</a>,
          <a href="https://truyentran.github.io/papers/aaai15_main.pdf">AAAI'15</a>,<a href="https://arxiv.org/abs/1703.01454">ReLiG'17</a>]</font></li>
      </ul>
      <p><font size="5"><span style="font-weight: bold;">» </span><span style="font-weight: bold; color: rgb(102, 102, 0);">Architecture engineering</span></font></p>
      <p><font size="5">A major part of modern
deep learning is
architecture
engineering, i.e., designing a neural network that best fits the
problems at hand, and at the same time, enables faster learning.</font></p>
      <ul>
        <li><font size="5">Statistical
relational learning [Published in: <a href="http://www.uow.edu.au/%7Ehoa/papers/ASE2015-preprint-choetkiertikul-dam-tran-ghose.pdf">ASE'15</a>,
          <a href="https://arxiv.org/abs/1609.04508">AAAI'17</a>; Submitted to: <a href="https://arxiv.org/abs/1804.00293">MLJ'18</a>]</font></li>
        <li><font size="5">Distance metrics
[Published in<a href="https://truyentran.github.io/papers/truyen_etal_icme12.pdf">
ICME'13</a>]</font></li>
        <li><font size="5">Motifs in medical
records [<a href="https://truyentran.github.io/papers/deepr.pdf">Deepr</a>]</font></li>
        <li><font size="5">Irregular timing [<a href="https://truyentran.github.io/papers/pakdd_16.pdf">DeepCare</a>,<a href="https://arxiv.org/abs/1707.05010">ICU</a>]</font></li>
        <li><font size="5">Flows with
interventions [<a href="https://truyentran.github.io/papers/pakdd_16.pdf">DeepCare</a>]</font></li>
        <li><font size="5">Compositional
multiscale [<a href="https://truyentran.github.io/papers/fse-vision-2016.pdf">DeepSoft</a>]</font></li><li><font size="5">Rank and
permutation [Published in <a href="https://truyentran.github.io/papers/bdm16.pdf">BDM</a>]</font></li>
        <li><font size="5">Smart gates
(Recurrent highway nets, GRU)
[Published in <a href="https://truyentran.github.io/papers/flexible_gating.pdf">ICPR'16</a>]</font></li>
        <li><font size="5">Time-gap and
intervention-induced gates
[DeepCare]</font></li>
        <li><font size="5">Multi-layered
sequences [<a href="https://truyentran.github.io/papers/truyen_cvpr06.pdf">Adaboost.MRF</a>, </font><font size="5">HSCRF</font><font size="5">].</font></li><li><font size="5">Sequence of sets [Published in: <a href="https://arxiv.org/abs/1802.00948">IJCNN'18</a>]<br></font></li>
      </ul>
      <p><font size="5"><span style="font-weight: bold;">»
<span style="color: rgb(0, 102, 0);">Neuroscience-inspired AI</span></span><span style="font-weight: bold;"></span></font></p>
      <p><font size="5">The interplay between neuroscience and AI is
super
rich, like never before. Neuroscience inspires and validates AI.
Whereas AI offers ideas, simulations and study tools for neuroscience.</font></p>
      <ul>
        <li><font size="5"><span style="font-style: italic;">Columnar structure</span>: Relational
domains [AAAI'17]</font></li>
        <li><font size="5"><span style="font-style: italic;">Thalamus-like structure</span>: fibre bundle to
connect input-output [<a href="https://arxiv.org/abs/1702.07021">Column Bundle</a>]</font></li><li><font size="5"><span style="font-style: italic;">Episodic memory</span>: Time-dependent inputs
[PAKDD'16, JBI'17], attention&nbsp;</font><font size="5">[</font><font size="5">KDH'17]</font></li>
        <li><font size="5"><span style="font-style: italic;">Working memory</span>: </font><font size="5">Matrix
as a representation [</font><font size="5">ReLiG'17]</font></li>
        <li><font size="5"><span style="font-style: italic;">Working memory</span>: Central executive - virtual
column [</font><font size="5">ReLiG'17, <a href="https://arxiv.org/abs/1801.02622">ICPR'18</a></font><font size="5">]</font></li><li><font size="5"><span style="font-style: italic;">Working memory</span>: Dual control [PAKDD'18], dual mem [KDD'18], variational reads [NIPS'18]</font></li>
        <li><font size="5"><span style="font-style: italic;">Relational reasoning</span>: Recurrent relational memory [<a href="https://arxiv.org/abs/1703.01454">MatrixRNN</a>]<span style="font-style: italic;"><br></span></font></li></ul><p><font size="5"><span style="font-weight: bold;">» <span style="color: rgb(102, 51, 102);">Generative models</span><span style="color: rgb(0, 102, 0);"></span></span></font></p><p><font size="5">The
ability to model high-dimensional world and to imagine the future is
fundamental to AI. Deep generative models offer great promises.</font></p><ul><li><font size="5"><span style="font-style: italic;">GAN</span>: mode collapse and catastrophic forgetting [ICML'18 WS]</font></li><li><font size="5"><span style="font-style: italic;">VAE</span>: Memory-enabled sequential VAE [In submission]<br></font></li></ul>
      <font size="5"><span style="font-weight: bold;">»
<span style="color: rgb(0, 0, 153);">Non-cognitive apps</span><br>
      </span><br>
Deep
learning is currently flooded with work in vision, speech and NLP, the
areas where humans perform well without any difficulties. But the world
isn't just about see, listen and read. The world is also about living,
learning, working, and staying safe. This is where our research comes
to play.</font><br><ul>
        <li><font size="5">Drug design [IJCAI'17 WS, GraphMem, MLJ Submit]</font></li><li><font size="5">Healthcare
analytics [DeepCare, Deepr, Resset]</font></li>
        <li><font size="5">Software analytics
[DeepSoft, Stacked
Inference, DL-RNN]</font></li>
        <li><font size="5">Cybersecurity [ADMA'16, KAIS'18]</font></li>
        <li><font size="5">Process
analytics [<a href="https://arxiv.org/abs/1802.00938">MANN</a>]</font></li>
        <li><font size="5">Complex survey
analysis [Mv.RBM, TBM]</font></li>
        <li><font size="5">Recommendation [OBM]</font></li>
        <li><font size="5">Choice and decision
[NCBE]</font></li>
        <li><font size="5">Medical imaging
[Tv.RBM]</font></li><li><font size="5">Knowledge engineering [ICLR'18]<br></font></li>
      </ul>
      <hr style="height: 1px;" noshade="noshade"><br>
      <br>
      <font style="font-weight: bold;" size="5">Preprints</font><font size="5"><span style="text-decoration: underline;"></span></font><br>
      <ol>
        <li><font size="5"><a href="https://arxiv.org/abs/1702.07021"><span style="text-decoration: underline;">On Size Fit Many: Column
Bundle for Multi-X Learning</span></a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;">&nbsp;</span></font><font size="5"><span style="font-style: italic;">arXiv
preprint arXiv</span>: </font><font size="5"><span style="font-style: italic;">1702.07021</span>.</font></li>
        <li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1603.01359"><span style="text-decoration: underline;">Learning deep
representation of multityped objects and tasks</span></a>,&nbsp;<span style="font-weight: bold;">Truyen Tran</span>, D.
Phung, and S. Venkatesh,&nbsp;<span style="font-style: italic;">arXiv
preprint arXiv</span>: <span style="font-style: italic;">1603.01359.</span></font></li>
        <li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1708.02368">Automatic feature learning for
vulnerability prediction</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang Pham, &nbsp;Shien
Wee Ng, John Grundy, Aditya Ghose,<span style="font-style: italic;">&nbsp;arXiv
preprint&nbsp;</span></font><font size="5"><span style="font-style: italic;">arXiv: </span></font><font size="5"><span style="font-style: italic;">1708.02368</span></font></li><li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1802.00921">A deep tree-based model for software defect prediction</a>, HK Dam, T Pham, SW Ng, <span style="font-weight: bold;">T Tran</span>, J Grundy, A Ghose, T Kim, CJ Kim, <span style="font-style: italic;">arXiv preprint arXiv:1802.00921</span></font></li><li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1802.00938">Memory–Augmented Neural Networks for Predictive Process Analytics</a>, A Khan, H Le, K Do, <span style="font-weight: bold;">T Tran</span>, A Ghose, H Dam, R Sindhgatta, <span style="font-style: italic;">arXiv preprint arXiv:1802.00938</span></font></li><li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1804.00293">Attentional multilabel learning over graphs: A message passing approach</a>, K Do, <span style="font-weight: bold;">T Tran</span>, T Nguyen, S Venkatesh, <span style="font-style: italic;">arXiv preprint arXiv:1804.00293</span></font></li><li class="itemize"><font size="5"><span style="font-style: italic;"></span><a href="https://arxiv.org/abs/1703.01454">Learning deep matrix representations</a>, K Do, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, <span style="font-style: italic;">arXiv preprint arXiv:1703.01454</span><br><span style="font-style: italic;"><br></span></font></li>
      </ol>
      <ul>
        <ul>
          <ul>
            <ul>
              <ol>
              </ol>
            </ul>
          </ul>
        </ul>
      </ul>
      <p align="justify"><font style="font-weight: bold;" size="5">Publications</font><font size="5"><a name="Publications"></a></font></p>
      <ol>
        
        <li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1802.00662">Dual Memory Neural Computer for Asynchronous Two-view Sequential Learning</a>, H Le, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, <span style="font-style: italic;">KDD'18</span></font></li><li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;">On catastrophic forgetting and mode collapse in Generative Adversarial Networks</span></a>, H Thanh-Tung, <span style="font-weight: bold;">T Tran</span>, S Venkatesh<span style="font-style: italic;">; ICML Workshop on Theoretical Foundations and Applications of Deep Generative Models</span>, 2018<span style="font-style: italic;">.<br></span></font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1801.02622">Graph
Memory Networks for Molecular Activity Prediction</a>,&nbsp;</font><font size="5">Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh,</font><font size="5"> <span style="font-style: italic;">ICPR'18</span>.&nbsp;</font></li>
<ul><li><font size="5">Prelim version appears at </font><font size="5"><span style="font-style: italic;">NIPS Workshop on Deep learning for
physical sciences</span>, 2017.<span style="text-decoration: underline;"></span></font></li></ul><li class="itemize"><font size="5"><a href="https://arxiv.org/abs/1801.08641">Knowledge Graph Embedding with Multiple Relation Projections</a>, K Do, <span style="font-weight: bold;">T Tran</span>, S Venkatesh,&nbsp;<span style="font-style: italic;">ICPR'18.</span></font></li><li><font size="5"><a href="https://arxiv.org/abs/1802.00948">Resset: A Recurrent Model for Sequence of Sets with Applications to Electronic Medical Records</a>, P Nguyen, <span style="font-weight: bold;">T Tran</span>, S Venkatesh<span style="font-style: italic;">, IJCNN'18.</span></font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1802.03689"> Dual control memory augmented neural networks for treatment recommendations</a>, H Le, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, <span style="font-style: italic;">PAKDD'18</span>.<span style="font-style: italic;"> </span></font>
          <br>
<font size="5"><span style="text-decoration: underline;"></span></font></li>

        <li><font size="5"><a href="https://dl.acm.org/citation.cfm?id=3194952"><span style="text-decoration: underline;">Predicting
components for issue reports using deep learning with information
retrieval</span></a>, M Choetkiertikul, HK Dam, <span style="font-weight: bold;">T Tran</span>, T Pham, A Ghose, <span style="font-style: italic;">International Conference on Software
Engineering (ICSE'18) - Poster Track<br>
          </span></font></li>

        <li><font size="5"><a href="papers/outlier_kais17.pdf"><span style="text-decoration: underline;">Energy-Based Anomaly Detection for
Mixed Data</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">Knowledge
and Information Systems</span>, 2018.&nbsp;</font><font size="5">Earlier
works are: </font></li>
        <ul>
          <li><font size="5"><a href="https://arxiv.org/abs/1610.06249">Multilevel
Anomaly Detection for Mixed Data</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh,
            <span style="font-style: italic;"></span></font><font size="5"><span style="font-style: italic;">arXiv
preprint arXiv</span>: </font><font size="5"><span style="font-style: italic;">1610.06249</span>.</font></li>
          <li><font size="5"><a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, K Do,
            <span style="font-weight: bold;">T Tran</span>,
D Phung, S Venkatesh,<span style="font-style: italic;"> International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font></li>
        </ul>
        <li><font size="5"><a href="http://arxiv.org/abs/1609.00489">A
deep learning model for estimating story points</a>, M
Choetkiertikul, HK Dam, <span style="font-weight: bold;">T
Tran</span>, T Pham, A Ghose, T Menzies, <span style="font-style: italic;">IEEE Transactions on Software Engineering,
2018.</span> <br>
          </font></li><li><font size="5"><span style="text-decoration: underline;">A
Generic Neural Architecture for Multiple Inputs and
Outputs</span>, Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">NIPS
Workshop on Women in Machine
Learning</span> (WiML 2017).</font></li>
        <li><font size="5"><a href="papers/nips17-ml4h.pdf"><span style="text-decoration: underline;">Finding Algebraic Structure of
Care in Time: A Deep Learning Approach</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">NIPS Workshop on Machine Learning for
Health (ML4H)</span>.</font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1708.04357"><span style="text-decoration: underline;">Graph Classification via Deep
Learning with Virtual Nodes</span></a> Trang Pham, </font><font size="5"><span style="text-decoration: underline;"></span><span style="font-weight: bold;">Truyen Tran</span>, Hoa Dam, Svetha
Venkatesh, <span style="font-style: italic;">Third Representation
Learning for Graphs Workshop (ReLiG 2017)</span>.</font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1707.05010"><span style="text-decoration: underline;">Deep Learning to Attend to Risk in
ICU</span></a>,&nbsp;Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">IJCAI'17
Workshop on Knowledge Discovery in Healthcare II: Towards Learning
Healthcare Systems</span> <span style="font-style: italic;">(KDH 2017</span>)</font><font size="5">.<span style="text-decoration: underline;"><br>
          </span></font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1703.01454"><span style="text-decoration: underline;">Learning Recurrent Matrix
Representation</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;"> </span></font><font size="5"><span style="font-style: italic;">Third Representation
Learning for Graphs Workshop (ReLiG 2017)</span>, also:<span style="font-style: italic;"> arXiv
preprint arXiv</span>: </font><font size="5"><span style="font-style: italic;">1703.01454</span>.</font></li>
        <li><font size="5"><a href="papers/aij15_main.pdf"><span style="text-decoration: underline;">Hierarchical semi-Markov
conditional random fields for deep recursive sequential data</span></a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Hung Bui, Svetha Venkatesh, &nbsp;<span style="font-style: italic;">Artificial Intelligence</span>,
Volume 246, May 2017, Pages 53–85.&nbsp;(Extension of the <a href="papers/truyen_nips08.pdf">NIPS'08 paper</a>).</font></li>
        <li><font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S1532046417300710">Predicting
healthcare trajectories from medical records: A deep learning approach</a>,</font><font size="5">Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">Journal of
Biomedical Informatics</span>, April 2017, DOI:
10.1016/j.jbi.2017.04.001. [<a href="http://arxiv.org/abs/1602.00357">Tech
report PDF</a>].</font></li>
        <li><font size="5"><a href="http://arxiv.org/abs/1607.07519"><span style="text-decoration: underline;">Deepr: A Convolutional
Net for Medical Records</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Nilmini
Wickramasinghe, Svetha Venkatesh,&nbsp;</font><font size="5">&nbsp;</font><font size="5"><span style="font-style: italic;">IEEE Journal of Biomedical
and
Health Informatics</span>,&nbsp;</font><font size="5">vol.
21, no. 1, pp. 22–30, Jan. 2017, Doi: 10.1109/JBHI.2016.2633963</font><font size="5">.</font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1609.04508">Column
Networks for Collective Classification</a>, T Pham, <span style="font-weight: bold;">T Tran</span>, D Phung, S
Venkatesh, <span style="font-style: italic;"></span></font><font size="5"><span style="font-style: italic;">AAAI'17</span></font></li>
        <li><font size="5"><a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, K Do,
          <span style="font-weight: bold;">T Tran</span>,
D Phung, S Venkatesh,<span style="font-style: italic;"> International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font></li>
        <li><font size="5"><a href="https://arxiv.org/abs/1609.08752"><span style="text-decoration: underline;">Stabilizing Linear
Prediction Models using Autoencoder</span></a>, Shivapratap
Gopakumara, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh, <span style="font-style: italic;">International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</font></li>
        <li><font size="5"><a href="http://arxiv.org/abs/1608.02715">A
deep language model for software code</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span> and
Trang Pham, <span style="font-style: italic;">FSE NL+SE
2016</span>.</font></li>
        <li><font size="5"><a href="http://arxiv.org/abs/1608.00092">DeepSoft:
A vision for a deep model of software</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, John
Grundy and Aditya Ghose, <span style="font-style: italic;">FSE
VaR</span> 2016.<a href="https://truyentran.github.io/papers/deepr.pdf"><span style="text-decoration: underline;"></span></a></font></li>
        <li><font size="5"><a href="papers/flexible_gating.pdf">Faster
Training of Very Deep Networks Via p-Norm Gates</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">ICPR'16</span>.</font></li>
        <li><font size="5"><a href="http://arxiv.org/abs/1602.00357">DeepCare:
A Deep Dynamic Memory Model for Predictive Medicine</a>, Trang
Pham,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh,<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD'16</span>, Auckland,
NZ, April 2016.&nbsp;</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/bdm16.pdf">Neural
Choice by Elimination via Highway Networks</a>,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung and Svetha Venkatesh,&nbsp;<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD workshop on Biologically
Inspired Techniques for Data Mining (BDM'16)</span><span class="Apple-converted-space"></span>, April 19-22
2016, Auckland, NZ.</font></li>
        <li class="itemize"><font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X"><span style="text-decoration: underline;">Graph-induced restricted
Boltzmann machines for document modeling</span></a>, Tu D.
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
D.
Phung, and S. Venkatesh, <span style="font-style: italic;">Information
Sciences</span><span style="font-style: italic;">.
doi:10.1016/j.ins.2015.08.023.</span></font></li>
        <li class="itemize"><font size="5"><a href="http://www.uow.edu.au/%7Ehoa/papers/ASE2015-preprint-choetkiertikul-dam-tran-ghose.pdf"><span style="text-decoration: underline;">Predicting delays in
software projects using networked classification</span></a>,
Morakot Choetikertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Aditya
Ghose,<span style="font-style: italic;"> 30th IEEE/ACM
International Conference on Automated Software Engineering</span>,
November 9–13, 2015 Lincoln, Nebraska, USA.</font></li>
        <li class="itemize"><font size="5"><a href="http://www.sciencedirect.com/science/article/pii/S1532046415000143">Learning
vector
representation of medical objects via EMR-driven nonnegative restricted
Boltzmann machines (e-NRBM)</a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
Tu
D. Nguyen, D.
Phung, and S. Venkatesh, <span style="font-style: italic;">Journal
of Biomedical Informatics</span>, 2015, pii:
S1532-0464(15)00014-3. doi: 10.1016/j.jbi.2015.01.012.&nbsp;</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/aaai15_main.pdf">Tensor-variate
Restricted Boltzmann Machines</a>, Tu D. Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, D.
Phung, and S. Venkatesh, <span style="font-style: italic;">AAAI</span>
2015.&nbsp;</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">Thurstonian
Boltzmann machines: Learning from multiple inequalities</a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
D.
Phung, and S. Venkatesh, In
          <span style="font-style: italic;">Proc. of 30th
International Conference in Machine Learning (ICML’13)</span>,
Atlanta, USA, June, 2013.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Learning
parts-based representations with Nonnegative Restricted Boltzmann
Machine</a>, Tu D. Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, D.
Phung, and S. Venkatesh, <span style="font-style: italic;">Journal
of Machine Learning Research (JMLR) Workshop and Conference
Proceedings, Vol. 29, Proc. of 5th Asian Conference on Machine
Learning,</span> Nov 2013.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Latent
patient profile modelling and
applications with Mixed-Variate Restricted Boltzmann Machine</a>,
Tu
D. Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
D. Phung, and S. Venkatesh,&nbsp; In<span style="font-style: italic;">
Proc. of 17th
Pacific-Asia Conference on Knowledge Discovery and Data Mining
(PAKDD’13)</span>, Gold Coast, Australia, April 2013.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/icme13_142.pdf">Learning
sparse latent representation and
distance metric for image retrieval</a>, Tu
D. Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
D. Phung, and S. Venkatesh, In
          <span style="font-style: italic;">Proc. of IEEE
International Conference on Multimedia and Expo (ICME)</span>,
San Jose, California, USA, July 2013.
          </font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/acml12_OSM_revised.pdf">Learning
from Ordered Sets and
Applications in Collaborative Ranking</a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">Cumulative
Restricted
Boltzmann Machines for Ordinal&nbsp;</a></font></li><li><font size="5"><a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">&nbsp;Data Analysis</a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_fusion12.pdf">Embedded
Restricted Boltzmann
Machines for Fusion of Mixed Data Types and Applications in Social
Measurements Analysis</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 15-th
International Conference on&nbsp;Information
Fusion&nbsp;(FUSION-12)</span>,
Singapore, July 2012.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">A
Sequential Decision Approach
to Ordinal Preferences in Recommender Systems</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 25-th Conference on Artificial Intelligence (AAAI-12)</span>,
Toronto,
Canada, July 2012.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/truyen_etal_icme12.pdf">Learning
Boltzmann Distance Metric for Face Recognition</a>,&nbsp;<span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of&nbsp;IEEE
International Conference on Multimedia &amp; Expo
(ICME-12)</span>, Melbourne, Australia, July 2012.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/tran_phung_venkatesh_acml11.pdf">Mixed-Variate
Restricted
Boltzmann Machines</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung and Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 3rd Asian Conference on Machine Learning (ACML2011)</span>,
Taoyuan, Taiwan, Nov 2011.</font></li>
        <li><font size="5"><a href="https://truyentran.github.io/papers/gupta_kdd10.pdf">Nonnegative
Shared Subspace
Learning and Its Application to Social Media Retrieval</a>, S.
Gupta, D. Phung, B. Adams, <span style="font-weight: bold;">Tran
The Truyen</span><span style="font-style: italic;">
Proc. of 16th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining</span>, 25-28 Jul,
Washington DC, 2010.
and Svetha Venkatesh, In</font></li>
        <li><font size="5"><a href="http://truyen.vietlabs.com/papers/uai09_final.pdf">Ordinal
Boltzmann Machines for
Collaborative Filtering</a>. <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung and Svetha Venkatesh. In
          <span style="font-style: italic;">Proc. of 25th
Conference on Uncertainty in Artificial Intelligence</span>,
June, 2009, Montreal, Canada. <span style="font-weight: bold; color: rgb(204, 0, 0);">Runner-up
for the best paper award</span>.</font></li>
        <li><font size="5"><a href="papers/hcrf_fast.pdf">MCMC
for Hierarchical
Semi-Markov Conditional Random Fields</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Q. Phung, Svetha Venkatesh and Hung H. Bui. In <span style="font-style: italic;">NIPS'09
Workshop on Deep Learning for Speech
Recognition and Related Applications</span>. December, 2009,
Whistler, BC, Canada</font></li>
        <li><font size="5"><a href="papers/truyen_nips08.pdf">Hierarchical
Semi-Markov
Conditional Random Fields for Recursive Sequential Data</a>,
          <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung, Hung H. Bui, and Svetha Venkatesh.
In <span style="font-style: italic;">Proc.
of&nbsp;21st
Annual Conference on Neural Information Processing Systems</span>,
Dec 2008, Vancouver, Canada. [See <a href="papers/truyen_hcrf_tr08.pdf">technical
report</a>
and <a href="papers/thesis.pdf">thesis</a>
for more
details and
extensions.]</font></li>
        <li><font size="5"><a href="papers/truyen_cvpr06.pdf">AdaBoost.MRF:
Boosted Markov
random forests and application to multilevel activity recognition</a>,
          <span style="font-weight: bold;">Truyen
Tran</span>, Dinh&nbsp;Quoc Phung, Hung&nbsp;Hai Bui,
and Svetha Venkatesh. In <span style="font-style: italic;">Proc.
of&nbsp; IEEE Conference
on Computer Vision and Pattern Recognition</span>,
volume Volume 2, pages 1686-1693, New York, USA, June 2006.</font></li>
      </ol>
      </td>
    </tr>
  </tbody>
</table>

 </body></html>