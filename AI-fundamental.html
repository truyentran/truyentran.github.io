<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>AI Fundamentals | Truyen Tran</title>

  

  
  
  <meta content="en-us" http-equiv="Content-Language">

  
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

  
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8">

  
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Abel">

  
  <style>
body {
font-family: 'Abel';
font-size: 100px;
}
  </style>
  
  <meta name="GENERATOR" content="LyX 2.3.1-1">

  
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8">

  
  <style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;</style>
  
  <meta name="GENERATOR" content="LyX 2.3.1-1">

  
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8">

  
  <style type="text/css">
/* Layout-provided Styles */
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;

}


  </style></head><body>
<table id="1" style="border-collapse: collapse; width: 900px; height: 1000px;" border="0" bordercolor="#111111" cellpadding="0" cellspacing="5">

  <tbody>
    <tr>
      <td style="border-right: 1px solid; background-color: rgb(0, 0, 0);" v="">&nbsp;</td>
    </tr>
    <tr>
      <td style="border-width: 1px; border-right: 1px solid; vertical-align: top;" v="" rowspan="2">
      <p align="right"><img style="border: 2px solid ; width: 200px; height: 200px;" alt="generated digits" src="http://rdn-consulting.com/blog/wp-content/uploads/2015/12/deepLearningAI500.png" hspace="0"><br>
      </p>
      <p align="right">[Source:&nbsp;rdn-consulting]</p>
      <p align="right"> </p>
      <p align="right"><font size="5"><a href="index.html">Home</a></font>&nbsp;
&nbsp; </p>
      <br>
&nbsp; <br>
      </td>
    </tr>
    <tr>
      <td style="width: 24px;">&nbsp; &nbsp;
&nbsp;&nbsp;
      <p>&nbsp;</p>
      <p>&nbsp;&nbsp;&nbsp; <br>
      </p>
      </td>
      <td style="vertical-align: top; width: 90%;">
      <p style="color: rgb(0, 51, 0);"><font style="color: rgb(0, 102, 0); font-weight: bold;" size="+3">AI
Fundamentals</font><a name="medical"></a></p>
      <table style="text-align: left; width: 100%;" border="0" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">
            <p class="MsoNormal" style="text-align: justify; color: rgb(0, 102, 0);"><big>Sub-areas</big></p>
            <big>» </big><a href="#New_inductive_biases_"><big>New
inductive
biases</big></a><br>
            <big>» </big><a href="#Memory-Augmented_Neural_Networks"><big>Memory-enabled
AI</big></a><br>
            <big>» </big> <a href="#Learning_to_reason"><big>Learning
to reason</big></a><br>
            <big>» </big><a href="#Learning_with_less_labels_"><big>Learning
with less labels</big></a><br>
            <big>» </big><a href="#Deep_reinforcement_learning"><big>Social
reinforcement learning</big></a><br>
            <big>» </big><big><a href="#Value-aligned_machine_learning">Human-compatible
learning</a></big><br>
            <ul>
            </ul>
            <br>
            <p class="MsoNormal" style="text-align: justify;"><a href="#Preprints"><big><span style="font-weight: bold;">Publications</span><br>
            </big></a> </p>
            </td>
            <td style="vertical-align: top;">
            <p class="MsoNormal" style="text-align: justify; color: rgb(0, 102, 0);"><big>Projects</big></p>
            <big>» </big><a href="#Human_behaviour_understanding_in_video"><big>Understanding
human behaviours in video</big></a><br>
            <big>» </big><a href="#Visual_question_answering_and_dialog"><big>Visual
question answering and dialog</big></a><br>
            <big></big><big>» </big><a href="#AI_for_bio"><big>AI for structural
biology</big></a><br>
            <big>» </big> <a href="#Exploring_the_molecular_and_materials"><big>Exploring
molecular and materials spaces</big></a><big><br>
            </big>
            <ul>
            </ul>
            </td>
          </tr>
        </tbody>
      </table>
      <p class="MsoNormal" style="text-align: justify;"><big>As
an
approach to general
intelligence, we study new ways for differentiable learning to reason
with
minimal
supervision, towards System 2 capability. Deep Learning achieves the
goals through compositional
neural
networks, iterative estimation, and differentiable programming. Our
research
program draws certain inspiration from cognitive neuroscience, fused
with
rigorous probabilistic inference. The ultimate long-term goal is devise
a unified
cognitive architecture that guides the learning and reasoning across
scales in space-time.<o:p></o:p></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>The
research program has three broad
aims:<o:p></o:p></big></p>
      <big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;"></span></span></span>»
To <span style="font-style: italic;">understand
intelligence</span> from computational and
cognitive perspectives.<o:p></o:p><br>
» To <span style="font-style: italic;">design intelligent machines</span>
that are
competent, scalable and robust.<o:p></o:p><br>
» To <span style="font-style: italic;">solve important data-rich
problems</span> across
living, physical and digital
domains.</big> <big><big><o:p></o:p></big></big>
      <p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 102, 0);"><big><big>Sub-area:
      <a name="New_inductive_biases_"></a>New
inductive biases</big></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>Successes
in machine learning
depend critically on having good priors on inductive biases. In deep
learning,
the strongest prior thus far has been neural architectures built on a
small set
of operators (signal filtering, convolution, recurrence, gating, memory
and
attention). We derive modular networks for regular data such as matrix
and
tensor as well as new data such as graphs and relations. We draw our
architectural inspiration from neuroscience including the columnar
structure of
the neocortex for distributed processing, the thalamus structure for
information routing, working memory for problem solving, and episodic
memory
for integrating information over time.<big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span><!--[if gte vml 1]><v:shapetype

id="_x0000_t75" coordsize="21600,21600" o:spt="75" o:preferrelative="t"

path="m@4@5l@4@11@9@11@9@5xe" filled="f" stroked="f">

<v:stroke joinstyle="miter"/>

<v:formulas>

<v:f eqn="if lineDrawn pixelLineWidth 0"/>

<v:f eqn="sum @0 1 0"/>

<v:f eqn="sum 0 0 @1"/>

<v:f eqn="prod @2 1 2"/>

<v:f eqn="prod @3 21600 pixelWidth"/>

<v:f eqn="prod @3 21600 pixelHeight"/>

<v:f eqn="sum @0 0 1"/>

<v:f eqn="prod @6 1 2"/>

<v:f eqn="prod @7 21600 pixelWidth"/>

<v:f eqn="sum @8 21600 0"/>

<v:f eqn="prod @7 21600 pixelHeight"/>

<v:f eqn="sum @10 21600 0"/>

</v:formulas>

<v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>

<o:lock v:ext="edit" aspectratio="t"/>

</v:shapetype><v:shape id="_x0000_i1033" type="#_x0000_t75" style='width:274.9pt;

height:184.5pt;visibility:visible;mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png"

o:title="Picture2"/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 367px; height: 246px;" alt="Column networks" src="figs/column-net.png" v:shapes="_x0000_i1033"><!--[endif]--></span><o:p></o:p></big></big></p>
      <p class="MsoCaption" style="text-align: center; font-style: italic;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big>Column
Networks, as inspired
by the cortical columns, to solve multi-relational learning.<o:p></o:p></big></p>
      <p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
      <a name="Memory-Augmented_Neural_Networks"></a>Memory-enabled AI<br>
      </big></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>Deep
neural networks excel at
function approximation and pattern recognition but fall short on
manipulating
complex, highly dependent systems, rapid contextualisation in new
settings, retaining previously acquired skills, and holding long
conversations. These limitations are possibly due to the lack of an
explicit notion of memory. We design new kinds of memory with more
robust handling of variability,
less
memorization, and stored programs. The memory serves as a central
component in a grand unified cognitive architecture that naturally
supports learning, reasoning, rapid contextualisation and imagination.<big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape

id="Picture_x0020_2" o:spid="_x0000_i1032" type="#_x0000_t75" style='width:389.25pt;

height:258.4pt;visibility:visible;mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image003.emz"

o:title="" gain="84021f" blacklevel="-655f"/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 519px; height: 345px;" alt="Variational memory encoder decoder" src="figs/VMED.png" v:shapes="Picture_x0020_2"><!--[endif]--></span><o:p></o:p></big></big></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><big><span style=""></span></big><span style="font-style: italic;">Variational
Memory
Encoder-Decoder, as applied for generating a diverse and coherent
dialog.</span></big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: justify; color: rgb(0, 153, 0); font-weight: bold;"><big><big>Sub-area:
      <a name="Learning_to_reason"></a>Learning to
reason</big></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>We
are concerned about learning
the capability to deduce new knowledge from previously acquired
knowledge in
response to a query. Such behaviours can be demonstrated naturally
using a symbolic
system with a rich set inferential tools, given that the symbols can be
grounded to the sensory world. Deep learning contributes to the
bottom-up
learning of such a reasoning system by resolving the symbol grounding
problem.
Our research aims to build neural architectures that can learn to
exhibit
high-level reasoning functionalities, e.g., answering new questions
over
space-time in a compositional and progressive fashion.<big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape

id="Picture_x0020_1" o:spid="_x0000_i1031" type="#_x0000_t75" style='width:451.5pt;

height:209.65pt;visibility:visible;mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image005.png"

o:title="overview"/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 602px; height: 280px;" alt="A system for Video QA" src="figs/VideoQA.png" v:shapes="Picture_x0020_1"><!--[endif]--></span><o:p></o:p></big></big></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><big><span style=""></span></big><span style="font-style: italic;">A system for
Video Question
Answering that implements the dual-process theory of reasoning.</span></big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
      <a name="Learning_with_less_labels_"></a>Learning
with less labels</big></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>Learning
with a few explicit
labels is the hallmark of human intelligence. Leveraging unlabelled
data,
either through existing datasets, or through self-exploration, will be
critical
to the next AI generation. We investigate the following sub-areas. <i style="">Representation learning</i>: Learning starts
with representation of latent factors in the data which are invariant
to small
changes and insensitive of noise. <i style="">Generative
models</i>: The ability to model high-dimensional world and to
imagine
the
future is fundamental to AI. We investigate fundamental issues of deep
generative models including stability, generalisation and catastrophic
forgetting in Generative Adversarial Networks, as well as
disentanglement in
Variational Auto-Encoders. <i style="">Continual
learning</i>: We design new learning algorithms that adapt
continually
as new
tasks are introduced, even if the task change is not explicitly marked.</big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="text-align: center; page-break-after: avoid;" align="center"><big><big><b style=""><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2084" o:spid="_x0000_i1030"

type="#_x0000_t75" style='width:260.25pt;height:249pt;visibility:visible;

mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image007.png"

o:title=""/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 347px; height: 332px;" alt="2D Boltzmann machine" src="figs/OrdRBM.png" v:shapes="Picture_x0020_2084"></span></b></big></big><!--[endif]--></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">A Boltzmann machine for
recommender system.</span><big><b style=""><o:p></o:p></b></big></big></p>
      <p class="MsoNormal" style="text-align: justify; font-weight: bold; color: rgb(0, 153, 0);"><big><big>Sub-area:
      <a name="Deep_reinforcement_learning"></a>Social
reinforcement
learning</big></big></p>
      <p class="MsoNormal" style="text-align: justify;"><big>We
leverage deep neural networks
to enable multi-agent systems to perceive the world, act on it,
interact with
others,
build theory of mind, imagine the future and receive feedbacks.
Equipped with deep
nets for perception, memory, statistical relational learning, and
reasoning
capabilities, we aim to bring multi-agent reinforcement learning to a
new level.</big></p>
      <p class="MsoNormal" style="text-align: center;"><big><img style="width: 500px; height: 283px;" alt="ToMAGA system." src="figs/ToMAGA.png"></big><big><span style="font-style: italic;"><br>
      </span></big></p>
      <p class="MsoNormal" style="text-align: center;"><big><span style="font-style: italic;">A system of multi-agents equipped with
social psychology.</span></big></p>
      <p class="MsoNormal" style="text-align: justify; margin-left: 8px; width: 714px;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;"></span></span></span></big><font style="color: rgb(0, 153, 0); font-weight: bold;" size="+2"> Sub-area:
      <span style="font-family: Symbol;"><span style=""><span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">&nbsp;&nbsp;
      </span></span></span><a name="Value-aligned_machine_learning"></a>Human-compatible
learning</font></big></p>
      <p class="MsoNormal" style="text-align: justify; margin-left: 6px; width: 716px;"><big>The
rapid advancement of AI raises new ethical challenges which pose great
risks to humanity if unsolved. We aim to invent new machine learning
algorithms that teach machine to be compatible with human preferences.
We derive&nbsp;
computational frameworks for instilling intrinsic human preferences
into AI through preference learning, alignment optimisation, and
preference-guided agent designs.</big><br>
      <big><big><o:p></o:p></big></big></p>
      
      <hr style="width: 100%; height: 2px;">
      <p class="MsoNormal" style="text-align: justify; font-weight: bold;"><big><big><big>Ongoing
Projects:</big></big></big></p>
      <p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      </span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Human_behaviour_understanding_in_video"></a>Human
behaviour
understanding in video</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big>This
project
aims at a deep understanding of human behaviours seen through (fixed
and
moving) videos in various indoor and outdoor contexts. We build new
models of
trajectories and social interactions, inferring past trigger events, and predict actions and
intention. <o:p></o:p></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><u>Partners</u>:
iCetana</big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2086" o:spid="_x0000_i1029"

type="#_x0000_t75" style='width:340.15pt;height:348.4pt;visibility:visible;

mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image009.png"

o:title="comparison_between_methods"/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 454px; height: 465px;" alt="Anomaly detection with skeleton trajectories" src="figs/skeleton-anomaly.png" v:shapes="Picture_x0020_2086"></span></big></big><!--[endif]--></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Detecting anomalies in video
using skeleton trajectories (last row).</span><big><o:p></o:p></big></big></p>
      <p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      </span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="Visual_question_answering_and_dialog"></a>Visual
question
answering and dialog</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt;"><big>We
study the new cognitive
capability of a system to answer new natural questions about an image
or a
video. This is a powerful way to demonstrate the reasoning capacity,
which
involves linguistic, visual processing and high-level symbols
manipulation
skills. In visual dialog, we build a system having a natural multi-turn
chat
with human about a visual object.<big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2085" o:spid="_x0000_i1028"

type="#_x0000_t75" style='width:425.65pt;height:155.25pt;visibility:visible;

mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image011.png"

o:title="qualcomp"/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 568px; height: 207px;" alt="Answering question about video" src="figs/VideoQA-exp.png" v:shapes="Picture_x0020_2085"></span></big></big><!--[endif]--></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Answering questions about a
video.</span></big></p>
      <p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: bold; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal; color: rgb(102, 0, 0);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      </span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);"><a name="AI_for_bio"></a>AI
for structural biology</span> <o:p style="font-weight: bold; color: rgb(102, 0, 0);"></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big>This
research
aims at designing neural architectures for representation of -omics and
structured biological data. We map
genotype-phenotype,
answer any genomic queries for a given sequence, predict protein-target
interactions, estimate protein folding, design drugs, and learn to
generate DNA/RNA and protein. The long-term goals also include
acquiring, organizing
and reasoning about established biology knowledge.<o:p></o:p></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><u>Partners</u>:
TBA.</big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2146" o:spid="_x0000_i1026"

type="#_x0000_t75" style='width:429pt;height:186.4pt;visibility:visible;

mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image015.png"

o:title=""/>

</v:shape><![endif]--><!--[if !vml]--></span></big></big></p>
      <big><span style="font-style: italic;"></span></big>
      <p class="MsoListParagraph" style="margin-left: 18pt; text-align: justify; text-indent: -18pt;"><!--[if !supportLists]--><!--[endif]--><big><big><span style="font-family: Symbol;"><span style="">·<span style="font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <a name="Exploring_the_molecular_and_materials"></a></span></span></span><span style="font-weight: bold; color: rgb(102, 0, 0);">Exploring
the
molecular and materials space</span> <o:p></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big>We
use deep
learning to characterise the chemical space, replace expensive physical
computation and experiments, predict molecular properties,
molecular-molecular interactions
and chemical reactions, and generate drug molecules given a set of
desirable
bioactivity properties. In materials design, we design new tools for
understanding the structure and characteristics of materials, searching
for new
alloys, and generating molecules &amp; crystals.<o:p></o:p></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: justify;"><big><u>Partners</u>:
Institute of Frontier Materials at Deakin, Japan Institute of Advanced
Science
and Technology.</big><big><big><o:p></o:p></big></big></p>
      <p class="MsoNormal" style="margin-left: 18pt; text-align: center; page-break-after: avoid;" align="center"><big><big><span style=""><!--[if gte vml 1]><v:shape id="Picture_x0020_2147" o:spid="_x0000_i1025"

type="#_x0000_t75" style='width:433.9pt;height:216.4pt;visibility:visible;

mso-wrap-style:square'>

<v:imagedata src="file:///C:/Users/truyen/AppData/Local/Temp/msohtmlclip1/01/clip_image017.png"

o:title=""/>

</v:shape><![endif]--><!--[if !vml]--><img style="width: 579px; height: 289px;" alt="Relational Dynamic Memory Network" src="figs/RDMN.png" v:shapes="Picture_x0020_2147"></span></big></big><!--[endif]--></p>
      <p class="MsoCaption" style="text-align: center;" align="center"><!--[if supportFields]><span

style='mso-element:field-begin'></span><span

style='mso-spacerun:yes'> </span>SEQ Figure \* ARABIC <span style='mso-element:

field-separator'></span><![endif]--><!--[if supportFields]><span

style='mso-element:field-end'></span><![endif]--><big><span style="font-style: italic;">Relational Dynamic Memory
Network, a model for detecting interactions among molecules.</span><big><o:p></o:p></big></big></p>
      <big> </big><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;">
      </span>
      <hr style="width: 100%; height: 2px;"><span style="font-size: 11pt; line-height: 107%; font-family: &quot;Calibri&quot;,sans-serif;"><br>
      </span><br>
      <font style="font-weight: bold;" size="5"><a name="Preprints"></a>Preprints<br>
      </font>
      <ul>
        <li><big><a href="https://arxiv.org/abs/1702.07021"><span style="text-decoration: underline;">On size fit many: Column
bundle
for multi-X learning</span></a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;">&nbsp;</span><span style="font-style: italic;">arXiv
preprint arXiv</span>: <span style="font-style: italic;">1702.07021</span>.</big></li>
        
        <li><big><span style="font-style: italic;"> </span><a href="https://arxiv.org/abs/1703.01454">Learning deep
matrix
representations</a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1703.01454.</span></big></li>
        <li><big><span style="font-style: italic;"> </span><a href="https://arxiv.org/abs/1808.04247">Relational
dynamic
memory
networks</a>, Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,&nbsp;Svetha
Venkatesh, <span style="font-style: italic;">arXiv
preprint
arXiv:1808.04247.</span></big></li>
        <li><big><span style="font-style: italic;"> </span><a href="https://arxiv.org/abs/2011.10094">Logically consistent loss for
visual question answering</a>, Anh-Cat Le-Ngo, <span style="font-weight: bold;">Truyen Tran</span>, Santu Sana, Sunil
Gupta, Svetha Venkatesh,<span style="font-style: italic;"> arXiv
preprint arXiv:2011.10094.</span></big></li>
      </ul>
      <ol>
      </ol>
      <p align="justify"><font style="font-weight: bold;" size="5">Publications</font><font size="5"><a name="Publications"></a></font></p>
      <ul>
        
        <li><big><a href="https://openreview.net/forum?id=0f-0I6RFAch">Improving out-of-distribution generalization with indirection representations</a>, Pham, Kha, Hung Le, Man Ngo, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">ICLR'23</span>.</big></li>
        <li><big><a href="https://arxiv.org/abs/2301.06926">Memory-augmented theory of mind network</a>, Nguyen, Dung, Phuoc Nguyen, Hung Le, Kien Do, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">AAAI'23</span>.</big></li>
        <li><big><a href="https://openaccess.thecvf.com/content/WACV2023/html/Le_Guiding_Visual_Question_Answering_With_Attention_Priors_WACV_2023_paper.html">Guiding visual question answering with attention priors</a>, Le, Thao Minh, Vuong Le, Sunil Gupta, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">WACV'23</span>.</big></li>
        <li><big><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/41128e5b3a7622da5b17588757599077-Abstract-Conference.html">Momentum adversarial distillation: Handling large
distribution shifts in data-free knowledge distillation</a>, Do, Kien, Thai
Hung Le, Dung Nguyen, Dang Nguyen, Haripriya Harikumar, <span style="font-weight: bold;">Truyen Tran</span>, Santu Rana, and Svetha Venkatesh, <span style="font-style: italic;">NeurIPS'22</span>.</big></li>
        <li><big><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/13b8d8fb8d05369480c2c344f2ce3f25-Abstract-Conference.html">Functional indirection neural estimator for better out-of-distribution generalization</a>, Pham, Kha, Thai Hung Le, Man Ngo, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">NeurIPS'22</span>.</big></li>
        <li><big><a href="https://link.springer.com/chapter/10.1007/978-3-031-19842-7_41">Video dialog as conversation about objects living in space-time</a>, Pham, Hoang-Anh, Thao Minh Le, Vuong Le, Tu Minh Phuong, and <span style="font-weight: bold;">Truyen Tran</span>. <span style="font-style: italic;">ECCV'22</span>.</big></li>
        <li><big><a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_17">Towards effective and robust neural Trojan defenses via input filtering</a>, Do, Kien, Haripriya Harikumar, Hung Le, Dung Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Santu Rana, Dang Nguyen, Willy Susilo, and Svetha Venkatesh. <span style="font-style: italic;">ECCV'22</span>.</big></li>
        <li><big><a href="https://arxiv.org/abs/2204.12937">Learning to
transfer role assignment across team sizes</a>,&nbsp;</big> <big>Dung
Nguyen, Phuoc Nguyen, Svetha Venkatesh, <b>Truyen Tran</b>, <em>AAMAS</em>,
2022.</big></li>

        <li><big><a href="https://arxiv.org/abs/2204.09047">Learning
theory of mind via dynamic traits attribution</a>, </big><big>Dung
Nguyen, Phuoc Nguyen, Hung Le, Kien Do, Svetha Venkatesh, <b>Truyen
Tran</b>, <em>AAMAS</em>, 2022.&nbsp;</big></li>
        <li><big><a href="https://arxiv.org/abs/2111.02104"><span style="text-decoration: underline;">Model-based episodic memory
induces dynamic hybrid controls</span></a>, </big><big>Hung Le,
Thommen K George, Majid Abdolshah, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">NeurIPS'21</span>.</big></li>
        <li><big><a href="https://link.springer.com/chapter/10.1007/978-3-030-91431-8_2"><span style="text-decoration: underline;">DeepProcess: Supporting business
process execution using a MANN-based recommender system</span></a>, </big><big>Asjad
Khan, Aditya Ghose, Hoa Dam, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Kien Do, <span style="font-style: italic;">ICSOC'21</span>.</big></li>
        <li><big><a href="https://dl.acm.org/doi/abs/10.1145/3447548.3470803">From deep
learning to deep reasoning</a>, Truyen Tran, Vuong Le, Hung Le, Thao
Le, <span style="font-style: italic;">KDD</span>, 2021.</big><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_366.pdf"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_366.pdf"><span style="text-decoration: underline;">Knowledge distillation with
distribution mismatch</span></a>, D Nguyen, S Gupta, T Nguyen, S Sana,
P Nguyen, <span style="font-weight: bold;">T Tran</span>, KL Le, S
Ryan, ... <span style="font-style: italic;">ECML-PKDD'21</span>, 2021<a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_529.pdf"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/09/sub_529.pdf"><span style="text-decoration: underline;">Fast conditional network
compression using Bayesian HyperNetworks</span></a>, P Nguyen, <span style="font-weight: bold;">T Tran</span>, KL Le, S Gupta, S Sana, D
Nguyen, T Nguyen, S Ryan, ... <span style="font-style: italic;">ECML-PKDD'21</span>,
2021<a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_659.pdf"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_659.pdf"><span style="text-decoration: underline;">Variational hyper-encoding networks</span></a>,
P Nguyen, <span style="font-weight: bold;">T Tran</span>, S Gupta, S
Rana, HC Dam, S Venkatesh, <span style="font-style: italic;">ECML-PKDD'21</span>,
2021</big></li>
        <li><big><a href="https://arxiv.org/abs/2010.10019">Hierarchical
conditional relation networks for multimodal video question answering</a>,
TM Le, V Le, S Venkatesh, <span style="font-weight: bold;">T Tran</span>,
          <span style="font-style: italic;">International Journal of
Computer Vision</span>, 2021<a href="https://arxiv.org/abs/2106.13432"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/2106.13432"><span style="text-decoration: underline;">Hierarchical object-oriented
spatio-temporal reasoning for video question answering</span></a>, LH
Dang, TM Le, V Le, <span style="font-weight: bold;">T Tran</span>, <span style="font-style: italic;">IJCAI'21</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2104.05166">Object-centric
representation learning for video question answering</a> Long Hoang
Dang, Thao Minh Le, Vuong Le, <span style="font-weight: bold;">Truyen
Tran</span><span style="font-style: italic;">, IJCNN'21.&nbsp;</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2103.02758">Learning
asynchronous and sparse human-object interaction in videos</a> Romero
Morais, Vuong Le, Svetha Vekatesh, <span style="font-weight: bold;">Truyen
Tran</span><span style="font-style: italic;">, CVPR'21.&nbsp;</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2011.02751">Goal-driven
long-term trajectory prediction</a>, Hung Tran, Vuong Le, <span style="font-weight: bold;">Truyen Tran</span><span style="font-style: italic;">, WACV'21.&nbsp;</span></big></li>
        <li><big><a href="https://link.springer.com/article/10.1007/s10664-020-09898-5">Automatically
recommending components for issue reports using deep learning</a>,
Morakot Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Trang Pham, Chaiyong Ragkhitwetsagul &amp; Aditya Ghose <span style="font-style: italic;">, Empirical Software Engineering</span>
volume 26, Article number: 14 (2021).</big><big><span style="font-style: italic;"></span></big></li>
        <li><big><a href="http://arxiv.org/abs/2012.01793">Semi-supervised
learning with variational Bayesian inference and maximum uncertainty
regularization</a>, </big><big>Kien Do, <span style="font-weight: bold;">Truyen Tran</span> and Svetha Venkatesh,</big><big>&nbsp;<span style="font-style: italic;"> AAAI'21.</span></big> <br>
          <big><span style="font-style: italic;"> </span></big></li>
        <li><big><a href="https://arxiv.org/abs/2011.00754">Toward a
generalization metric for deep generative models</a>, Thanh-Tung,
Hoang, and <span style="font-weight: bold;">Truyen Tran</span>.<span style="font-style: italic;"> NeurNIPS 2020 1st Workshop on I Can’t
Believe It’s Not Better.</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2009.12146">GEFA: Early
Fusion Approach in Drug-Target Affinity Prediction</a>, Tri Minh
Nguyen, Thin Nguyen, Thao Minh Le, <span style="font-weight: bold;">Truyen
Tran</span>, <span style="font-style: italic;">Machine Learning for
Structural Biology (MLSB) Workshop at NeurIPS 2020.</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2005.08482">HyperVAE: A
minimum description length variational hyper-encoding network</a>,
Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Sunil Gupta, Santu Rana, Hieu-Chi Dam, Svetha Venkatesh<span style="font-style: italic;">, NeurIPS 2020 Workshop on Meta-Learning</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2009.09443">Unsupervised
anomaly detection on temporal multiway data</a>, Duc Nguyen, Phuoc
Nguyen, Kien Do, Santu Rana, Sunil Gupta, <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">2020 IEEE Symposium Series on
Computational Intelligence (SSCI) (SSCI 2020).</span></big></li>
        <li><big><a href="https://arxiv.org/abs/2009.07445">Theory of
mind with guilt aversion facilitates cooperative reinforcement learning</a>,
          <span style="font-style: italic;"></span>Dung Nguyen, Svetha
Venkatesh, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
          <span style="font-style: italic;">ACML'20</span>.</big></li>
        <li><big><a href="https://arxiv.org/abs/2008.09234">Learning to
abstract and predict human actions</a>, <span style="font-style: italic;"></span>Romero Morais, Vuong Le, <span style="font-weight: bold;">Truyen Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">BMVC'20</span>.</big><big><span style="text-decoration: underline;"></span></big></li>
        <li><big><span style="text-decoration: underline;">Object-centric
relational reasoning for video question answering</span>, <span style="font-style: italic;"></span>Long Hoang Dang, Thao Minh Le,
Vuong Le, <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">The ECCV 2nd Workshop on Video Turing
Test: Toward Human-Level Video Story Understanding, August 2020</span>.</big></li>
        <li><big><a href="https://www.biorxiv.org/content/10.1101/686394v1.abstract">Deep
in the bowel: Highly interpretable neural encoder-decoder networks
predict gut metabolites from gut microbiome</a>, <span style="font-style: italic;"></span>V Le, TP Quinn, <span style="font-weight: bold;">T Tran</span>, S Venkatesh, <span style="font-style: italic;">BMC Genomics (21)</span>, 07/2020.</big></li>
        <li><big><a href="https://arxiv.org/abs/2002.03519">Self-attentive
associative memory</a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh<span style="font-style: italic;">, ICML'20</span><span style="font-style: italic;">.</span></big><big><a href="https://arxiv.org/abs/2004.14603"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/2004.14603"><span style="text-decoration: underline;">Dynamic language binding in
relational visual reasoning</span></a>, Thao Minh Le, Vuong
Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>,<span style="font-style: italic;"> </span><span style="font-style: italic;">
IJCAI'20</span>, July 11-17, Yokohama, Japan.<br>
          <a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/1907.04553"><span style="text-decoration: underline;">Neural reasoning, fast and slow,
for video question answering</span></a>, Thao Minh Le, Vuong Le, Svetha
Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>, <span style="font-style: italic;">IJCNN'20</span><br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1909.04307">Learning
transferable
domain priors for safe exploration in reinforcement learning</a><span style="font-style: italic;"></span>, Thommen G Karimpanal, Santu Rana,
Sunil Gupta, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">, IJCNN'20</span><br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1807.04015">On
catastrophic
forgetting and mode collapse in Generative Adversarial Networks</a>,
Thanh-Tung, Hoang, and <span style="font-weight: bold;">Truyen Tran</span>,
          <span style="font-style: italic;">IJCNN'20</span><br>
          <a href="https://arxiv.org/abs/2002.10698"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/2002.10698"><span style="text-decoration: underline;">Hierarchical conditional relation
networks for video question answering</span></a>, Thao Minh Le, Vuong
Le, Svetha Venkatesh, and <span style="font-weight: bold;">Truyen Tran</span>,&nbsp;<span style="font-style: italic;">CVPR'20.</span><br>
          <a href="https://baicsworkshop.github.io/pdf/BAICS_28.pdf"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://baicsworkshop.github.io/pdf/BAICS_28.pdf"><span style="text-decoration: underline;">Theory of mind with guilt aversion
facilitates cooperative reinforcement learning</span></a>, Dung Nguyen,
Truyen Tran, Svetha Venkatesh,<span style="font-style: italic;"> </span><span style="font-style: italic;">ICLR 2020 workshop on Bridging AI and
Cognitive Science</span>, April 26-30, Addis Ababa, Ethiopia. <span style="font-style: italic;"></span><br>
          <span style="font-style: italic;"> </span></big></li>
        <li><big><a href="https://arxiv.org/abs/1906.08862">Neural
stored-program memory</a>,
Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh<span style="font-style: italic;">, ICLR'20.</span><br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1908.09961">Theory and
evaluation
metrics for learning disentangled representations</a>, K Do, <span style="font-weight: bold;">T Tran</span><span style="font-style: italic;">, ICLR'20.</span><br>
          </big></li>
        <li><big><a href="https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-020-0658-5">DeepTRIAGE:
Interpretable and individualised biomarker scores using attention
mechanism for the classification of breast cancer sub-types</a>, Adham
Beykikhoshk, Thom P Quinn, Sam C Lee, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,<span style="font-style: italic;"> B</span><span style="font-style: italic;">MC Medical Genomics, 2020</span><span style="font-style: italic;">MC Medical Genomics, 2020</span> <br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1812.09441">Graph
transformation
policy
network for chemical reaction prediction</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;">KDD'19</span>.<br>
          <a href="https://arxiv.org/abs/1903.03295"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/1903.03295"><span style="text-decoration: underline;">Learning regularity in
skeleton
trajectories for anomaly detection in videos</span></a>,
Romero Morais,
Vuong Le, Budhaditya Saha, <span style="font-weight: bold;">Truyen
Tran</span>,
Moussa Reda Mansour, Svetha Venkatesh, <span style="font-style: italic;">CVPR'19</span>.<br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1802.00921">Lessons
learned from using a deep tree-based model for software defect
prediction in practice</a>, Hoa Khanh Dam, Trang Pham, Shien Wee Ng, <span style="font-weight: bold;">Truyen Tran</span>, John Grundy, Aditya
Ghose, Taeksu Kim, Chul-Joo Kim, <span style="font-style: italic;">MSR'19.</span><br>
          <a href="https://openreview.net/forum?id=r1xlvi0qYm"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://openreview.net/forum?id=r1xlvi0qYm"><span style="text-decoration: underline;">Learning to remember
more with
less memorization</span></a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.<br>
          <a href="https://openreview.net/forum?id=ByxPYjC5KQ"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://openreview.net/forum?id=ByxPYjC5KQ"><span style="text-decoration: underline;">Improving generalization
and
stability of Generative Adversarial Networks</span></a>, Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICLR'19</span>.<br>
          <a href="https://arxiv.org/abs/1811.06060"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/1811.06060"><span style="text-decoration: underline;">Incomplete conditional
density
estimation for fast materials discovery</span></a>, Phuoc
Nguyen,
Truyen Tran,&nbsp;Sunil
Gupta, Svetha Venkatesh. <span style="font-style: italic;"></span><span style="font-style: italic;">SDM'19</span>. <br>
          </big></li>
        <li><big><a href="https://truyentran.github.io/papers/main-CCI.pdf">Neural
reasoning for chemical-chemical interaction</a>.&nbsp;Trang Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">NIPS 2018 Workshop
on Machine
Learning for
Molecules and Materials</span>. <br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1804.00293">Attentional
multilabel
learning over graphs: A message passing approach</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Thin Nguyen,
SvethaVenkatesh,&nbsp;<span style="font-style: italic;">Machine
Learning, 2019.</span><br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1708.02368">Automatic
feature
learning for
predicting vulnerable software components</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang
Pham, &nbsp;Shien
Wee Ng, John Grundy, Aditya Ghose,<span style="font-style: italic;">
IEEE Transactions on Software Engineering, </span>2019.<br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1807.09950">Variational
memory
encoder-decoder,</a> Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Thin Nguyen, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">NIPS'18.</span><br>
          </big></li>
        <li><big><a href="https://arxiv.org/abs/1802.00662">Dual Memory
Neural
Computer
for Asynchronous Two-view Sequential Learning</a>, Hung Le, <span style="font-weight: bold;">Truyen Tran</span>, S vetha Venkatesh, <span style="font-style: italic;">KDD'18.</span><br>
          <a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big><a href="https://arxiv.org/abs/1807.04015"><span style="text-decoration: underline;">On catastrophic
forgetting and
mode collapse in Generative Adversarial Networks</span></a>,
Hoang
Thanh-Tung, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">; ICML
Workshop on Theoretical Foundations
and Applications of Deep Generative Models</span>, 2018<span style="font-style: italic;">.</span><br>
          <span style="font-style: italic;"> </span></big></li>
        <li><big><a href="https://arxiv.org/abs/1801.02622">Graph
Memory Networks for Molecular Activity Prediction</a>,&nbsp;Trang Pham,
          <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">ICPR'18</span>.&nbsp;<br>
          </big> </li>
        <li><big><a href="https://arxiv.org/abs/1801.08641">Knowledge
Graph
Embedding with
Multiple Relation Projections</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh,&nbsp;<span style="font-style: italic;">ICPR'18.</span></big></li>
        <li><big> <a href="https://arxiv.org/abs/1802.00948">Resset:
A Recurrent Model for Sequence of Sets with Applications to Electronic
Medical Records</a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh<span style="font-style: italic;">, IJCNN'18.</span></big></li>
        <li><big> <a href="https://arxiv.org/abs/1802.03689">Dual
control memory
augmented neural networks for treatment
recommendations</a>, Hung Le, <span style="font-weight: bold;">Truyen
Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">PAKDD'18</span>.<span style="font-style: italic;"> </span></big></li>
        <li><big> <a href="https://dl.acm.org/citation.cfm?id=3194952"><span style="text-decoration: underline;">Predicting
components for issue reports using deep learning with information
retrieval</span></a>, Morakot Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, Trang Pham, Aditya
Ghose, <span style="font-style: italic;">International
Conference on Software
Engineering (ICSE'18) - Poster Track</span><span style="font-style: italic;"></span></big></li>
        <li><big> <a href="https://truyentran.github.io/papers/outlier_kais17.pdf"><span style="text-decoration: underline;">Energy-Based Anomaly
Detection for
Mixed Data</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh, <span style="font-style: italic;">Knowledge
and Information Systems</span>, 2018.&nbsp;Earlier
works are: </big></li>
        <li><big> <a href="https://arxiv.org/abs/1610.06249">Multilevel
Anomaly Detection for Mixed Data</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>, Svetha
Venkatesh, <span style="font-style: italic;"></span><span style="font-style: italic;">arXiv
preprint arXiv</span>: <span style="font-style: italic;">1610.06249</span>.</big></li>
        <li><big> <a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
        <li><big> <a href="http://arxiv.org/abs/1609.00489">A
deep learning model for estimating story points</a>, Morakot
Choetkiertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Trang Pham, Aditya Ghose, Tim Menzies, <span style="font-style: italic;">IEEE Transactions on Software
Engineering,
2018.</span></big></li>
        <li><big> <a href="https://truyentran.github.io/papers/nips17-ml4h.pdf"><span style="text-decoration: underline;">Finding Algebraic
Structure of
Care in Time: A Deep Learning Approach</span></a>, Phuoc
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Svetha Venkatesh, <span style="font-style: italic;">NIPS
Workshop on Machine Learning for
Health (ML4H)</span>.</big></li>
        <li><big> <a href="https://arxiv.org/abs/1708.04357"><span style="text-decoration: underline;">Graph Classification via
Deep
Learning with Virtual Nodes</span></a> Trang Pham, <span style="text-decoration: underline;"></span><span style="font-weight: bold;">Truyen Tran</span>, Hoa
Dam, Svetha
Venkatesh, <span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiG 2017)</span>.</big></li>
        <li><big> <a href="https://arxiv.org/abs/1707.05010"><span style="text-decoration: underline;">Deep Learning to Attend
to Risk in
ICU</span></a>,&nbsp;Phuoc Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha Venkatesh,&nbsp;<span style="font-style: italic;">IJCAI'17
Workshop on Knowledge Discovery in Healthcare II: Towards Learning
Healthcare Systems</span> <span style="font-style: italic;">(KDH
2017</span>).<span style="text-decoration: underline;"></span><span style="text-decoration: underline;"></span></big></li>
        <li><big> <a href="https://arxiv.org/abs/1703.01454"><span style="text-decoration: underline;">Learning Recurrent
Matrix
Representation</span></a>, Kien Do, <span style="font-weight: bold;">Truyen
Tran</span>, Svetha
Venkatesh.<span style="font-style: italic;"> </span><span style="font-style: italic;">Third
Representation
Learning for Graphs Workshop (ReLiF 2017)</span></big></li>
        <li><big> <a href="https://www.researchgate.net/profile/Truyen_Tran/publication/314024495_Hierarchical_semi-Markov_conditional_random_fields_for_deep_recursive_sequential_data/links/5a585845a6fdccf0ad1a4ce9/Hierarchical-semi-Markov-conditional-random-fields-for-deep-recursive-sequential-data.pdf"><span style="text-decoration: underline;">Hierarchical semi-Markov
conditional random fields for deep recursive sequential data</span></a>,
          <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Hung Bui, Svetha Venkatesh, &nbsp;<span style="font-style: italic;">Artificial Intelligence</span>,
Volume 246, May 2017, Pages 53–85.&nbsp;(Extension of the <a href="https://truyentran.github.io/papers/truyen_nips08.pdf">NIPS'08
paper</a>).</big></li>
        <li><big> <a href="http://www.sciencedirect.com/science/article/pii/S1532046417300710">Predicting
healthcare trajectories from medical records: A deep learning approach</a>,Trang
Pham, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">Journal
of
Biomedical Informatics</span>, April 2017, DOI:
10.1016/j.jbi.2017.04.001. [<a href="http://arxiv.org/abs/1602.00357">Tech
report PDF</a>].</big></li>
        <li><big> <a href="http://arxiv.org/abs/1607.07519"><span style="text-decoration: underline;">Deepr: A Convolutional
Net for Medical Records</span></a>, Phuoc Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Nilmini
Wickramasinghe, Svetha Venkatesh,&nbsp;&nbsp;<span style="font-style: italic;">IEEE Journal of Biomedical
and
Health Informatics</span>,&nbsp;vol.
21, no. 1, pp. 22–30, Jan. 2017, Doi: 10.1109/JBHI.2016.2633963.</big></li>
        <li><big> <a href="https://arxiv.org/abs/1609.04508">Column
Networks for Collective Classification</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh Phung, Svetha
Venkatesh, <span style="font-style: italic;"></span><span style="font-style: italic;">AAAI'17</span></big></li>
        <li><big> <a href="http://arxiv.org/abs/1608.04830">Outlier
Detection on Mixed-Type Data: An Energy-based Approach</a>, Kien Do, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh,<span style="font-style: italic;">
International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
        <li><big> <a href="https://arxiv.org/abs/1609.08752"><span style="text-decoration: underline;">Stabilizing Linear
Prediction Models using Autoencoder</span></a>, Shivapratap
Gopakumara, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, Svetha Venkatesh, <span style="font-style: italic;">International
Conference on Advanced Data Mining and Applications</span> (ADMA
2016).</big></li>
        <li><big> <a href="http://arxiv.org/abs/1608.02715">A
deep language model for software code</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span> and
Trang Pham, <span style="font-style: italic;">FSE NL+SE
2016</span>.</big></li>
        <li><big> <a href="http://arxiv.org/abs/1608.00092">DeepSoft:
A vision for a deep model of software</a>, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen Tran</span>, John
Grundy and Aditya Ghose, <span style="font-style: italic;">FSE
VaR</span> 2016.<a href="https://truyentran.github.io/papers/deepr.pdf"><span style="text-decoration: underline;"></span></a></big></li>
        <li><big> <a href="https://truyentran.github.io/papers/flexible_gating.pdf">Faster
Training of Very Deep Networks Via p-Norm Gates</a>, Trang Pham, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh, <span style="font-style: italic;">ICPR'16</span>.</big></li>
        <li><big> <a href="http://arxiv.org/abs/1602.00357">DeepCare:
A Deep Dynamic Memory Model for Predictive Medicine</a>, Trang
Pham,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, Svetha Venkatesh,<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD'16</span>, Auckland,
NZ, April 2016.&nbsp;</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/bdm16.pdf">Neural
Choice by Elimination via Highway Networks</a>,<span class="Apple-converted-space">&nbsp;</span><span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung and Svetha Venkatesh,&nbsp;<span class="Apple-converted-space">&nbsp;</span><span style="font-style: italic;">PAKDD workshop on Biologically
Inspired Techniques for Data Mining (BDM'16)</span><span class="Apple-converted-space"></span>, April 19-22
2016, Auckland, NZ.</big></li>
        <li><big> <a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X"><span style="text-decoration: underline;">Graph-induced restricted
Boltzmann machines for document modeling</span></a>, Tu Dinh
Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Information
Sciences</span><span style="font-style: italic;">.
doi:10.1016/j.ins.2015.08.023.</span> </big></li>
        <li><big> <a href="http://www.uow.edu.au/%7Ehoa/papers/ASE2015-preprint-choetkiertikul-dam-tran-ghose.pdf"><span style="text-decoration: underline;">Predicting delays in
software projects using networked classification</span></a>,
Morakot Choetikertikul, Hoa Khanh Dam, <span style="font-weight: bold;">Truyen
Tran</span>, Aditya
Ghose,<span style="font-style: italic;"> 30th IEEE/ACM
International Conference on Automated Software Engineering</span>,
November 9–13, 2015 Lincoln, Nebraska, USA.</big></li>
        <li><big> <a href="http://www.sciencedirect.com/science/article/pii/S1532046415000143">Learning
vector
representation of medical objects via EMR-driven nonnegative restricted
Boltzmann machines (e-NRBM)</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Tu
Dinh Nguyen, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Biomedical Informatics</span>, 2015, pii:
S1532-0464(15)00014-3. doi: 10.1016/j.jbi.2015.01.012.&nbsp;</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/aaai15_main.pdf">Tensor-variate
Restricted Boltzmann Machines</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">AAAI</span>
2015.&nbsp;</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/icml13_camera_ready.pdf">Thurstonian
Boltzmann machines: Learning from multiple inequalities</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh
Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of
30th
International Conference in Machine Learning (ICML’13)</span>,
Atlanta, USA, June, 2013.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Learning
parts-based representations with Nonnegative Restricted Boltzmann
Machine</a>, Tu Dinh Nguyen, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh
Phung, and Svetha Venkatesh, <span style="font-style: italic;">Journal
of Machine Learning Research (JMLR) Workshop and Conference
Proceedings, Vol. 29, Proc. of 5th Asian Conference on Machine
Learning,</span> Nov 2013.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/acml13_nguyen.pdf">Latent
patient profile modelling and
applications with Mixed-Variate Restricted Boltzmann Machine</a>,
Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh,&nbsp; In<span style="font-style: italic;">
Proc. of 17th
Pacific-Asia Conference on Knowledge Discovery and Data Mining
(PAKDD’13)</span>, Gold Coast, Australia, April 2013.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/icme13_142.pdf">Learning
sparse latent representation and
distance metric for image retrieval</a>, Tu
Dinh Nguyen, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung, and Svetha Venkatesh, In <span style="font-style: italic;">Proc.
of IEEE
International Conference on Multimedia and Expo (ICME)</span>,
San Jose, California, USA, July 2013. </big></li>
        <li><big> <a href="https://truyentran.github.io/papers/acml12_OSM_revised.pdf">Learning
from Ordered Sets and
Applications in Collaborative Ranking</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/acml12_recsys_revised.pdf">Cumulative
Restricted
Boltzmann Machines for Ordinal&nbsp;Data Analysis</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Phung and
Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 4th Asian Conference on
Machine Learning (ACML2012)</span>, Singapore, Nov 2012.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/truyen_etal_fusion12.pdf">Embedded
Restricted Boltzmann
Machines for Fusion of Mixed Data Types and Applications in Social
Measurements Analysis</a>, <span style="font-weight: bold;">Truyen
Tran</span>,
Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 15-th
International Conference on&nbsp;Information
Fusion&nbsp;(FUSION-12)</span>,
Singapore, July 2012.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/truyen_etal_aaai12.pdf">A
Sequential Decision Approach
to Ordinal Preferences in Recommender Systems</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of 25-th Conference on Artificial Intelligence (AAAI-12)</span>,
Toronto,
Canada, July 2012.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/truyen_etal_icme12.pdf">Learning
Boltzmann Distance Metric for Face Recognition</a>,&nbsp;<span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung, Svetha Venkatesh, in P<span style="font-style: italic;">roc.
of&nbsp;IEEE
International Conference on Multimedia &amp; Expo
(ICME-12)</span>, Melbourne, Australia, July 2012.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/tran_phung_venkatesh_acml11.pdf">Mixed-Variate
Restricted
Boltzmann Machines</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Phung and Svetha Venkatesh, in <span style="font-style: italic;">Proc.
of. the 3rd Asian Conference on Machine Learning (ACML2011)</span>,
Taoyuan, Taiwan, Nov 2011.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/gupta_kdd10.pdf">Nonnegative
Shared Subspace
Learning and Its Application to Social Media Retrieval</a>, Sunil
Gupta, Dinh Phung, Brett. Adams, <span style="font-weight: bold;">Tran
The Truyen</span><span style="font-style: italic;">
Proc. of 16th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining</span>, 25-28 Jul,
Washington DC, 2010.
and Svetha Venkatesh, In</big></li>
        <li><big> <a href="http://truyen.vietlabs.com/papers/uai09_final.pdf">Ordinal
Boltzmann Machines for
Collaborative Filtering</a>. <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung and Svetha Venkatesh. In <span style="font-style: italic;">Proc. of 25th
Conference on Uncertainty in Artificial Intelligence</span>,
June, 2009, Montreal, Canada. <span style="font-weight: bold; color: rgb(204, 0, 0);">Runner-up
for the best paper award</span>.</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/hcrf_fast.pdf">MCMC
for Hierarchical
Semi-Markov Conditional Random Fields</a>, <span style="font-weight: bold;">Truyen Tran</span>,
Dinh Q. Phung, Svetha Venkatesh and Hung H. Bui. In <span style="font-style: italic;">NIPS'09
Workshop on Deep Learning for Speech
Recognition and Related Applications</span>. December, 2009,
Whistler, BC, Canada</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/truyen_nips08.pdf">Hierarchical
Semi-Markov
Conditional Random Fields for Recursive Sequential Data</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh Q. Phung, Hung H. Bui, and Svetha Venkatesh.
In <span style="font-style: italic;">Proc.
of&nbsp;21st
Annual Conference on Neural Information Processing Systems</span>,
Dec 2008, Vancouver, Canada. [See <a href="https://truyentran.github.io/papers/truyen_hcrf_tr08.pdf">technical
report</a>
and <a href="https://truyentran.github.io/papers/thesis.pdf">thesis</a>
for more
details and
extensions.]</big></li>
        <li><big> <a href="https://truyentran.github.io/papers/truyen_cvpr06.pdf">AdaBoost.MRF:
Boosted Markov
random forests and application to multilevel activity recognition</a>, <span style="font-weight: bold;">Truyen
Tran</span>, Dinh&nbsp;Quoc Phung, Hung&nbsp;Hai Bui,
and Svetha Venkatesh. In <span style="font-style: italic;">Proc.
of&nbsp; IEEE Conference
on Computer Vision and Pattern Recognition</span>,
volume Volume 2, pages 1686-1693, New York, USA, June 2006.</big></li>
      </ul>
      <ol>
      </ol>
      <ul>
      </ul>
      <ol>
      </ol>
      </td>
    </tr>
  </tbody>
</table>

</body></html>